{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chinmaya-3141/Capstone-Project/blob/main/Improving_Capstone_Classification_EfficientNetB4_IntermediateFile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWeXcctAC5Sl"
      },
      "source": [
        "# **EfficientNet-B4**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4rTr6szCy9s"
      },
      "source": [
        "## Install and import necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2ebdJ-I796R",
        "outputId": "017628df-0e39-4491-b842-1525885e6849"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.16\n",
            "Name: torch\n",
            "Version: 1.13.1+cu116\n",
            "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\n",
            "Home-page: https://pytorch.org/\n",
            "Author: PyTorch Team\n",
            "Author-email: packages@pytorch.org\n",
            "License: BSD-3\n",
            "Location: /usr/local/lib/python3.9/dist-packages\n",
            "Requires: typing-extensions\n",
            "Required-by: efficientnet-pytorch, fastai, torchaudio, torchtext, torchvision\n"
          ]
        }
      ],
      "source": [
        "!python --version\n",
        "!pip show torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xF8GkYFL6aqF"
      },
      "outputs": [],
      "source": [
        "!pip install torchinfo -qq\n",
        "!pip install efficientnet_pytorch -qq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2ZoL_Ug53pN",
        "outputId": "c40cbe2f-b0d0-44ce-b27a-6dd56d426275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VH3xCD3JCl44"
      },
      "source": [
        "\n",
        "Python 3.9.16\\\n",
        "Name: torch\\\n",
        "Version: 1.13.1+cu116\\\n",
        "Summary: Tensors and Dynamic neural networks in Python with strong GPU acceleration\\\n",
        "Home-page: https://pytorch.org/\\\n",
        "Author: PyTorch Team\\\n",
        "Author-email: packages@pytorch.org\\\n",
        "License: BSD-3\\\n",
        "Location: /usr/local/lib/python3.9/dist-packages\\\n",
        "Requires: typing-extensions\\\n",
        "Required-by: fastai, torchaudio, torchtext, torchvision\\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJ0vp-oA6Ep3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "from numba import cuda\n",
        "import PIL\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MA5XhpDK6Lwa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Et4zkk26Ent"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, ConcatDataset\n",
        "from torchsummary import summary as tssum\n",
        "from torchinfo import summary as tisum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hiwXlcay7G6o"
      },
      "outputs": [],
      "source": [
        "# from torchvision.models import efficientnet_b7 as en7\n",
        "from efficientnet_pytorch import EfficientNet as en4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpxND-LBC_Tf"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup"
      ],
      "metadata": {
        "id": "R6dYzfjF0CK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the root directory of your dataset\n",
        "path = '/content/drive/MyDrive/Capstone Data (Shared)/Capstone Data/Resized Data/Resized Data_320x320'"
      ],
      "metadata": {
        "id": "iWIEeFDbMxY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if GPU is available\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1VrXky-zsfb",
        "outputId": "e3bd6522-4bfe-417c-c9ac-e6a8eb112058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "totCPFA5Cqdx",
        "outputId": "472ebd46-412d-4828-da9f-0a0e740a7a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f6d2393bb10>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kaoXjY4Skty"
      },
      "outputs": [],
      "source": [
        "batchsize = 20\n",
        "dimension=380\n",
        "channels = 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL0n71ZtB3Kc"
      },
      "outputs": [],
      "source": [
        "# Transform to apply to complete dataset\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(380),\n",
        "    transforms.CenterCrop(380),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5121, 0.5121, 0.5121], std=[0.2298, 0.2298, 0.2298])\n",
        "])\n",
        "\n",
        "# Define transform to augment Pneumonia data and then combine it with the rest of the data\n",
        "\n",
        "augmented_transforms = transforms.Compose([\n",
        "    transforms.Resize(380),\n",
        "    transforms.RandomRotation(degrees=20),\n",
        "    transforms.CenterCrop(380),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5121, 0.5121, 0.5121], std=[0.2298, 0.2298, 0.2298])\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation 1"
      ],
      "metadata": {
        "id": "CHswD2cYBTuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drop_classes = ['Covid', 'Normal']\n",
        "list1 = [(path,transform,[]),(path,augmented_transforms,drop_classes)]"
      ],
      "metadata": {
        "id": "qtZAPCeHpqEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConcatImageFolder(ConcatDataset):\n",
        "    def __init__(self, folder_transforms):\n",
        "        # create a list of ImageFolder datasets from the input folder/transform pairs\n",
        "        datasets = []\n",
        "        for folder, transform, drop_classes in folder_transforms:\n",
        "            data = ImageFolder(folder, transform=transforms.Compose([transform]))\n",
        "            data.samples = [(x, y) for x, y in data.samples if data.classes[y] not in drop_classes]\n",
        "            data.classes = [c for c in data.classes if c not in drop_classes]\n",
        "            datasets.append(data)\n",
        "            \n",
        "\n",
        "        # call the parent ConcatDataset constructor with the list of datasets\n",
        "        super().__init__(datasets)\n",
        "\n",
        "        # store the union of all classes from the constituent datasets\n",
        "        self.classes = list(set().union(*[dataset.classes for dataset in datasets]))"
      ],
      "metadata": {
        "id": "lxIC29Z9ngbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datavar = ConcatImageFolder(list1)"
      ],
      "metadata": {
        "id": "Tc2sAgTxoAmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datavar.classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySQ-bMAMqJ-s",
        "outputId": "de61d3fb-937a-4a87-ffec-cfc8f86fa310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pneumonia', 'Normal', 'Covid']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of images: {len(datavar)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82eg4isXqZ2-",
        "outputId": "75cd8633-c473-47f1-ac96-6ff0dee5316d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 9307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation 2"
      ],
      "metadata": {
        "id": "1OhTO5UWBXw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset using the ImageFolder function and apply the transformations\n",
        "\n",
        "train_dataset = ImageFolder(root=path, transform=transform)"
      ],
      "metadata": {
        "id": "UNbtAmcINDYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gs_OQnF5ByKe"
      },
      "outputs": [],
      "source": [
        "# Create new dataset without the specified classes\n",
        "\n",
        "augmented_dataset = ImageFolder(root=path, transform=augmented_transforms)\n",
        "augmented_dataset.samples = [(x, y) for x, y in augmented_dataset.samples if augmented_dataset.classes[y] not in drop_classes]\n",
        "augmented_dataset.classes = [c for c in augmented_dataset.classes if c not in drop_classes]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine the original and augmented datasets into a single dataset\n",
        "# combined_dataset = torch.utils.data.ConcatDataset([train_dataset, augmented_dataset])\n",
        "\n",
        "datavar2 = ConcatDataset([train_dataset, augmented_dataset])"
      ],
      "metadata": {
        "id": "qNIfhbbkl3ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(train_dataset),\"\\n\",type(augmented_dataset),\"\\n\",type(datavar2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xu0yn_mYfqAO",
        "outputId": "162e68fe-181e-4ead-9fe5-b66711b3999f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'torchvision.datasets.folder.ImageFolder'> \n",
            " <class 'torchvision.datasets.folder.ImageFolder'> \n",
            " <class 'torch.utils.data.dataset.ConcatDataset'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(datavar2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bZywt0XV8iA",
        "outputId": "6252dfe6-285f-4291-cfaf-5a6489c2f123"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9307"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Number of images: {len(datavar2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZcGc9V1VvVY",
        "outputId": "577f0bf2-d068-407e-f30c-a496e6702944"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images: 9307\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train-Test-Split"
      ],
      "metadata": {
        "id": "HUQO3TxrCUZQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = torch.utils.data.random_split(datavar, [int(0.8*len(datavar)), len(datavar)-int(0.8*len(datavar))])"
      ],
      "metadata": {
        "id": "gq0AJKBxN0zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LaMYDnlgBYys"
      },
      "outputs": [],
      "source": [
        "# Define the data loaders\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=batchsize, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=batchsize, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean and standard deviation of the training data\n",
        "\n",
        "# mean = 0.0\n",
        "# std = 0.0\n",
        "# num_samples = 0\n",
        "\n",
        "# for images, _ in train_loader:\n",
        "#     batch_samples = images.size(0)\n",
        "#     images = images.view(batch_samples, images.size(1), -1).to(device)\n",
        "#     mean += images.mean(2).sum(0).to(device)\n",
        "#     std += images.std(2).sum(0).to(device)\n",
        "#     num_samples += batch_samples\n",
        "\n",
        "# mean /= num_samples\n",
        "# std /= num_samples\n",
        "\n",
        "# print(\"Mean:\", mean)\n",
        "# print(\"Standard deviation:\", std)"
      ],
      "metadata": {
        "id": "4zct4qkrJEQB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRnQitcODO5B"
      },
      "source": [
        "## Modelling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z92J0S7j6_-U",
        "outputId": "1d2a46ca-cc91-4bd7-eab3-21d3851bc11d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained weights for efficientnet-b4\n"
          ]
        }
      ],
      "source": [
        "# EfficientNetB7 requires 380*380 images\n",
        "\n",
        "model = en4.from_pretrained('efficientnet-b4', num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1Vv5Vjc6Eia",
        "outputId": "ef8ee5bb-5b5c-443a-c1dc-e06ce29e96f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (2): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (5): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (6): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (7): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (8): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (11): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (12): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (13): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (14): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (16): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (17): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (18): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (19): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (20): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (21): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (22): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (23): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (24): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (25): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (26): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (27): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (28): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (29): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (30): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (31): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.4, inplace=False)\n",
              "  (_fc): Linear(in_features=1792, out_features=3, bias=True)\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Load the model to device\n",
        "\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfEk_LrX6Efl",
        "outputId": "1d10ac03-bec4-4486-ea01-59ec8235c3a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "         ZeroPad2d-1          [-1, 3, 381, 381]               0\n",
            "Conv2dStaticSamePadding-2         [-1, 48, 190, 190]           1,296\n",
            "       BatchNorm2d-3         [-1, 48, 190, 190]              96\n",
            "MemoryEfficientSwish-4         [-1, 48, 190, 190]               0\n",
            "         ZeroPad2d-5         [-1, 48, 192, 192]               0\n",
            "Conv2dStaticSamePadding-6         [-1, 48, 190, 190]             432\n",
            "       BatchNorm2d-7         [-1, 48, 190, 190]              96\n",
            "MemoryEfficientSwish-8         [-1, 48, 190, 190]               0\n",
            "          Identity-9             [-1, 48, 1, 1]               0\n",
            "Conv2dStaticSamePadding-10             [-1, 12, 1, 1]             588\n",
            "MemoryEfficientSwish-11             [-1, 12, 1, 1]               0\n",
            "         Identity-12             [-1, 12, 1, 1]               0\n",
            "Conv2dStaticSamePadding-13             [-1, 48, 1, 1]             624\n",
            "         Identity-14         [-1, 48, 190, 190]               0\n",
            "Conv2dStaticSamePadding-15         [-1, 24, 190, 190]           1,152\n",
            "      BatchNorm2d-16         [-1, 24, 190, 190]              48\n",
            "      MBConvBlock-17         [-1, 24, 190, 190]               0\n",
            "        ZeroPad2d-18         [-1, 24, 192, 192]               0\n",
            "Conv2dStaticSamePadding-19         [-1, 24, 190, 190]             216\n",
            "      BatchNorm2d-20         [-1, 24, 190, 190]              48\n",
            "MemoryEfficientSwish-21         [-1, 24, 190, 190]               0\n",
            "         Identity-22             [-1, 24, 1, 1]               0\n",
            "Conv2dStaticSamePadding-23              [-1, 6, 1, 1]             150\n",
            "MemoryEfficientSwish-24              [-1, 6, 1, 1]               0\n",
            "         Identity-25              [-1, 6, 1, 1]               0\n",
            "Conv2dStaticSamePadding-26             [-1, 24, 1, 1]             168\n",
            "         Identity-27         [-1, 24, 190, 190]               0\n",
            "Conv2dStaticSamePadding-28         [-1, 24, 190, 190]             576\n",
            "      BatchNorm2d-29         [-1, 24, 190, 190]              48\n",
            "      MBConvBlock-30         [-1, 24, 190, 190]               0\n",
            "         Identity-31         [-1, 24, 190, 190]               0\n",
            "Conv2dStaticSamePadding-32        [-1, 144, 190, 190]           3,456\n",
            "      BatchNorm2d-33        [-1, 144, 190, 190]             288\n",
            "MemoryEfficientSwish-34        [-1, 144, 190, 190]               0\n",
            "        ZeroPad2d-35        [-1, 144, 191, 191]               0\n",
            "Conv2dStaticSamePadding-36          [-1, 144, 95, 95]           1,296\n",
            "      BatchNorm2d-37          [-1, 144, 95, 95]             288\n",
            "MemoryEfficientSwish-38          [-1, 144, 95, 95]               0\n",
            "         Identity-39            [-1, 144, 1, 1]               0\n",
            "Conv2dStaticSamePadding-40              [-1, 6, 1, 1]             870\n",
            "MemoryEfficientSwish-41              [-1, 6, 1, 1]               0\n",
            "         Identity-42              [-1, 6, 1, 1]               0\n",
            "Conv2dStaticSamePadding-43            [-1, 144, 1, 1]           1,008\n",
            "         Identity-44          [-1, 144, 95, 95]               0\n",
            "Conv2dStaticSamePadding-45           [-1, 32, 95, 95]           4,608\n",
            "      BatchNorm2d-46           [-1, 32, 95, 95]              64\n",
            "      MBConvBlock-47           [-1, 32, 95, 95]               0\n",
            "         Identity-48           [-1, 32, 95, 95]               0\n",
            "Conv2dStaticSamePadding-49          [-1, 192, 95, 95]           6,144\n",
            "      BatchNorm2d-50          [-1, 192, 95, 95]             384\n",
            "MemoryEfficientSwish-51          [-1, 192, 95, 95]               0\n",
            "        ZeroPad2d-52          [-1, 192, 97, 97]               0\n",
            "Conv2dStaticSamePadding-53          [-1, 192, 95, 95]           1,728\n",
            "      BatchNorm2d-54          [-1, 192, 95, 95]             384\n",
            "MemoryEfficientSwish-55          [-1, 192, 95, 95]               0\n",
            "         Identity-56            [-1, 192, 1, 1]               0\n",
            "Conv2dStaticSamePadding-57              [-1, 8, 1, 1]           1,544\n",
            "MemoryEfficientSwish-58              [-1, 8, 1, 1]               0\n",
            "         Identity-59              [-1, 8, 1, 1]               0\n",
            "Conv2dStaticSamePadding-60            [-1, 192, 1, 1]           1,728\n",
            "         Identity-61          [-1, 192, 95, 95]               0\n",
            "Conv2dStaticSamePadding-62           [-1, 32, 95, 95]           6,144\n",
            "      BatchNorm2d-63           [-1, 32, 95, 95]              64\n",
            "      MBConvBlock-64           [-1, 32, 95, 95]               0\n",
            "         Identity-65           [-1, 32, 95, 95]               0\n",
            "Conv2dStaticSamePadding-66          [-1, 192, 95, 95]           6,144\n",
            "      BatchNorm2d-67          [-1, 192, 95, 95]             384\n",
            "MemoryEfficientSwish-68          [-1, 192, 95, 95]               0\n",
            "        ZeroPad2d-69          [-1, 192, 97, 97]               0\n",
            "Conv2dStaticSamePadding-70          [-1, 192, 95, 95]           1,728\n",
            "      BatchNorm2d-71          [-1, 192, 95, 95]             384\n",
            "MemoryEfficientSwish-72          [-1, 192, 95, 95]               0\n",
            "         Identity-73            [-1, 192, 1, 1]               0\n",
            "Conv2dStaticSamePadding-74              [-1, 8, 1, 1]           1,544\n",
            "MemoryEfficientSwish-75              [-1, 8, 1, 1]               0\n",
            "         Identity-76              [-1, 8, 1, 1]               0\n",
            "Conv2dStaticSamePadding-77            [-1, 192, 1, 1]           1,728\n",
            "         Identity-78          [-1, 192, 95, 95]               0\n",
            "Conv2dStaticSamePadding-79           [-1, 32, 95, 95]           6,144\n",
            "      BatchNorm2d-80           [-1, 32, 95, 95]              64\n",
            "      MBConvBlock-81           [-1, 32, 95, 95]               0\n",
            "         Identity-82           [-1, 32, 95, 95]               0\n",
            "Conv2dStaticSamePadding-83          [-1, 192, 95, 95]           6,144\n",
            "      BatchNorm2d-84          [-1, 192, 95, 95]             384\n",
            "MemoryEfficientSwish-85          [-1, 192, 95, 95]               0\n",
            "        ZeroPad2d-86          [-1, 192, 97, 97]               0\n",
            "Conv2dStaticSamePadding-87          [-1, 192, 95, 95]           1,728\n",
            "      BatchNorm2d-88          [-1, 192, 95, 95]             384\n",
            "MemoryEfficientSwish-89          [-1, 192, 95, 95]               0\n",
            "         Identity-90            [-1, 192, 1, 1]               0\n",
            "Conv2dStaticSamePadding-91              [-1, 8, 1, 1]           1,544\n",
            "MemoryEfficientSwish-92              [-1, 8, 1, 1]               0\n",
            "         Identity-93              [-1, 8, 1, 1]               0\n",
            "Conv2dStaticSamePadding-94            [-1, 192, 1, 1]           1,728\n",
            "         Identity-95          [-1, 192, 95, 95]               0\n",
            "Conv2dStaticSamePadding-96           [-1, 32, 95, 95]           6,144\n",
            "      BatchNorm2d-97           [-1, 32, 95, 95]              64\n",
            "      MBConvBlock-98           [-1, 32, 95, 95]               0\n",
            "         Identity-99           [-1, 32, 95, 95]               0\n",
            "Conv2dStaticSamePadding-100          [-1, 192, 95, 95]           6,144\n",
            "     BatchNorm2d-101          [-1, 192, 95, 95]             384\n",
            "MemoryEfficientSwish-102          [-1, 192, 95, 95]               0\n",
            "       ZeroPad2d-103          [-1, 192, 99, 99]               0\n",
            "Conv2dStaticSamePadding-104          [-1, 192, 48, 48]           4,800\n",
            "     BatchNorm2d-105          [-1, 192, 48, 48]             384\n",
            "MemoryEfficientSwish-106          [-1, 192, 48, 48]               0\n",
            "        Identity-107            [-1, 192, 1, 1]               0\n",
            "Conv2dStaticSamePadding-108              [-1, 8, 1, 1]           1,544\n",
            "MemoryEfficientSwish-109              [-1, 8, 1, 1]               0\n",
            "        Identity-110              [-1, 8, 1, 1]               0\n",
            "Conv2dStaticSamePadding-111            [-1, 192, 1, 1]           1,728\n",
            "        Identity-112          [-1, 192, 48, 48]               0\n",
            "Conv2dStaticSamePadding-113           [-1, 56, 48, 48]          10,752\n",
            "     BatchNorm2d-114           [-1, 56, 48, 48]             112\n",
            "     MBConvBlock-115           [-1, 56, 48, 48]               0\n",
            "        Identity-116           [-1, 56, 48, 48]               0\n",
            "Conv2dStaticSamePadding-117          [-1, 336, 48, 48]          18,816\n",
            "     BatchNorm2d-118          [-1, 336, 48, 48]             672\n",
            "MemoryEfficientSwish-119          [-1, 336, 48, 48]               0\n",
            "       ZeroPad2d-120          [-1, 336, 52, 52]               0\n",
            "Conv2dStaticSamePadding-121          [-1, 336, 48, 48]           8,400\n",
            "     BatchNorm2d-122          [-1, 336, 48, 48]             672\n",
            "MemoryEfficientSwish-123          [-1, 336, 48, 48]               0\n",
            "        Identity-124            [-1, 336, 1, 1]               0\n",
            "Conv2dStaticSamePadding-125             [-1, 14, 1, 1]           4,718\n",
            "MemoryEfficientSwish-126             [-1, 14, 1, 1]               0\n",
            "        Identity-127             [-1, 14, 1, 1]               0\n",
            "Conv2dStaticSamePadding-128            [-1, 336, 1, 1]           5,040\n",
            "        Identity-129          [-1, 336, 48, 48]               0\n",
            "Conv2dStaticSamePadding-130           [-1, 56, 48, 48]          18,816\n",
            "     BatchNorm2d-131           [-1, 56, 48, 48]             112\n",
            "     MBConvBlock-132           [-1, 56, 48, 48]               0\n",
            "        Identity-133           [-1, 56, 48, 48]               0\n",
            "Conv2dStaticSamePadding-134          [-1, 336, 48, 48]          18,816\n",
            "     BatchNorm2d-135          [-1, 336, 48, 48]             672\n",
            "MemoryEfficientSwish-136          [-1, 336, 48, 48]               0\n",
            "       ZeroPad2d-137          [-1, 336, 52, 52]               0\n",
            "Conv2dStaticSamePadding-138          [-1, 336, 48, 48]           8,400\n",
            "     BatchNorm2d-139          [-1, 336, 48, 48]             672\n",
            "MemoryEfficientSwish-140          [-1, 336, 48, 48]               0\n",
            "        Identity-141            [-1, 336, 1, 1]               0\n",
            "Conv2dStaticSamePadding-142             [-1, 14, 1, 1]           4,718\n",
            "MemoryEfficientSwish-143             [-1, 14, 1, 1]               0\n",
            "        Identity-144             [-1, 14, 1, 1]               0\n",
            "Conv2dStaticSamePadding-145            [-1, 336, 1, 1]           5,040\n",
            "        Identity-146          [-1, 336, 48, 48]               0\n",
            "Conv2dStaticSamePadding-147           [-1, 56, 48, 48]          18,816\n",
            "     BatchNorm2d-148           [-1, 56, 48, 48]             112\n",
            "     MBConvBlock-149           [-1, 56, 48, 48]               0\n",
            "        Identity-150           [-1, 56, 48, 48]               0\n",
            "Conv2dStaticSamePadding-151          [-1, 336, 48, 48]          18,816\n",
            "     BatchNorm2d-152          [-1, 336, 48, 48]             672\n",
            "MemoryEfficientSwish-153          [-1, 336, 48, 48]               0\n",
            "       ZeroPad2d-154          [-1, 336, 52, 52]               0\n",
            "Conv2dStaticSamePadding-155          [-1, 336, 48, 48]           8,400\n",
            "     BatchNorm2d-156          [-1, 336, 48, 48]             672\n",
            "MemoryEfficientSwish-157          [-1, 336, 48, 48]               0\n",
            "        Identity-158            [-1, 336, 1, 1]               0\n",
            "Conv2dStaticSamePadding-159             [-1, 14, 1, 1]           4,718\n",
            "MemoryEfficientSwish-160             [-1, 14, 1, 1]               0\n",
            "        Identity-161             [-1, 14, 1, 1]               0\n",
            "Conv2dStaticSamePadding-162            [-1, 336, 1, 1]           5,040\n",
            "        Identity-163          [-1, 336, 48, 48]               0\n",
            "Conv2dStaticSamePadding-164           [-1, 56, 48, 48]          18,816\n",
            "     BatchNorm2d-165           [-1, 56, 48, 48]             112\n",
            "     MBConvBlock-166           [-1, 56, 48, 48]               0\n",
            "        Identity-167           [-1, 56, 48, 48]               0\n",
            "Conv2dStaticSamePadding-168          [-1, 336, 48, 48]          18,816\n",
            "     BatchNorm2d-169          [-1, 336, 48, 48]             672\n",
            "MemoryEfficientSwish-170          [-1, 336, 48, 48]               0\n",
            "       ZeroPad2d-171          [-1, 336, 49, 49]               0\n",
            "Conv2dStaticSamePadding-172          [-1, 336, 24, 24]           3,024\n",
            "     BatchNorm2d-173          [-1, 336, 24, 24]             672\n",
            "MemoryEfficientSwish-174          [-1, 336, 24, 24]               0\n",
            "        Identity-175            [-1, 336, 1, 1]               0\n",
            "Conv2dStaticSamePadding-176             [-1, 14, 1, 1]           4,718\n",
            "MemoryEfficientSwish-177             [-1, 14, 1, 1]               0\n",
            "        Identity-178             [-1, 14, 1, 1]               0\n",
            "Conv2dStaticSamePadding-179            [-1, 336, 1, 1]           5,040\n",
            "        Identity-180          [-1, 336, 24, 24]               0\n",
            "Conv2dStaticSamePadding-181          [-1, 112, 24, 24]          37,632\n",
            "     BatchNorm2d-182          [-1, 112, 24, 24]             224\n",
            "     MBConvBlock-183          [-1, 112, 24, 24]               0\n",
            "        Identity-184          [-1, 112, 24, 24]               0\n",
            "Conv2dStaticSamePadding-185          [-1, 672, 24, 24]          75,264\n",
            "     BatchNorm2d-186          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-187          [-1, 672, 24, 24]               0\n",
            "       ZeroPad2d-188          [-1, 672, 26, 26]               0\n",
            "Conv2dStaticSamePadding-189          [-1, 672, 24, 24]           6,048\n",
            "     BatchNorm2d-190          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-191          [-1, 672, 24, 24]               0\n",
            "        Identity-192            [-1, 672, 1, 1]               0\n",
            "Conv2dStaticSamePadding-193             [-1, 28, 1, 1]          18,844\n",
            "MemoryEfficientSwish-194             [-1, 28, 1, 1]               0\n",
            "        Identity-195             [-1, 28, 1, 1]               0\n",
            "Conv2dStaticSamePadding-196            [-1, 672, 1, 1]          19,488\n",
            "        Identity-197          [-1, 672, 24, 24]               0\n",
            "Conv2dStaticSamePadding-198          [-1, 112, 24, 24]          75,264\n",
            "     BatchNorm2d-199          [-1, 112, 24, 24]             224\n",
            "     MBConvBlock-200          [-1, 112, 24, 24]               0\n",
            "        Identity-201          [-1, 112, 24, 24]               0\n",
            "Conv2dStaticSamePadding-202          [-1, 672, 24, 24]          75,264\n",
            "     BatchNorm2d-203          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-204          [-1, 672, 24, 24]               0\n",
            "       ZeroPad2d-205          [-1, 672, 26, 26]               0\n",
            "Conv2dStaticSamePadding-206          [-1, 672, 24, 24]           6,048\n",
            "     BatchNorm2d-207          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-208          [-1, 672, 24, 24]               0\n",
            "        Identity-209            [-1, 672, 1, 1]               0\n",
            "Conv2dStaticSamePadding-210             [-1, 28, 1, 1]          18,844\n",
            "MemoryEfficientSwish-211             [-1, 28, 1, 1]               0\n",
            "        Identity-212             [-1, 28, 1, 1]               0\n",
            "Conv2dStaticSamePadding-213            [-1, 672, 1, 1]          19,488\n",
            "        Identity-214          [-1, 672, 24, 24]               0\n",
            "Conv2dStaticSamePadding-215          [-1, 112, 24, 24]          75,264\n",
            "     BatchNorm2d-216          [-1, 112, 24, 24]             224\n",
            "     MBConvBlock-217          [-1, 112, 24, 24]               0\n",
            "        Identity-218          [-1, 112, 24, 24]               0\n",
            "Conv2dStaticSamePadding-219          [-1, 672, 24, 24]          75,264\n",
            "     BatchNorm2d-220          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-221          [-1, 672, 24, 24]               0\n",
            "       ZeroPad2d-222          [-1, 672, 26, 26]               0\n",
            "Conv2dStaticSamePadding-223          [-1, 672, 24, 24]           6,048\n",
            "     BatchNorm2d-224          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-225          [-1, 672, 24, 24]               0\n",
            "        Identity-226            [-1, 672, 1, 1]               0\n",
            "Conv2dStaticSamePadding-227             [-1, 28, 1, 1]          18,844\n",
            "MemoryEfficientSwish-228             [-1, 28, 1, 1]               0\n",
            "        Identity-229             [-1, 28, 1, 1]               0\n",
            "Conv2dStaticSamePadding-230            [-1, 672, 1, 1]          19,488\n",
            "        Identity-231          [-1, 672, 24, 24]               0\n",
            "Conv2dStaticSamePadding-232          [-1, 112, 24, 24]          75,264\n",
            "     BatchNorm2d-233          [-1, 112, 24, 24]             224\n",
            "     MBConvBlock-234          [-1, 112, 24, 24]               0\n",
            "        Identity-235          [-1, 112, 24, 24]               0\n",
            "Conv2dStaticSamePadding-236          [-1, 672, 24, 24]          75,264\n",
            "     BatchNorm2d-237          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-238          [-1, 672, 24, 24]               0\n",
            "       ZeroPad2d-239          [-1, 672, 26, 26]               0\n",
            "Conv2dStaticSamePadding-240          [-1, 672, 24, 24]           6,048\n",
            "     BatchNorm2d-241          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-242          [-1, 672, 24, 24]               0\n",
            "        Identity-243            [-1, 672, 1, 1]               0\n",
            "Conv2dStaticSamePadding-244             [-1, 28, 1, 1]          18,844\n",
            "MemoryEfficientSwish-245             [-1, 28, 1, 1]               0\n",
            "        Identity-246             [-1, 28, 1, 1]               0\n",
            "Conv2dStaticSamePadding-247            [-1, 672, 1, 1]          19,488\n",
            "        Identity-248          [-1, 672, 24, 24]               0\n",
            "Conv2dStaticSamePadding-249          [-1, 112, 24, 24]          75,264\n",
            "     BatchNorm2d-250          [-1, 112, 24, 24]             224\n",
            "     MBConvBlock-251          [-1, 112, 24, 24]               0\n",
            "        Identity-252          [-1, 112, 24, 24]               0\n",
            "Conv2dStaticSamePadding-253          [-1, 672, 24, 24]          75,264\n",
            "     BatchNorm2d-254          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-255          [-1, 672, 24, 24]               0\n",
            "       ZeroPad2d-256          [-1, 672, 26, 26]               0\n",
            "Conv2dStaticSamePadding-257          [-1, 672, 24, 24]           6,048\n",
            "     BatchNorm2d-258          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-259          [-1, 672, 24, 24]               0\n",
            "        Identity-260            [-1, 672, 1, 1]               0\n",
            "Conv2dStaticSamePadding-261             [-1, 28, 1, 1]          18,844\n",
            "MemoryEfficientSwish-262             [-1, 28, 1, 1]               0\n",
            "        Identity-263             [-1, 28, 1, 1]               0\n",
            "Conv2dStaticSamePadding-264            [-1, 672, 1, 1]          19,488\n",
            "        Identity-265          [-1, 672, 24, 24]               0\n",
            "Conv2dStaticSamePadding-266          [-1, 112, 24, 24]          75,264\n",
            "     BatchNorm2d-267          [-1, 112, 24, 24]             224\n",
            "     MBConvBlock-268          [-1, 112, 24, 24]               0\n",
            "        Identity-269          [-1, 112, 24, 24]               0\n",
            "Conv2dStaticSamePadding-270          [-1, 672, 24, 24]          75,264\n",
            "     BatchNorm2d-271          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-272          [-1, 672, 24, 24]               0\n",
            "       ZeroPad2d-273          [-1, 672, 28, 28]               0\n",
            "Conv2dStaticSamePadding-274          [-1, 672, 24, 24]          16,800\n",
            "     BatchNorm2d-275          [-1, 672, 24, 24]           1,344\n",
            "MemoryEfficientSwish-276          [-1, 672, 24, 24]               0\n",
            "        Identity-277            [-1, 672, 1, 1]               0\n",
            "Conv2dStaticSamePadding-278             [-1, 28, 1, 1]          18,844\n",
            "MemoryEfficientSwish-279             [-1, 28, 1, 1]               0\n",
            "        Identity-280             [-1, 28, 1, 1]               0\n",
            "Conv2dStaticSamePadding-281            [-1, 672, 1, 1]          19,488\n",
            "        Identity-282          [-1, 672, 24, 24]               0\n",
            "Conv2dStaticSamePadding-283          [-1, 160, 24, 24]         107,520\n",
            "     BatchNorm2d-284          [-1, 160, 24, 24]             320\n",
            "     MBConvBlock-285          [-1, 160, 24, 24]               0\n",
            "        Identity-286          [-1, 160, 24, 24]               0\n",
            "Conv2dStaticSamePadding-287          [-1, 960, 24, 24]         153,600\n",
            "     BatchNorm2d-288          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-289          [-1, 960, 24, 24]               0\n",
            "       ZeroPad2d-290          [-1, 960, 28, 28]               0\n",
            "Conv2dStaticSamePadding-291          [-1, 960, 24, 24]          24,000\n",
            "     BatchNorm2d-292          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-293          [-1, 960, 24, 24]               0\n",
            "        Identity-294            [-1, 960, 1, 1]               0\n",
            "Conv2dStaticSamePadding-295             [-1, 40, 1, 1]          38,440\n",
            "MemoryEfficientSwish-296             [-1, 40, 1, 1]               0\n",
            "        Identity-297             [-1, 40, 1, 1]               0\n",
            "Conv2dStaticSamePadding-298            [-1, 960, 1, 1]          39,360\n",
            "        Identity-299          [-1, 960, 24, 24]               0\n",
            "Conv2dStaticSamePadding-300          [-1, 160, 24, 24]         153,600\n",
            "     BatchNorm2d-301          [-1, 160, 24, 24]             320\n",
            "     MBConvBlock-302          [-1, 160, 24, 24]               0\n",
            "        Identity-303          [-1, 160, 24, 24]               0\n",
            "Conv2dStaticSamePadding-304          [-1, 960, 24, 24]         153,600\n",
            "     BatchNorm2d-305          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-306          [-1, 960, 24, 24]               0\n",
            "       ZeroPad2d-307          [-1, 960, 28, 28]               0\n",
            "Conv2dStaticSamePadding-308          [-1, 960, 24, 24]          24,000\n",
            "     BatchNorm2d-309          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-310          [-1, 960, 24, 24]               0\n",
            "        Identity-311            [-1, 960, 1, 1]               0\n",
            "Conv2dStaticSamePadding-312             [-1, 40, 1, 1]          38,440\n",
            "MemoryEfficientSwish-313             [-1, 40, 1, 1]               0\n",
            "        Identity-314             [-1, 40, 1, 1]               0\n",
            "Conv2dStaticSamePadding-315            [-1, 960, 1, 1]          39,360\n",
            "        Identity-316          [-1, 960, 24, 24]               0\n",
            "Conv2dStaticSamePadding-317          [-1, 160, 24, 24]         153,600\n",
            "     BatchNorm2d-318          [-1, 160, 24, 24]             320\n",
            "     MBConvBlock-319          [-1, 160, 24, 24]               0\n",
            "        Identity-320          [-1, 160, 24, 24]               0\n",
            "Conv2dStaticSamePadding-321          [-1, 960, 24, 24]         153,600\n",
            "     BatchNorm2d-322          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-323          [-1, 960, 24, 24]               0\n",
            "       ZeroPad2d-324          [-1, 960, 28, 28]               0\n",
            "Conv2dStaticSamePadding-325          [-1, 960, 24, 24]          24,000\n",
            "     BatchNorm2d-326          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-327          [-1, 960, 24, 24]               0\n",
            "        Identity-328            [-1, 960, 1, 1]               0\n",
            "Conv2dStaticSamePadding-329             [-1, 40, 1, 1]          38,440\n",
            "MemoryEfficientSwish-330             [-1, 40, 1, 1]               0\n",
            "        Identity-331             [-1, 40, 1, 1]               0\n",
            "Conv2dStaticSamePadding-332            [-1, 960, 1, 1]          39,360\n",
            "        Identity-333          [-1, 960, 24, 24]               0\n",
            "Conv2dStaticSamePadding-334          [-1, 160, 24, 24]         153,600\n",
            "     BatchNorm2d-335          [-1, 160, 24, 24]             320\n",
            "     MBConvBlock-336          [-1, 160, 24, 24]               0\n",
            "        Identity-337          [-1, 160, 24, 24]               0\n",
            "Conv2dStaticSamePadding-338          [-1, 960, 24, 24]         153,600\n",
            "     BatchNorm2d-339          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-340          [-1, 960, 24, 24]               0\n",
            "       ZeroPad2d-341          [-1, 960, 28, 28]               0\n",
            "Conv2dStaticSamePadding-342          [-1, 960, 24, 24]          24,000\n",
            "     BatchNorm2d-343          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-344          [-1, 960, 24, 24]               0\n",
            "        Identity-345            [-1, 960, 1, 1]               0\n",
            "Conv2dStaticSamePadding-346             [-1, 40, 1, 1]          38,440\n",
            "MemoryEfficientSwish-347             [-1, 40, 1, 1]               0\n",
            "        Identity-348             [-1, 40, 1, 1]               0\n",
            "Conv2dStaticSamePadding-349            [-1, 960, 1, 1]          39,360\n",
            "        Identity-350          [-1, 960, 24, 24]               0\n",
            "Conv2dStaticSamePadding-351          [-1, 160, 24, 24]         153,600\n",
            "     BatchNorm2d-352          [-1, 160, 24, 24]             320\n",
            "     MBConvBlock-353          [-1, 160, 24, 24]               0\n",
            "        Identity-354          [-1, 160, 24, 24]               0\n",
            "Conv2dStaticSamePadding-355          [-1, 960, 24, 24]         153,600\n",
            "     BatchNorm2d-356          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-357          [-1, 960, 24, 24]               0\n",
            "       ZeroPad2d-358          [-1, 960, 28, 28]               0\n",
            "Conv2dStaticSamePadding-359          [-1, 960, 24, 24]          24,000\n",
            "     BatchNorm2d-360          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-361          [-1, 960, 24, 24]               0\n",
            "        Identity-362            [-1, 960, 1, 1]               0\n",
            "Conv2dStaticSamePadding-363             [-1, 40, 1, 1]          38,440\n",
            "MemoryEfficientSwish-364             [-1, 40, 1, 1]               0\n",
            "        Identity-365             [-1, 40, 1, 1]               0\n",
            "Conv2dStaticSamePadding-366            [-1, 960, 1, 1]          39,360\n",
            "        Identity-367          [-1, 960, 24, 24]               0\n",
            "Conv2dStaticSamePadding-368          [-1, 160, 24, 24]         153,600\n",
            "     BatchNorm2d-369          [-1, 160, 24, 24]             320\n",
            "     MBConvBlock-370          [-1, 160, 24, 24]               0\n",
            "        Identity-371          [-1, 160, 24, 24]               0\n",
            "Conv2dStaticSamePadding-372          [-1, 960, 24, 24]         153,600\n",
            "     BatchNorm2d-373          [-1, 960, 24, 24]           1,920\n",
            "MemoryEfficientSwish-374          [-1, 960, 24, 24]               0\n",
            "       ZeroPad2d-375          [-1, 960, 27, 27]               0\n",
            "Conv2dStaticSamePadding-376          [-1, 960, 12, 12]          24,000\n",
            "     BatchNorm2d-377          [-1, 960, 12, 12]           1,920\n",
            "MemoryEfficientSwish-378          [-1, 960, 12, 12]               0\n",
            "        Identity-379            [-1, 960, 1, 1]               0\n",
            "Conv2dStaticSamePadding-380             [-1, 40, 1, 1]          38,440\n",
            "MemoryEfficientSwish-381             [-1, 40, 1, 1]               0\n",
            "        Identity-382             [-1, 40, 1, 1]               0\n",
            "Conv2dStaticSamePadding-383            [-1, 960, 1, 1]          39,360\n",
            "        Identity-384          [-1, 960, 12, 12]               0\n",
            "Conv2dStaticSamePadding-385          [-1, 272, 12, 12]         261,120\n",
            "     BatchNorm2d-386          [-1, 272, 12, 12]             544\n",
            "     MBConvBlock-387          [-1, 272, 12, 12]               0\n",
            "        Identity-388          [-1, 272, 12, 12]               0\n",
            "Conv2dStaticSamePadding-389         [-1, 1632, 12, 12]         443,904\n",
            "     BatchNorm2d-390         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-391         [-1, 1632, 12, 12]               0\n",
            "       ZeroPad2d-392         [-1, 1632, 16, 16]               0\n",
            "Conv2dStaticSamePadding-393         [-1, 1632, 12, 12]          40,800\n",
            "     BatchNorm2d-394         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-395         [-1, 1632, 12, 12]               0\n",
            "        Identity-396           [-1, 1632, 1, 1]               0\n",
            "Conv2dStaticSamePadding-397             [-1, 68, 1, 1]         111,044\n",
            "MemoryEfficientSwish-398             [-1, 68, 1, 1]               0\n",
            "        Identity-399             [-1, 68, 1, 1]               0\n",
            "Conv2dStaticSamePadding-400           [-1, 1632, 1, 1]         112,608\n",
            "        Identity-401         [-1, 1632, 12, 12]               0\n",
            "Conv2dStaticSamePadding-402          [-1, 272, 12, 12]         443,904\n",
            "     BatchNorm2d-403          [-1, 272, 12, 12]             544\n",
            "     MBConvBlock-404          [-1, 272, 12, 12]               0\n",
            "        Identity-405          [-1, 272, 12, 12]               0\n",
            "Conv2dStaticSamePadding-406         [-1, 1632, 12, 12]         443,904\n",
            "     BatchNorm2d-407         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-408         [-1, 1632, 12, 12]               0\n",
            "       ZeroPad2d-409         [-1, 1632, 16, 16]               0\n",
            "Conv2dStaticSamePadding-410         [-1, 1632, 12, 12]          40,800\n",
            "     BatchNorm2d-411         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-412         [-1, 1632, 12, 12]               0\n",
            "        Identity-413           [-1, 1632, 1, 1]               0\n",
            "Conv2dStaticSamePadding-414             [-1, 68, 1, 1]         111,044\n",
            "MemoryEfficientSwish-415             [-1, 68, 1, 1]               0\n",
            "        Identity-416             [-1, 68, 1, 1]               0\n",
            "Conv2dStaticSamePadding-417           [-1, 1632, 1, 1]         112,608\n",
            "        Identity-418         [-1, 1632, 12, 12]               0\n",
            "Conv2dStaticSamePadding-419          [-1, 272, 12, 12]         443,904\n",
            "     BatchNorm2d-420          [-1, 272, 12, 12]             544\n",
            "     MBConvBlock-421          [-1, 272, 12, 12]               0\n",
            "        Identity-422          [-1, 272, 12, 12]               0\n",
            "Conv2dStaticSamePadding-423         [-1, 1632, 12, 12]         443,904\n",
            "     BatchNorm2d-424         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-425         [-1, 1632, 12, 12]               0\n",
            "       ZeroPad2d-426         [-1, 1632, 16, 16]               0\n",
            "Conv2dStaticSamePadding-427         [-1, 1632, 12, 12]          40,800\n",
            "     BatchNorm2d-428         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-429         [-1, 1632, 12, 12]               0\n",
            "        Identity-430           [-1, 1632, 1, 1]               0\n",
            "Conv2dStaticSamePadding-431             [-1, 68, 1, 1]         111,044\n",
            "MemoryEfficientSwish-432             [-1, 68, 1, 1]               0\n",
            "        Identity-433             [-1, 68, 1, 1]               0\n",
            "Conv2dStaticSamePadding-434           [-1, 1632, 1, 1]         112,608\n",
            "        Identity-435         [-1, 1632, 12, 12]               0\n",
            "Conv2dStaticSamePadding-436          [-1, 272, 12, 12]         443,904\n",
            "     BatchNorm2d-437          [-1, 272, 12, 12]             544\n",
            "     MBConvBlock-438          [-1, 272, 12, 12]               0\n",
            "        Identity-439          [-1, 272, 12, 12]               0\n",
            "Conv2dStaticSamePadding-440         [-1, 1632, 12, 12]         443,904\n",
            "     BatchNorm2d-441         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-442         [-1, 1632, 12, 12]               0\n",
            "       ZeroPad2d-443         [-1, 1632, 16, 16]               0\n",
            "Conv2dStaticSamePadding-444         [-1, 1632, 12, 12]          40,800\n",
            "     BatchNorm2d-445         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-446         [-1, 1632, 12, 12]               0\n",
            "        Identity-447           [-1, 1632, 1, 1]               0\n",
            "Conv2dStaticSamePadding-448             [-1, 68, 1, 1]         111,044\n",
            "MemoryEfficientSwish-449             [-1, 68, 1, 1]               0\n",
            "        Identity-450             [-1, 68, 1, 1]               0\n",
            "Conv2dStaticSamePadding-451           [-1, 1632, 1, 1]         112,608\n",
            "        Identity-452         [-1, 1632, 12, 12]               0\n",
            "Conv2dStaticSamePadding-453          [-1, 272, 12, 12]         443,904\n",
            "     BatchNorm2d-454          [-1, 272, 12, 12]             544\n",
            "     MBConvBlock-455          [-1, 272, 12, 12]               0\n",
            "        Identity-456          [-1, 272, 12, 12]               0\n",
            "Conv2dStaticSamePadding-457         [-1, 1632, 12, 12]         443,904\n",
            "     BatchNorm2d-458         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-459         [-1, 1632, 12, 12]               0\n",
            "       ZeroPad2d-460         [-1, 1632, 16, 16]               0\n",
            "Conv2dStaticSamePadding-461         [-1, 1632, 12, 12]          40,800\n",
            "     BatchNorm2d-462         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-463         [-1, 1632, 12, 12]               0\n",
            "        Identity-464           [-1, 1632, 1, 1]               0\n",
            "Conv2dStaticSamePadding-465             [-1, 68, 1, 1]         111,044\n",
            "MemoryEfficientSwish-466             [-1, 68, 1, 1]               0\n",
            "        Identity-467             [-1, 68, 1, 1]               0\n",
            "Conv2dStaticSamePadding-468           [-1, 1632, 1, 1]         112,608\n",
            "        Identity-469         [-1, 1632, 12, 12]               0\n",
            "Conv2dStaticSamePadding-470          [-1, 272, 12, 12]         443,904\n",
            "     BatchNorm2d-471          [-1, 272, 12, 12]             544\n",
            "     MBConvBlock-472          [-1, 272, 12, 12]               0\n",
            "        Identity-473          [-1, 272, 12, 12]               0\n",
            "Conv2dStaticSamePadding-474         [-1, 1632, 12, 12]         443,904\n",
            "     BatchNorm2d-475         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-476         [-1, 1632, 12, 12]               0\n",
            "       ZeroPad2d-477         [-1, 1632, 16, 16]               0\n",
            "Conv2dStaticSamePadding-478         [-1, 1632, 12, 12]          40,800\n",
            "     BatchNorm2d-479         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-480         [-1, 1632, 12, 12]               0\n",
            "        Identity-481           [-1, 1632, 1, 1]               0\n",
            "Conv2dStaticSamePadding-482             [-1, 68, 1, 1]         111,044\n",
            "MemoryEfficientSwish-483             [-1, 68, 1, 1]               0\n",
            "        Identity-484             [-1, 68, 1, 1]               0\n",
            "Conv2dStaticSamePadding-485           [-1, 1632, 1, 1]         112,608\n",
            "        Identity-486         [-1, 1632, 12, 12]               0\n",
            "Conv2dStaticSamePadding-487          [-1, 272, 12, 12]         443,904\n",
            "     BatchNorm2d-488          [-1, 272, 12, 12]             544\n",
            "     MBConvBlock-489          [-1, 272, 12, 12]               0\n",
            "        Identity-490          [-1, 272, 12, 12]               0\n",
            "Conv2dStaticSamePadding-491         [-1, 1632, 12, 12]         443,904\n",
            "     BatchNorm2d-492         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-493         [-1, 1632, 12, 12]               0\n",
            "       ZeroPad2d-494         [-1, 1632, 16, 16]               0\n",
            "Conv2dStaticSamePadding-495         [-1, 1632, 12, 12]          40,800\n",
            "     BatchNorm2d-496         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-497         [-1, 1632, 12, 12]               0\n",
            "        Identity-498           [-1, 1632, 1, 1]               0\n",
            "Conv2dStaticSamePadding-499             [-1, 68, 1, 1]         111,044\n",
            "MemoryEfficientSwish-500             [-1, 68, 1, 1]               0\n",
            "        Identity-501             [-1, 68, 1, 1]               0\n",
            "Conv2dStaticSamePadding-502           [-1, 1632, 1, 1]         112,608\n",
            "        Identity-503         [-1, 1632, 12, 12]               0\n",
            "Conv2dStaticSamePadding-504          [-1, 272, 12, 12]         443,904\n",
            "     BatchNorm2d-505          [-1, 272, 12, 12]             544\n",
            "     MBConvBlock-506          [-1, 272, 12, 12]               0\n",
            "        Identity-507          [-1, 272, 12, 12]               0\n",
            "Conv2dStaticSamePadding-508         [-1, 1632, 12, 12]         443,904\n",
            "     BatchNorm2d-509         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-510         [-1, 1632, 12, 12]               0\n",
            "       ZeroPad2d-511         [-1, 1632, 14, 14]               0\n",
            "Conv2dStaticSamePadding-512         [-1, 1632, 12, 12]          14,688\n",
            "     BatchNorm2d-513         [-1, 1632, 12, 12]           3,264\n",
            "MemoryEfficientSwish-514         [-1, 1632, 12, 12]               0\n",
            "        Identity-515           [-1, 1632, 1, 1]               0\n",
            "Conv2dStaticSamePadding-516             [-1, 68, 1, 1]         111,044\n",
            "MemoryEfficientSwish-517             [-1, 68, 1, 1]               0\n",
            "        Identity-518             [-1, 68, 1, 1]               0\n",
            "Conv2dStaticSamePadding-519           [-1, 1632, 1, 1]         112,608\n",
            "        Identity-520         [-1, 1632, 12, 12]               0\n",
            "Conv2dStaticSamePadding-521          [-1, 448, 12, 12]         731,136\n",
            "     BatchNorm2d-522          [-1, 448, 12, 12]             896\n",
            "     MBConvBlock-523          [-1, 448, 12, 12]               0\n",
            "        Identity-524          [-1, 448, 12, 12]               0\n",
            "Conv2dStaticSamePadding-525         [-1, 2688, 12, 12]       1,204,224\n",
            "     BatchNorm2d-526         [-1, 2688, 12, 12]           5,376\n",
            "MemoryEfficientSwish-527         [-1, 2688, 12, 12]               0\n",
            "       ZeroPad2d-528         [-1, 2688, 14, 14]               0\n",
            "Conv2dStaticSamePadding-529         [-1, 2688, 12, 12]          24,192\n",
            "     BatchNorm2d-530         [-1, 2688, 12, 12]           5,376\n",
            "MemoryEfficientSwish-531         [-1, 2688, 12, 12]               0\n",
            "        Identity-532           [-1, 2688, 1, 1]               0\n",
            "Conv2dStaticSamePadding-533            [-1, 112, 1, 1]         301,168\n",
            "MemoryEfficientSwish-534            [-1, 112, 1, 1]               0\n",
            "        Identity-535            [-1, 112, 1, 1]               0\n",
            "Conv2dStaticSamePadding-536           [-1, 2688, 1, 1]         303,744\n",
            "        Identity-537         [-1, 2688, 12, 12]               0\n",
            "Conv2dStaticSamePadding-538          [-1, 448, 12, 12]       1,204,224\n",
            "     BatchNorm2d-539          [-1, 448, 12, 12]             896\n",
            "     MBConvBlock-540          [-1, 448, 12, 12]               0\n",
            "        Identity-541          [-1, 448, 12, 12]               0\n",
            "Conv2dStaticSamePadding-542         [-1, 1792, 12, 12]         802,816\n",
            "     BatchNorm2d-543         [-1, 1792, 12, 12]           3,584\n",
            "MemoryEfficientSwish-544         [-1, 1792, 12, 12]               0\n",
            "AdaptiveAvgPool2d-545           [-1, 1792, 1, 1]               0\n",
            "         Dropout-546                 [-1, 1792]               0\n",
            "          Linear-547                    [-1, 3]           5,379\n",
            "================================================================\n",
            "Total params: 17,553,995\n",
            "Trainable params: 17,553,995\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.65\n",
            "Forward/backward pass size (MB): 1542.03\n",
            "Params size (MB): 66.96\n",
            "Estimated Total Size (MB): 1610.65\n",
            "----------------------------------------------------------------\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Display the summary of the model\n",
        "\n",
        "print(tssum(model, input_size=(channels,dimension,dimension)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-k_-YPF6Ec0",
        "outputId": "9411e732-2d3e-4cf8-bce3-aedfc47ea8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "====================================================================================================\n",
            "Layer (type:depth-idx)                             Output Shape              Param #\n",
            "====================================================================================================\n",
            "EfficientNet                                       [20, 3]                   --\n",
            "Conv2dStaticSamePadding: 1-1                     [20, 48, 190, 190]        1,296\n",
            "    ZeroPad2d: 2-1                              [20, 3, 381, 381]         --\n",
            "BatchNorm2d: 1-2                                 [20, 48, 190, 190]        96\n",
            "MemoryEfficientSwish: 1-3                        [20, 48, 190, 190]        --\n",
            "ModuleList: 1-4                                  --                        --\n",
            "    MBConvBlock: 2-2                            [20, 24, 190, 190]        --\n",
            "        Conv2dStaticSamePadding: 3-1           [20, 48, 190, 190]        432\n",
            "        BatchNorm2d: 3-2                       [20, 48, 190, 190]        96\n",
            "        MemoryEfficientSwish: 3-3              [20, 48, 190, 190]        --\n",
            "        Conv2dStaticSamePadding: 3-4           [20, 12, 1, 1]            588\n",
            "        MemoryEfficientSwish: 3-5              [20, 12, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-6           [20, 48, 1, 1]            624\n",
            "        Conv2dStaticSamePadding: 3-7           [20, 24, 190, 190]        1,152\n",
            "        BatchNorm2d: 3-8                       [20, 24, 190, 190]        48\n",
            "    MBConvBlock: 2-3                            [20, 24, 190, 190]        --\n",
            "        Conv2dStaticSamePadding: 3-9           [20, 24, 190, 190]        216\n",
            "        BatchNorm2d: 3-10                      [20, 24, 190, 190]        48\n",
            "        MemoryEfficientSwish: 3-11             [20, 24, 190, 190]        --\n",
            "        Conv2dStaticSamePadding: 3-12          [20, 6, 1, 1]             150\n",
            "        MemoryEfficientSwish: 3-13             [20, 6, 1, 1]             --\n",
            "        Conv2dStaticSamePadding: 3-14          [20, 24, 1, 1]            168\n",
            "        Conv2dStaticSamePadding: 3-15          [20, 24, 190, 190]        576\n",
            "        BatchNorm2d: 3-16                      [20, 24, 190, 190]        48\n",
            "    MBConvBlock: 2-4                            [20, 32, 95, 95]          --\n",
            "        Conv2dStaticSamePadding: 3-17          [20, 144, 190, 190]       3,456\n",
            "        BatchNorm2d: 3-18                      [20, 144, 190, 190]       288\n",
            "        MemoryEfficientSwish: 3-19             [20, 144, 190, 190]       --\n",
            "        Conv2dStaticSamePadding: 3-20          [20, 144, 95, 95]         1,296\n",
            "        BatchNorm2d: 3-21                      [20, 144, 95, 95]         288\n",
            "        MemoryEfficientSwish: 3-22             [20, 144, 95, 95]         --\n",
            "        Conv2dStaticSamePadding: 3-23          [20, 6, 1, 1]             870\n",
            "        MemoryEfficientSwish: 3-24             [20, 6, 1, 1]             --\n",
            "        Conv2dStaticSamePadding: 3-25          [20, 144, 1, 1]           1,008\n",
            "        Conv2dStaticSamePadding: 3-26          [20, 32, 95, 95]          4,608\n",
            "        BatchNorm2d: 3-27                      [20, 32, 95, 95]          64\n",
            "    MBConvBlock: 2-5                            [20, 32, 95, 95]          --\n",
            "        Conv2dStaticSamePadding: 3-28          [20, 192, 95, 95]         6,144\n",
            "        BatchNorm2d: 3-29                      [20, 192, 95, 95]         384\n",
            "        MemoryEfficientSwish: 3-30             [20, 192, 95, 95]         --\n",
            "        Conv2dStaticSamePadding: 3-31          [20, 192, 95, 95]         1,728\n",
            "        BatchNorm2d: 3-32                      [20, 192, 95, 95]         384\n",
            "        MemoryEfficientSwish: 3-33             [20, 192, 95, 95]         --\n",
            "        Conv2dStaticSamePadding: 3-34          [20, 8, 1, 1]             1,544\n",
            "        MemoryEfficientSwish: 3-35             [20, 8, 1, 1]             --\n",
            "        Conv2dStaticSamePadding: 3-36          [20, 192, 1, 1]           1,728\n",
            "        Conv2dStaticSamePadding: 3-37          [20, 32, 95, 95]          6,144\n",
            "        BatchNorm2d: 3-38                      [20, 32, 95, 95]          64\n",
            "    MBConvBlock: 2-6                            [20, 32, 95, 95]          --\n",
            "        Conv2dStaticSamePadding: 3-39          [20, 192, 95, 95]         6,144\n",
            "        BatchNorm2d: 3-40                      [20, 192, 95, 95]         384\n",
            "        MemoryEfficientSwish: 3-41             [20, 192, 95, 95]         --\n",
            "        Conv2dStaticSamePadding: 3-42          [20, 192, 95, 95]         1,728\n",
            "        BatchNorm2d: 3-43                      [20, 192, 95, 95]         384\n",
            "        MemoryEfficientSwish: 3-44             [20, 192, 95, 95]         --\n",
            "        Conv2dStaticSamePadding: 3-45          [20, 8, 1, 1]             1,544\n",
            "        MemoryEfficientSwish: 3-46             [20, 8, 1, 1]             --\n",
            "        Conv2dStaticSamePadding: 3-47          [20, 192, 1, 1]           1,728\n",
            "        Conv2dStaticSamePadding: 3-48          [20, 32, 95, 95]          6,144\n",
            "        BatchNorm2d: 3-49                      [20, 32, 95, 95]          64\n",
            "    MBConvBlock: 2-7                            [20, 32, 95, 95]          --\n",
            "        Conv2dStaticSamePadding: 3-50          [20, 192, 95, 95]         6,144\n",
            "        BatchNorm2d: 3-51                      [20, 192, 95, 95]         384\n",
            "        MemoryEfficientSwish: 3-52             [20, 192, 95, 95]         --\n",
            "        Conv2dStaticSamePadding: 3-53          [20, 192, 95, 95]         1,728\n",
            "        BatchNorm2d: 3-54                      [20, 192, 95, 95]         384\n",
            "        MemoryEfficientSwish: 3-55             [20, 192, 95, 95]         --\n",
            "        Conv2dStaticSamePadding: 3-56          [20, 8, 1, 1]             1,544\n",
            "        MemoryEfficientSwish: 3-57             [20, 8, 1, 1]             --\n",
            "        Conv2dStaticSamePadding: 3-58          [20, 192, 1, 1]           1,728\n",
            "        Conv2dStaticSamePadding: 3-59          [20, 32, 95, 95]          6,144\n",
            "        BatchNorm2d: 3-60                      [20, 32, 95, 95]          64\n",
            "    MBConvBlock: 2-8                            [20, 56, 48, 48]          --\n",
            "        Conv2dStaticSamePadding: 3-61          [20, 192, 95, 95]         6,144\n",
            "        BatchNorm2d: 3-62                      [20, 192, 95, 95]         384\n",
            "        MemoryEfficientSwish: 3-63             [20, 192, 95, 95]         --\n",
            "        Conv2dStaticSamePadding: 3-64          [20, 192, 48, 48]         4,800\n",
            "        BatchNorm2d: 3-65                      [20, 192, 48, 48]         384\n",
            "        MemoryEfficientSwish: 3-66             [20, 192, 48, 48]         --\n",
            "        Conv2dStaticSamePadding: 3-67          [20, 8, 1, 1]             1,544\n",
            "        MemoryEfficientSwish: 3-68             [20, 8, 1, 1]             --\n",
            "        Conv2dStaticSamePadding: 3-69          [20, 192, 1, 1]           1,728\n",
            "        Conv2dStaticSamePadding: 3-70          [20, 56, 48, 48]          10,752\n",
            "        BatchNorm2d: 3-71                      [20, 56, 48, 48]          112\n",
            "    MBConvBlock: 2-9                            [20, 56, 48, 48]          --\n",
            "        Conv2dStaticSamePadding: 3-72          [20, 336, 48, 48]         18,816\n",
            "        BatchNorm2d: 3-73                      [20, 336, 48, 48]         672\n",
            "        MemoryEfficientSwish: 3-74             [20, 336, 48, 48]         --\n",
            "        Conv2dStaticSamePadding: 3-75          [20, 336, 48, 48]         8,400\n",
            "        BatchNorm2d: 3-76                      [20, 336, 48, 48]         672\n",
            "        MemoryEfficientSwish: 3-77             [20, 336, 48, 48]         --\n",
            "        Conv2dStaticSamePadding: 3-78          [20, 14, 1, 1]            4,718\n",
            "        MemoryEfficientSwish: 3-79             [20, 14, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-80          [20, 336, 1, 1]           5,040\n",
            "        Conv2dStaticSamePadding: 3-81          [20, 56, 48, 48]          18,816\n",
            "        BatchNorm2d: 3-82                      [20, 56, 48, 48]          112\n",
            "    MBConvBlock: 2-10                           [20, 56, 48, 48]          --\n",
            "        Conv2dStaticSamePadding: 3-83          [20, 336, 48, 48]         18,816\n",
            "        BatchNorm2d: 3-84                      [20, 336, 48, 48]         672\n",
            "        MemoryEfficientSwish: 3-85             [20, 336, 48, 48]         --\n",
            "        Conv2dStaticSamePadding: 3-86          [20, 336, 48, 48]         8,400\n",
            "        BatchNorm2d: 3-87                      [20, 336, 48, 48]         672\n",
            "        MemoryEfficientSwish: 3-88             [20, 336, 48, 48]         --\n",
            "        Conv2dStaticSamePadding: 3-89          [20, 14, 1, 1]            4,718\n",
            "        MemoryEfficientSwish: 3-90             [20, 14, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-91          [20, 336, 1, 1]           5,040\n",
            "        Conv2dStaticSamePadding: 3-92          [20, 56, 48, 48]          18,816\n",
            "        BatchNorm2d: 3-93                      [20, 56, 48, 48]          112\n",
            "    MBConvBlock: 2-11                           [20, 56, 48, 48]          --\n",
            "        Conv2dStaticSamePadding: 3-94          [20, 336, 48, 48]         18,816\n",
            "        BatchNorm2d: 3-95                      [20, 336, 48, 48]         672\n",
            "        MemoryEfficientSwish: 3-96             [20, 336, 48, 48]         --\n",
            "        Conv2dStaticSamePadding: 3-97          [20, 336, 48, 48]         8,400\n",
            "        BatchNorm2d: 3-98                      [20, 336, 48, 48]         672\n",
            "        MemoryEfficientSwish: 3-99             [20, 336, 48, 48]         --\n",
            "        Conv2dStaticSamePadding: 3-100         [20, 14, 1, 1]            4,718\n",
            "        MemoryEfficientSwish: 3-101            [20, 14, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-102         [20, 336, 1, 1]           5,040\n",
            "        Conv2dStaticSamePadding: 3-103         [20, 56, 48, 48]          18,816\n",
            "        BatchNorm2d: 3-104                     [20, 56, 48, 48]          112\n",
            "    MBConvBlock: 2-12                           [20, 112, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-105         [20, 336, 48, 48]         18,816\n",
            "        BatchNorm2d: 3-106                     [20, 336, 48, 48]         672\n",
            "        MemoryEfficientSwish: 3-107            [20, 336, 48, 48]         --\n",
            "        Conv2dStaticSamePadding: 3-108         [20, 336, 24, 24]         3,024\n",
            "        BatchNorm2d: 3-109                     [20, 336, 24, 24]         672\n",
            "        MemoryEfficientSwish: 3-110            [20, 336, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-111         [20, 14, 1, 1]            4,718\n",
            "        MemoryEfficientSwish: 3-112            [20, 14, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-113         [20, 336, 1, 1]           5,040\n",
            "        Conv2dStaticSamePadding: 3-114         [20, 112, 24, 24]         37,632\n",
            "        BatchNorm2d: 3-115                     [20, 112, 24, 24]         224\n",
            "    MBConvBlock: 2-13                           [20, 112, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-116         [20, 672, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-117                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-118            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-119         [20, 672, 24, 24]         6,048\n",
            "        BatchNorm2d: 3-120                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-121            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-122         [20, 28, 1, 1]            18,844\n",
            "        MemoryEfficientSwish: 3-123            [20, 28, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-124         [20, 672, 1, 1]           19,488\n",
            "        Conv2dStaticSamePadding: 3-125         [20, 112, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-126                     [20, 112, 24, 24]         224\n",
            "    MBConvBlock: 2-14                           [20, 112, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-127         [20, 672, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-128                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-129            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-130         [20, 672, 24, 24]         6,048\n",
            "        BatchNorm2d: 3-131                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-132            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-133         [20, 28, 1, 1]            18,844\n",
            "        MemoryEfficientSwish: 3-134            [20, 28, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-135         [20, 672, 1, 1]           19,488\n",
            "        Conv2dStaticSamePadding: 3-136         [20, 112, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-137                     [20, 112, 24, 24]         224\n",
            "    MBConvBlock: 2-15                           [20, 112, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-138         [20, 672, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-139                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-140            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-141         [20, 672, 24, 24]         6,048\n",
            "        BatchNorm2d: 3-142                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-143            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-144         [20, 28, 1, 1]            18,844\n",
            "        MemoryEfficientSwish: 3-145            [20, 28, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-146         [20, 672, 1, 1]           19,488\n",
            "        Conv2dStaticSamePadding: 3-147         [20, 112, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-148                     [20, 112, 24, 24]         224\n",
            "    MBConvBlock: 2-16                           [20, 112, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-149         [20, 672, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-150                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-151            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-152         [20, 672, 24, 24]         6,048\n",
            "        BatchNorm2d: 3-153                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-154            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-155         [20, 28, 1, 1]            18,844\n",
            "        MemoryEfficientSwish: 3-156            [20, 28, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-157         [20, 672, 1, 1]           19,488\n",
            "        Conv2dStaticSamePadding: 3-158         [20, 112, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-159                     [20, 112, 24, 24]         224\n",
            "    MBConvBlock: 2-17                           [20, 112, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-160         [20, 672, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-161                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-162            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-163         [20, 672, 24, 24]         6,048\n",
            "        BatchNorm2d: 3-164                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-165            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-166         [20, 28, 1, 1]            18,844\n",
            "        MemoryEfficientSwish: 3-167            [20, 28, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-168         [20, 672, 1, 1]           19,488\n",
            "        Conv2dStaticSamePadding: 3-169         [20, 112, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-170                     [20, 112, 24, 24]         224\n",
            "    MBConvBlock: 2-18                           [20, 160, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-171         [20, 672, 24, 24]         75,264\n",
            "        BatchNorm2d: 3-172                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-173            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-174         [20, 672, 24, 24]         16,800\n",
            "        BatchNorm2d: 3-175                     [20, 672, 24, 24]         1,344\n",
            "        MemoryEfficientSwish: 3-176            [20, 672, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-177         [20, 28, 1, 1]            18,844\n",
            "        MemoryEfficientSwish: 3-178            [20, 28, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-179         [20, 672, 1, 1]           19,488\n",
            "        Conv2dStaticSamePadding: 3-180         [20, 160, 24, 24]         107,520\n",
            "        BatchNorm2d: 3-181                     [20, 160, 24, 24]         320\n",
            "    MBConvBlock: 2-19                           [20, 160, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-182         [20, 960, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-183                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-184            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-185         [20, 960, 24, 24]         24,000\n",
            "        BatchNorm2d: 3-186                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-187            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-188         [20, 40, 1, 1]            38,440\n",
            "        MemoryEfficientSwish: 3-189            [20, 40, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-190         [20, 960, 1, 1]           39,360\n",
            "        Conv2dStaticSamePadding: 3-191         [20, 160, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-192                     [20, 160, 24, 24]         320\n",
            "    MBConvBlock: 2-20                           [20, 160, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-193         [20, 960, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-194                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-195            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-196         [20, 960, 24, 24]         24,000\n",
            "        BatchNorm2d: 3-197                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-198            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-199         [20, 40, 1, 1]            38,440\n",
            "        MemoryEfficientSwish: 3-200            [20, 40, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-201         [20, 960, 1, 1]           39,360\n",
            "        Conv2dStaticSamePadding: 3-202         [20, 160, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-203                     [20, 160, 24, 24]         320\n",
            "    MBConvBlock: 2-21                           [20, 160, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-204         [20, 960, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-205                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-206            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-207         [20, 960, 24, 24]         24,000\n",
            "        BatchNorm2d: 3-208                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-209            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-210         [20, 40, 1, 1]            38,440\n",
            "        MemoryEfficientSwish: 3-211            [20, 40, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-212         [20, 960, 1, 1]           39,360\n",
            "        Conv2dStaticSamePadding: 3-213         [20, 160, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-214                     [20, 160, 24, 24]         320\n",
            "    MBConvBlock: 2-22                           [20, 160, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-215         [20, 960, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-216                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-217            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-218         [20, 960, 24, 24]         24,000\n",
            "        BatchNorm2d: 3-219                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-220            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-221         [20, 40, 1, 1]            38,440\n",
            "        MemoryEfficientSwish: 3-222            [20, 40, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-223         [20, 960, 1, 1]           39,360\n",
            "        Conv2dStaticSamePadding: 3-224         [20, 160, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-225                     [20, 160, 24, 24]         320\n",
            "    MBConvBlock: 2-23                           [20, 160, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-226         [20, 960, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-227                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-228            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-229         [20, 960, 24, 24]         24,000\n",
            "        BatchNorm2d: 3-230                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-231            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-232         [20, 40, 1, 1]            38,440\n",
            "        MemoryEfficientSwish: 3-233            [20, 40, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-234         [20, 960, 1, 1]           39,360\n",
            "        Conv2dStaticSamePadding: 3-235         [20, 160, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-236                     [20, 160, 24, 24]         320\n",
            "    MBConvBlock: 2-24                           [20, 272, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-237         [20, 960, 24, 24]         153,600\n",
            "        BatchNorm2d: 3-238                     [20, 960, 24, 24]         1,920\n",
            "        MemoryEfficientSwish: 3-239            [20, 960, 24, 24]         --\n",
            "        Conv2dStaticSamePadding: 3-240         [20, 960, 12, 12]         24,000\n",
            "        BatchNorm2d: 3-241                     [20, 960, 12, 12]         1,920\n",
            "        MemoryEfficientSwish: 3-242            [20, 960, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-243         [20, 40, 1, 1]            38,440\n",
            "        MemoryEfficientSwish: 3-244            [20, 40, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-245         [20, 960, 1, 1]           39,360\n",
            "        Conv2dStaticSamePadding: 3-246         [20, 272, 12, 12]         261,120\n",
            "        BatchNorm2d: 3-247                     [20, 272, 12, 12]         544\n",
            "    MBConvBlock: 2-25                           [20, 272, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-248         [20, 1632, 12, 12]        443,904\n",
            "        BatchNorm2d: 3-249                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-250            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-251         [20, 1632, 12, 12]        40,800\n",
            "        BatchNorm2d: 3-252                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-253            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-254         [20, 68, 1, 1]            111,044\n",
            "        MemoryEfficientSwish: 3-255            [20, 68, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-256         [20, 1632, 1, 1]          112,608\n",
            "        Conv2dStaticSamePadding: 3-257         [20, 272, 12, 12]         443,904\n",
            "        BatchNorm2d: 3-258                     [20, 272, 12, 12]         544\n",
            "    MBConvBlock: 2-26                           [20, 272, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-259         [20, 1632, 12, 12]        443,904\n",
            "        BatchNorm2d: 3-260                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-261            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-262         [20, 1632, 12, 12]        40,800\n",
            "        BatchNorm2d: 3-263                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-264            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-265         [20, 68, 1, 1]            111,044\n",
            "        MemoryEfficientSwish: 3-266            [20, 68, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-267         [20, 1632, 1, 1]          112,608\n",
            "        Conv2dStaticSamePadding: 3-268         [20, 272, 12, 12]         443,904\n",
            "        BatchNorm2d: 3-269                     [20, 272, 12, 12]         544\n",
            "    MBConvBlock: 2-27                           [20, 272, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-270         [20, 1632, 12, 12]        443,904\n",
            "        BatchNorm2d: 3-271                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-272            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-273         [20, 1632, 12, 12]        40,800\n",
            "        BatchNorm2d: 3-274                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-275            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-276         [20, 68, 1, 1]            111,044\n",
            "        MemoryEfficientSwish: 3-277            [20, 68, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-278         [20, 1632, 1, 1]          112,608\n",
            "        Conv2dStaticSamePadding: 3-279         [20, 272, 12, 12]         443,904\n",
            "        BatchNorm2d: 3-280                     [20, 272, 12, 12]         544\n",
            "    MBConvBlock: 2-28                           [20, 272, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-281         [20, 1632, 12, 12]        443,904\n",
            "        BatchNorm2d: 3-282                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-283            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-284         [20, 1632, 12, 12]        40,800\n",
            "        BatchNorm2d: 3-285                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-286            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-287         [20, 68, 1, 1]            111,044\n",
            "        MemoryEfficientSwish: 3-288            [20, 68, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-289         [20, 1632, 1, 1]          112,608\n",
            "        Conv2dStaticSamePadding: 3-290         [20, 272, 12, 12]         443,904\n",
            "        BatchNorm2d: 3-291                     [20, 272, 12, 12]         544\n",
            "    MBConvBlock: 2-29                           [20, 272, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-292         [20, 1632, 12, 12]        443,904\n",
            "        BatchNorm2d: 3-293                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-294            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-295         [20, 1632, 12, 12]        40,800\n",
            "        BatchNorm2d: 3-296                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-297            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-298         [20, 68, 1, 1]            111,044\n",
            "        MemoryEfficientSwish: 3-299            [20, 68, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-300         [20, 1632, 1, 1]          112,608\n",
            "        Conv2dStaticSamePadding: 3-301         [20, 272, 12, 12]         443,904\n",
            "        BatchNorm2d: 3-302                     [20, 272, 12, 12]         544\n",
            "    MBConvBlock: 2-30                           [20, 272, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-303         [20, 1632, 12, 12]        443,904\n",
            "        BatchNorm2d: 3-304                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-305            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-306         [20, 1632, 12, 12]        40,800\n",
            "        BatchNorm2d: 3-307                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-308            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-309         [20, 68, 1, 1]            111,044\n",
            "        MemoryEfficientSwish: 3-310            [20, 68, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-311         [20, 1632, 1, 1]          112,608\n",
            "        Conv2dStaticSamePadding: 3-312         [20, 272, 12, 12]         443,904\n",
            "        BatchNorm2d: 3-313                     [20, 272, 12, 12]         544\n",
            "    MBConvBlock: 2-31                           [20, 272, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-314         [20, 1632, 12, 12]        443,904\n",
            "        BatchNorm2d: 3-315                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-316            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-317         [20, 1632, 12, 12]        40,800\n",
            "        BatchNorm2d: 3-318                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-319            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-320         [20, 68, 1, 1]            111,044\n",
            "        MemoryEfficientSwish: 3-321            [20, 68, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-322         [20, 1632, 1, 1]          112,608\n",
            "        Conv2dStaticSamePadding: 3-323         [20, 272, 12, 12]         443,904\n",
            "        BatchNorm2d: 3-324                     [20, 272, 12, 12]         544\n",
            "    MBConvBlock: 2-32                           [20, 448, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-325         [20, 1632, 12, 12]        443,904\n",
            "        BatchNorm2d: 3-326                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-327            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-328         [20, 1632, 12, 12]        14,688\n",
            "        BatchNorm2d: 3-329                     [20, 1632, 12, 12]        3,264\n",
            "        MemoryEfficientSwish: 3-330            [20, 1632, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-331         [20, 68, 1, 1]            111,044\n",
            "        MemoryEfficientSwish: 3-332            [20, 68, 1, 1]            --\n",
            "        Conv2dStaticSamePadding: 3-333         [20, 1632, 1, 1]          112,608\n",
            "        Conv2dStaticSamePadding: 3-334         [20, 448, 12, 12]         731,136\n",
            "        BatchNorm2d: 3-335                     [20, 448, 12, 12]         896\n",
            "    MBConvBlock: 2-33                           [20, 448, 12, 12]         --\n",
            "        Conv2dStaticSamePadding: 3-336         [20, 2688, 12, 12]        1,204,224\n",
            "        BatchNorm2d: 3-337                     [20, 2688, 12, 12]        5,376\n",
            "        MemoryEfficientSwish: 3-338            [20, 2688, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-339         [20, 2688, 12, 12]        24,192\n",
            "        BatchNorm2d: 3-340                     [20, 2688, 12, 12]        5,376\n",
            "        MemoryEfficientSwish: 3-341            [20, 2688, 12, 12]        --\n",
            "        Conv2dStaticSamePadding: 3-342         [20, 112, 1, 1]           301,168\n",
            "        MemoryEfficientSwish: 3-343            [20, 112, 1, 1]           --\n",
            "        Conv2dStaticSamePadding: 3-344         [20, 2688, 1, 1]          303,744\n",
            "        Conv2dStaticSamePadding: 3-345         [20, 448, 12, 12]         1,204,224\n",
            "        BatchNorm2d: 3-346                     [20, 448, 12, 12]         896\n",
            "Conv2dStaticSamePadding: 1-5                     [20, 1792, 12, 12]        802,816\n",
            "    Identity: 2-34                              [20, 448, 12, 12]         --\n",
            "BatchNorm2d: 1-6                                 [20, 1792, 12, 12]        3,584\n",
            "MemoryEfficientSwish: 1-7                        [20, 1792, 12, 12]        --\n",
            "AdaptiveAvgPool2d: 1-8                           [20, 1792, 1, 1]          --\n",
            "Dropout: 1-9                                     [20, 1792]                --\n",
            "Linear: 1-10                                     [20, 3]                   5,379\n",
            "====================================================================================================\n",
            "Total params: 17,553,995\n",
            "Trainable params: 17,553,995\n",
            "Non-trainable params: 0\n",
            "Total mult-adds (M): 2.61\n",
            "====================================================================================================\n",
            "Input size (MB): 34.66\n",
            "Forward/backward pass size (MB): 7913.44\n",
            "Params size (MB): 0.52\n",
            "Estimated Total Size (MB): 7948.62\n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "print(tisum(\\\n",
        "            model,\\\n",
        "            input_size = (batchsize,channels,dimension,dimension)\\\n",
        "            )\\\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "deZaBsqiLfdL"
      },
      "outputs": [],
      "source": [
        "learning_rate=1e-4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nGnCpmab6EaN"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "# lr_decay=0.99\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay = lr_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zFD8Yci36EXB"
      },
      "outputs": [],
      "source": [
        "history_accuracy=[]\n",
        "history_loss=[]\n",
        "epochs = 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_jig7wnMSXV"
      },
      "outputs": [],
      "source": [
        "#Create a class list\n",
        "\n",
        "# Creates standard basis\n",
        "eye = torch.eye(3).to(device)\n",
        "\n",
        "# Classes\n",
        "classes=[0,1,2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZHhYFcUwTle",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89761d06-d7e7-483b-c9bc-24546eb580ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "type(classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "df7RJ3u76EUO",
        "outputId": "5ae91d4e-9a83-4bf1-cd66-533077743107"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch :  1  Batch :  1  Loss :   1.1275027990341187  Accuracy :  0.25 Time  1.74 s\n",
            "Epoch :  1  Batch :  2  Loss :   1.126521348953247  Accuracy :  0.2 Time  1.01 s\n",
            "Epoch :  1  Batch :  3  Loss :   1.1017862955729167  Accuracy :  0.35 Time  1.04 s\n",
            "Epoch :  1  Batch :  4  Loss :   1.1014801859855652  Accuracy :  0.3625 Time  1.02 s\n",
            "Epoch :  1  Batch :  5  Loss :   1.0826392889022827  Accuracy :  0.4 Time  1.01 s\n",
            "Epoch :  1  Batch :  6  Loss :   1.063580224911372  Accuracy :  0.45 Time  1.0 s\n",
            "Epoch :  1  Batch :  7  Loss :   1.0604380794933863  Accuracy :  0.4857142857142857 Time  1.0 s\n",
            "Epoch :  1  Batch :  8  Loss :   1.053370364010334  Accuracy :  0.4875 Time  1.01 s\n",
            "Epoch :  1  Batch :  9  Loss :   1.0467714269955952  Accuracy :  0.5111111111111111 Time  1.01 s\n",
            "Epoch :  1  Batch :  10  Loss :   1.0357091844081878  Accuracy :  0.54 Time  1.0 s\n",
            "Epoch :  1  Batch :  11  Loss :   1.0242291417988865  Accuracy :  0.5727272727272728 Time  1.0 s\n",
            "Epoch :  1  Batch :  12  Loss :   1.0109592179457347  Accuracy :  0.5958333333333333 Time  1.0 s\n",
            "Epoch :  1  Batch :  13  Loss :   0.9992438371364887  Accuracy :  0.6153846153846154 Time  1.0 s\n",
            "Epoch :  1  Batch :  14  Loss :   0.9877892392022269  Accuracy :  0.6321428571428571 Time  1.02 s\n",
            "Epoch :  1  Batch :  15  Loss :   0.9726371526718139  Accuracy :  0.65 Time  1.02 s\n",
            "Epoch :  1  Batch :  16  Loss :   0.9645055830478668  Accuracy :  0.659375 Time  1.02 s\n",
            "Epoch :  1  Batch :  17  Loss :   0.9516262832809897  Accuracy :  0.6735294117647059 Time  1.01 s\n",
            "Epoch :  1  Batch :  18  Loss :   0.942460772063997  Accuracy :  0.6861111111111111 Time  1.03 s\n",
            "Epoch :  1  Batch :  19  Loss :   0.9344692261595475  Accuracy :  0.6921052631578948 Time  1.13 s\n",
            "Epoch :  1  Batch :  20  Loss :   0.9220411628484726  Accuracy :  0.705 Time  1.04 s\n",
            "Epoch :  1  Batch :  21  Loss :   0.9086686912037077  Accuracy :  0.7119047619047619 Time  1.02 s\n",
            "Epoch :  1  Batch :  22  Loss :   0.8938631252809004  Accuracy :  0.7227272727272728 Time  1.01 s\n",
            "Epoch :  1  Batch :  23  Loss :   0.8865340740784354  Accuracy :  0.7217391304347827 Time  1.01 s\n",
            "Epoch :  1  Batch :  24  Loss :   0.8724484443664551  Accuracy :  0.73125 Time  1.02 s\n",
            "Epoch :  1  Batch :  25  Loss :   0.8605027031898499  Accuracy :  0.74 Time  1.02 s\n",
            "Epoch :  1  Batch :  26  Loss :   0.8462518109725072  Accuracy :  0.7480769230769231 Time  1.04 s\n",
            "Epoch :  1  Batch :  27  Loss :   0.8356466911457203  Accuracy :  0.7518518518518519 Time  1.02 s\n",
            "Epoch :  1  Batch :  28  Loss :   0.8228080783571515  Accuracy :  0.7553571428571428 Time  1.01 s\n",
            "Epoch :  1  Batch :  29  Loss :   0.8135965425392677  Accuracy :  0.7586206896551724 Time  1.01 s\n",
            "Epoch :  1  Batch :  30  Loss :   0.8022594730059306  Accuracy :  0.7633333333333333 Time  1.01 s\n",
            "Epoch :  1  Batch :  31  Loss :   0.7900385327877537  Accuracy :  0.7693548387096775 Time  1.02 s\n",
            "Epoch :  1  Batch :  32  Loss :   0.7761112628504634  Accuracy :  0.7765625 Time  1.01 s\n",
            "Epoch :  1  Batch :  33  Loss :   0.7636397788018892  Accuracy :  0.7803030303030303 Time  1.02 s\n",
            "Epoch :  1  Batch :  34  Loss :   0.755209388978341  Accuracy :  0.7808823529411765 Time  1.02 s\n",
            "Epoch :  1  Batch :  35  Loss :   0.7429495062146868  Accuracy :  0.7842857142857143 Time  1.03 s\n",
            "Epoch :  1  Batch :  36  Loss :   0.7349749737315707  Accuracy :  0.7847222222222222 Time  1.02 s\n",
            "Epoch :  1  Batch :  37  Loss :   0.7236124671794273  Accuracy :  0.7891891891891892 Time  1.02 s\n",
            "Epoch :  1  Batch :  38  Loss :   0.7159430910097925  Accuracy :  0.7921052631578948 Time  1.02 s\n",
            "Epoch :  1  Batch :  39  Loss :   0.7048504918049543  Accuracy :  0.7961538461538461 Time  1.01 s\n",
            "Epoch :  1  Batch :  40  Loss :   0.6975300759077072  Accuracy :  0.8 Time  1.01 s\n",
            "Epoch :  1  Batch :  41  Loss :   0.6872859589937257  Accuracy :  0.802439024390244 Time  1.01 s\n",
            "Epoch :  1  Batch :  42  Loss :   0.6847310924813861  Accuracy :  0.8 Time  1.02 s\n",
            "Epoch :  1  Batch :  43  Loss :   0.6810155379217725  Accuracy :  0.7988372093023256 Time  1.01 s\n",
            "Epoch :  1  Batch :  44  Loss :   0.6743853078647093  Accuracy :  0.8 Time  1.02 s\n",
            "Epoch :  1  Batch :  45  Loss :   0.6636401851971944  Accuracy :  0.8044444444444444 Time  1.01 s\n",
            "Epoch :  1  Batch :  46  Loss :   0.6563799277595852  Accuracy :  0.8054347826086956 Time  1.03 s\n",
            "Epoch :  1  Batch :  47  Loss :   0.6546876354420439  Accuracy :  0.8053191489361702 Time  1.24 s\n",
            "Epoch :  1  Batch :  48  Loss :   0.6477739376326402  Accuracy :  0.8072916666666666 Time  1.03 s\n",
            "Epoch :  1  Batch :  49  Loss :   0.6374007551645746  Accuracy :  0.8112244897959183 Time  1.01 s\n",
            "Epoch :  1  Batch :  50  Loss :   0.629659716784954  Accuracy :  0.815 Time  1.02 s\n",
            "Epoch :  1  Batch :  51  Loss :   0.62359512173662  Accuracy :  0.8176470588235294 Time  1.02 s\n",
            "Epoch :  1  Batch :  52  Loss :   0.6191489544625466  Accuracy :  0.8182692307692307 Time  1.01 s\n",
            "Epoch :  1  Batch :  53  Loss :   0.6101161036288963  Accuracy :  0.8216981132075472 Time  1.01 s\n",
            "Epoch :  1  Batch :  54  Loss :   0.6011116049355931  Accuracy :  0.825 Time  1.02 s\n",
            "Epoch :  1  Batch :  55  Loss :   0.5932809388095682  Accuracy :  0.8272727272727273 Time  1.01 s\n",
            "Epoch :  1  Batch :  56  Loss :   0.5862456735755716  Accuracy :  0.8294642857142858 Time  1.02 s\n",
            "Epoch :  1  Batch :  57  Loss :   0.5789713009930494  Accuracy :  0.8307017543859649 Time  1.03 s\n",
            "Epoch :  1  Batch :  58  Loss :   0.5754812192814104  Accuracy :  0.8301724137931035 Time  1.04 s\n",
            "Epoch :  1  Batch :  59  Loss :   0.5695320986590143  Accuracy :  0.8313559322033899 Time  1.11 s\n",
            "Epoch :  1  Batch :  60  Loss :   0.5674303499360879  Accuracy :  0.8316666666666667 Time  1.11 s\n",
            "Epoch :  1  Batch :  61  Loss :   0.5622462007354517  Accuracy :  0.8319672131147541 Time  1.12 s\n",
            "Epoch :  1  Batch :  62  Loss :   0.5580538412736308  Accuracy :  0.8330645161290322 Time  1.05 s\n",
            "Epoch :  1  Batch :  63  Loss :   0.5519913316719116  Accuracy :  0.834920634920635 Time  1.02 s\n",
            "Epoch :  1  Batch :  64  Loss :   0.5473803007043898  Accuracy :  0.8359375 Time  1.02 s\n",
            "Epoch :  1  Batch :  65  Loss :   0.5439630801861103  Accuracy :  0.8369230769230769 Time  1.01 s\n",
            "Epoch :  1  Batch :  66  Loss :   0.5385019007054243  Accuracy :  0.8386363636363636 Time  1.02 s\n",
            "Epoch :  1  Batch :  67  Loss :   0.532249095279779  Accuracy :  0.841044776119403 Time  1.01 s\n",
            "Epoch :  1  Batch :  68  Loss :   0.5278279470170245  Accuracy :  0.8426470588235294 Time  1.03 s\n",
            "Epoch :  1  Batch :  69  Loss :   0.5262448446474214  Accuracy :  0.841304347826087 Time  1.03 s\n",
            "Epoch :  1  Batch :  70  Loss :   0.5232355913945607  Accuracy :  0.8421428571428572 Time  1.04 s\n",
            "Epoch :  1  Batch :  71  Loss :   0.5214840077178579  Accuracy :  0.8415492957746479 Time  1.02 s\n",
            "Epoch :  1  Batch :  72  Loss :   0.5188706297841337  Accuracy :  0.8423611111111111 Time  1.02 s\n",
            "Epoch :  1  Batch :  73  Loss :   0.5156617164611816  Accuracy :  0.8438356164383561 Time  1.02 s\n",
            "Epoch :  1  Batch :  74  Loss :   0.5105611329545846  Accuracy :  0.8452702702702702 Time  1.02 s\n",
            "Epoch :  1  Batch :  75  Loss :   0.5050604729851087  Accuracy :  0.8473333333333334 Time  1.01 s\n",
            "Epoch :  1  Batch :  76  Loss :   0.5005021451139137  Accuracy :  0.8486842105263158 Time  1.02 s\n",
            "Epoch :  1  Batch :  77  Loss :   0.4962443538106881  Accuracy :  0.85 Time  1.02 s\n",
            "Epoch :  1  Batch :  78  Loss :   0.4919807957724119  Accuracy :  0.8512820512820513 Time  1.02 s\n",
            "Epoch :  1  Batch :  79  Loss :   0.4877846011821228  Accuracy :  0.8531645569620253 Time  1.04 s\n",
            "Epoch :  1  Batch :  80  Loss :   0.4872509867884219  Accuracy :  0.8525 Time  1.05 s\n",
            "Epoch :  1  Batch :  81  Loss :   0.48239143036397886  Accuracy :  0.854320987654321 Time  1.03 s\n",
            "Epoch :  1  Batch :  82  Loss :   0.48069189643351046  Accuracy :  0.8542682926829268 Time  1.02 s\n",
            "Epoch :  1  Batch :  83  Loss :   0.4765477432723505  Accuracy :  0.8560240963855422 Time  1.02 s\n",
            "Epoch :  1  Batch :  84  Loss :   0.4723765840310426  Accuracy :  0.8577380952380952 Time  1.02 s\n",
            "Epoch :  1  Batch :  85  Loss :   0.47245708923129476  Accuracy :  0.8582352941176471 Time  1.02 s\n",
            "Epoch :  1  Batch :  86  Loss :   0.4682199188269848  Accuracy :  0.8598837209302326 Time  1.02 s\n",
            "Epoch :  1  Batch :  87  Loss :   0.4651204391286291  Accuracy :  0.860919540229885 Time  1.02 s\n",
            "Epoch :  1  Batch :  88  Loss :   0.4623519685966047  Accuracy :  0.8619318181818182 Time  1.02 s\n",
            "Epoch :  1  Batch :  89  Loss :   0.4590204841132914  Accuracy :  0.8629213483146068 Time  1.03 s\n",
            "Epoch :  1  Batch :  90  Loss :   0.45846363049414424  Accuracy :  0.8627777777777778 Time  1.03 s\n",
            "Epoch :  1  Batch :  91  Loss :   0.4546425950887439  Accuracy :  0.8642857142857143 Time  1.03 s\n",
            "Epoch :  1  Batch :  92  Loss :   0.45492176541491697  Accuracy :  0.8635869565217391 Time  1.05 s\n",
            "Epoch :  1  Batch :  93  Loss :   0.45118715285613975  Accuracy :  0.864516129032258 Time  1.03 s\n",
            "Epoch :  1  Batch :  94  Loss :   0.44776128787309566  Accuracy :  0.8659574468085106 Time  1.02 s\n",
            "Epoch :  1  Batch :  95  Loss :   0.4458592250158912  Accuracy :  0.8663157894736843 Time  1.02 s\n",
            "Epoch :  1  Batch :  96  Loss :   0.4422013081299762  Accuracy :  0.8677083333333333 Time  1.02 s\n",
            "Epoch :  1  Batch :  97  Loss :   0.4391575799774878  Accuracy :  0.8685567010309279 Time  1.02 s\n",
            "Epoch :  1  Batch :  98  Loss :   0.43616764308238515  Accuracy :  0.8698979591836735 Time  1.02 s\n",
            "Epoch :  1  Batch :  99  Loss :   0.4351462246191622  Accuracy :  0.8702020202020202 Time  1.02 s\n",
            "Epoch :  1  Batch :  100  Loss :   0.43484056830406187  Accuracy :  0.8695 Time  1.04 s\n",
            "Epoch :  1  Batch :  101  Loss :   0.4342619986227243  Accuracy :  0.8698019801980198 Time  1.07 s\n",
            "Epoch :  1  Batch :  102  Loss :   0.431880696877545  Accuracy :  0.8705882352941177 Time  1.07 s\n",
            "Epoch :  1  Batch :  103  Loss :   0.4282866100446113  Accuracy :  0.8718446601941747 Time  1.05 s\n",
            "Epoch :  1  Batch :  104  Loss :   0.42607254051388455  Accuracy :  0.8725961538461539 Time  1.04 s\n",
            "Epoch :  1  Batch :  105  Loss :   0.4253205089696816  Accuracy :  0.871904761904762 Time  1.02 s\n",
            "Epoch :  1  Batch :  106  Loss :   0.4229912136874671  Accuracy :  0.8721698113207547 Time  1.02 s\n",
            "Epoch :  1  Batch :  107  Loss :   0.4204955949474161  Accuracy :  0.8728971962616823 Time  1.02 s\n",
            "Epoch :  1  Batch :  108  Loss :   0.4181497934860764  Accuracy :  0.8731481481481481 Time  1.02 s\n",
            "Epoch :  1  Batch :  109  Loss :   0.4150530508967168  Accuracy :  0.8743119266055046 Time  1.03 s\n",
            "Epoch :  1  Batch :  110  Loss :   0.411861909350211  Accuracy :  0.8754545454545455 Time  1.03 s\n",
            "Epoch :  1  Batch :  111  Loss :   0.4093610929946105  Accuracy :  0.8761261261261262 Time  1.02 s\n",
            "Epoch :  1  Batch :  112  Loss :   0.40863687209119753  Accuracy :  0.8758928571428571 Time  1.02 s\n",
            "Epoch :  1  Batch :  113  Loss :   0.40609419085415066  Accuracy :  0.8761061946902655 Time  1.04 s\n",
            "Epoch :  1  Batch :  114  Loss :   0.40498909383620085  Accuracy :  0.8758771929824561 Time  1.05 s\n",
            "Epoch :  1  Batch :  115  Loss :   0.404614143041165  Accuracy :  0.8756521739130435 Time  1.04 s\n",
            "Epoch :  1  Batch :  116  Loss :   0.4038283462989433  Accuracy :  0.8754310344827586 Time  1.03 s\n",
            "Epoch :  1  Batch :  117  Loss :   0.40579268288535947  Accuracy :  0.8743589743589744 Time  1.02 s\n",
            "Epoch :  1  Batch :  118  Loss :   0.4026960137031846  Accuracy :  0.8754237288135593 Time  1.03 s\n",
            "Epoch :  1  Batch :  119  Loss :   0.4005151047926991  Accuracy :  0.8760504201680672 Time  1.02 s\n",
            "Epoch :  1  Batch :  120  Loss :   0.3977891637633244  Accuracy :  0.8770833333333333 Time  1.02 s\n",
            "Epoch :  1  Batch :  121  Loss :   0.3959335215574454  Accuracy :  0.8776859504132232 Time  1.03 s\n",
            "Epoch :  1  Batch :  122  Loss :   0.3938573859021312  Accuracy :  0.8782786885245901 Time  1.02 s\n",
            "Epoch :  1  Batch :  123  Loss :   0.39257845052374085  Accuracy :  0.8784552845528455 Time  1.02 s\n",
            "Epoch :  1  Batch :  124  Loss :   0.39369162520573986  Accuracy :  0.8778225806451613 Time  1.04 s\n",
            "Epoch :  1  Batch :  125  Loss :   0.3913480690717697  Accuracy :  0.8784 Time  1.04 s\n",
            "Epoch :  1  Batch :  126  Loss :   0.38999163087398286  Accuracy :  0.878968253968254 Time  1.04 s\n",
            "Epoch :  1  Batch :  127  Loss :   0.3894920513385863  Accuracy :  0.878740157480315 Time  1.03 s\n",
            "Epoch :  1  Batch :  128  Loss :   0.3881528046913445  Accuracy :  0.879296875 Time  1.03 s\n",
            "Epoch :  1  Batch :  129  Loss :   0.387612266133922  Accuracy :  0.8794573643410852 Time  1.03 s\n",
            "Epoch :  1  Batch :  130  Loss :   0.3855267732189252  Accuracy :  0.88 Time  1.02 s\n",
            "Epoch :  1  Batch :  131  Loss :   0.3834224829578218  Accuracy :  0.8805343511450382 Time  1.03 s\n",
            "Epoch :  1  Batch :  132  Loss :   0.3817586108026179  Accuracy :  0.8806818181818182 Time  1.03 s\n",
            "Epoch :  1  Batch :  133  Loss :   0.38056590027154835  Accuracy :  0.880827067669173 Time  1.03 s\n",
            "Epoch :  1  Batch :  134  Loss :   0.3783097563506062  Accuracy :  0.8817164179104477 Time  1.02 s\n",
            "Epoch :  1  Batch :  135  Loss :   0.37797089599900774  Accuracy :  0.8814814814814815 Time  1.03 s\n",
            "Epoch :  1  Batch :  136  Loss :   0.37649934306083355  Accuracy :  0.881985294117647 Time  1.03 s\n",
            "Epoch :  1  Batch :  137  Loss :   0.37461664484147605  Accuracy :  0.8828467153284671 Time  1.04 s\n",
            "Epoch :  1  Batch :  138  Loss :   0.3747653578394565  Accuracy :  0.8826086956521739 Time  1.03 s\n",
            "Epoch :  1  Batch :  139  Loss :   0.37321858220606396  Accuracy :  0.8827338129496403 Time  1.03 s\n",
            "Epoch :  1  Batch :  140  Loss :   0.37164199900414263  Accuracy :  0.8832142857142857 Time  1.02 s\n",
            "Epoch :  1  Batch :  141  Loss :   0.3701044051042685  Accuracy :  0.8836879432624114 Time  1.05 s\n",
            "Epoch :  1  Batch :  142  Loss :   0.3694057183891115  Accuracy :  0.8838028169014085 Time  1.04 s\n",
            "Epoch :  1  Batch :  143  Loss :   0.36716387243746046  Accuracy :  0.8846153846153846 Time  1.05 s\n",
            "Epoch :  1  Batch :  144  Loss :   0.366464894109716  Accuracy :  0.8847222222222222 Time  1.02 s\n",
            "Epoch :  1  Batch :  145  Loss :   0.3648661523543555  Accuracy :  0.8851724137931034 Time  1.02 s\n",
            "Epoch :  1  Batch :  146  Loss :   0.36328433214189254  Accuracy :  0.885958904109589 Time  1.05 s\n",
            "Epoch :  1  Batch :  147  Loss :   0.3618308373150371  Accuracy :  0.8863945578231293 Time  1.04 s\n",
            "Epoch :  1  Batch :  148  Loss :   0.3603274925435717  Accuracy :  0.8864864864864865 Time  1.04 s\n",
            "Epoch :  1  Batch :  149  Loss :   0.35847531119049  Accuracy :  0.887248322147651 Time  1.03 s\n",
            "Epoch :  1  Batch :  150  Loss :   0.35655566240350406  Accuracy :  0.888 Time  1.03 s\n",
            "Epoch :  1  Batch :  151  Loss :   0.3555512580749215  Accuracy :  0.8884105960264901 Time  1.15 s\n",
            "Epoch :  1  Batch :  152  Loss :   0.35514220717902245  Accuracy :  0.8881578947368421 Time  1.03 s\n",
            "Epoch :  1  Batch :  153  Loss :   0.35600149422104843  Accuracy :  0.8875816993464052 Time  1.03 s\n",
            "Epoch :  1  Batch :  154  Loss :   0.35388935462559584  Accuracy :  0.8883116883116883 Time  1.03 s\n",
            "Epoch :  1  Batch :  155  Loss :   0.35194671825776175  Accuracy :  0.8890322580645161 Time  1.02 s\n",
            "Epoch :  1  Batch :  156  Loss :   0.35033282378497416  Accuracy :  0.8897435897435897 Time  1.03 s\n",
            "Epoch :  1  Batch :  157  Loss :   0.34947938342715146  Accuracy :  0.8898089171974523 Time  1.05 s\n",
            "Epoch :  1  Batch :  158  Loss :   0.34870014791200055  Accuracy :  0.8901898734177215 Time  1.04 s\n",
            "Epoch :  1  Batch :  159  Loss :   0.3478835908192321  Accuracy :  0.8905660377358491 Time  1.06 s\n",
            "Epoch :  1  Batch :  160  Loss :   0.34820758652640504  Accuracy :  0.890625 Time  1.03 s\n",
            "Epoch :  1  Batch :  161  Loss :   0.34647759733872013  Accuracy :  0.8913043478260869 Time  1.03 s\n",
            "Epoch :  1  Batch :  162  Loss :   0.34577520047946847  Accuracy :  0.891358024691358 Time  1.03 s\n",
            "Epoch :  1  Batch :  163  Loss :   0.3440118955299715  Accuracy :  0.8920245398773006 Time  1.03 s\n",
            "Epoch :  1  Batch :  164  Loss :   0.34367753096242865  Accuracy :  0.8923780487804878 Time  1.02 s\n",
            "Epoch :  1  Batch :  165  Loss :   0.3427177403347962  Accuracy :  0.8927272727272727 Time  1.03 s\n",
            "Epoch :  1  Batch :  166  Loss :   0.3418747357552849  Accuracy :  0.8930722891566265 Time  1.03 s\n",
            "Epoch :  1  Batch :  167  Loss :   0.34058838996835455  Accuracy :  0.8934131736526946 Time  1.03 s\n",
            "Epoch :  1  Batch :  168  Loss :   0.3400155818865945  Accuracy :  0.89375 Time  1.05 s\n",
            "Epoch :  1  Batch :  169  Loss :   0.33842493354524733  Accuracy :  0.894378698224852 Time  1.04 s\n",
            "Epoch :  1  Batch :  170  Loss :   0.33706988287980066  Accuracy :  0.895 Time  1.04 s\n",
            "Epoch :  1  Batch :  171  Loss :   0.33528009045063056  Accuracy :  0.8956140350877193 Time  1.02 s\n",
            "Epoch :  1  Batch :  172  Loss :   0.3352195534443613  Accuracy :  0.895639534883721 Time  1.03 s\n",
            "Epoch :  1  Batch :  173  Loss :   0.3342545110560049  Accuracy :  0.8959537572254336 Time  1.03 s\n",
            "Epoch :  1  Batch :  174  Loss :   0.33276698139935046  Accuracy :  0.896551724137931 Time  1.02 s\n",
            "Epoch :  1  Batch :  175  Loss :   0.33173047058284283  Accuracy :  0.8968571428571429 Time  1.03 s\n",
            "Epoch :  1  Batch :  176  Loss :   0.33032061059070245  Accuracy :  0.8974431818181818 Time  1.03 s\n",
            "Epoch :  1  Batch :  177  Loss :   0.3291325909374966  Accuracy :  0.8977401129943503 Time  1.03 s\n",
            "Epoch :  1  Batch :  178  Loss :   0.32808468508628313  Accuracy :  0.8977528089887641 Time  1.03 s\n",
            "Epoch :  1  Batch :  179  Loss :   0.32677720696275125  Accuracy :  0.8983240223463688 Time  1.04 s\n",
            "Epoch :  1  Batch :  180  Loss :   0.3254195409619974  Accuracy :  0.8986111111111111 Time  1.04 s\n",
            "Epoch :  1  Batch :  181  Loss :   0.3246784474577199  Accuracy :  0.8986187845303868 Time  1.04 s\n",
            "Epoch :  1  Batch :  182  Loss :   0.3233427984312504  Accuracy :  0.8991758241758242 Time  1.04 s\n",
            "Epoch :  1  Batch :  183  Loss :   0.3219838293951229  Accuracy :  0.8997267759562841 Time  1.04 s\n",
            "Epoch :  1  Batch :  184  Loss :   0.32128866600966  Accuracy :  0.8997282608695653 Time  1.04 s\n",
            "Epoch :  1  Batch :  185  Loss :   0.3210460145831914  Accuracy :  0.8991891891891892 Time  1.03 s\n",
            "Epoch :  1  Batch :  186  Loss :   0.31959984925205026  Accuracy :  0.8994623655913978 Time  1.03 s\n",
            "Epoch :  1  Batch :  187  Loss :   0.31888171864105735  Accuracy :  0.8997326203208557 Time  1.03 s\n",
            "Epoch :  1  Batch :  188  Loss :   0.31826557243797693  Accuracy :  0.9 Time  1.03 s\n",
            "Epoch :  1  Batch :  189  Loss :   0.3175901123396461  Accuracy :  0.9002645502645502 Time  1.03 s\n",
            "Epoch :  1  Batch :  190  Loss :   0.31620198528429394  Accuracy :  0.9007894736842105 Time  1.04 s\n",
            "Epoch :  1  Batch :  191  Loss :   0.31485530243533133  Accuracy :  0.9013089005235602 Time  1.04 s\n",
            "Epoch :  1  Batch :  192  Loss :   0.3139397360015816  Accuracy :  0.9015625 Time  1.03 s\n",
            "Epoch :  1  Batch :  193  Loss :   0.31289162039949797  Accuracy :  0.9018134715025907 Time  1.03 s\n",
            "Epoch :  1  Batch :  194  Loss :   0.3118795485706213  Accuracy :  0.9020618556701031 Time  1.03 s\n",
            "Epoch :  1  Batch :  195  Loss :   0.311106824540557  Accuracy :  0.9023076923076923 Time  1.03 s\n",
            "Epoch :  1  Batch :  196  Loss :   0.31024704270102843  Accuracy :  0.9025510204081633 Time  1.03 s\n",
            "Epoch :  1  Batch :  197  Loss :   0.30907126562433496  Accuracy :  0.9027918781725889 Time  1.03 s\n",
            "Epoch :  1  Batch :  198  Loss :   0.3083014590289406  Accuracy :  0.9027777777777778 Time  1.03 s\n",
            "Epoch :  1  Batch :  199  Loss :   0.30775277111585714  Accuracy :  0.9027638190954774 Time  1.03 s\n",
            "Epoch :  1  Batch :  200  Loss :   0.30683537875302136  Accuracy :  0.903 Time  1.03 s\n",
            "Epoch :  1  Batch :  201  Loss :   0.30621689377324796  Accuracy :  0.9032338308457711 Time  1.05 s\n",
            "Epoch :  1  Batch :  202  Loss :   0.30562349332330546  Accuracy :  0.9034653465346535 Time  1.04 s\n",
            "Epoch :  1  Batch :  203  Loss :   0.304489115968787  Accuracy :  0.9039408866995073 Time  1.04 s\n",
            "Epoch :  1  Batch :  204  Loss :   0.30319734607074483  Accuracy :  0.9044117647058824 Time  1.03 s\n",
            "Epoch :  1  Batch :  205  Loss :   0.3048041828067564  Accuracy :  0.904390243902439 Time  1.03 s\n",
            "Epoch :  1  Batch :  206  Loss :   0.30357844652879296  Accuracy :  0.9048543689320389 Time  1.03 s\n",
            "Epoch :  1  Batch :  207  Loss :   0.30231972793702055  Accuracy :  0.9053140096618357 Time  1.03 s\n",
            "Epoch :  1  Batch :  208  Loss :   0.3010480322498971  Accuracy :  0.9057692307692308 Time  1.03 s\n",
            "Epoch :  1  Batch :  209  Loss :   0.3001228494560747  Accuracy :  0.9062200956937799 Time  1.03 s\n",
            "Epoch :  1  Batch :  210  Loss :   0.2988546671168435  Accuracy :  0.9066666666666666 Time  1.03 s\n",
            "Epoch :  1  Batch :  211  Loss :   0.29840220478297125  Accuracy :  0.9066350710900474 Time  1.03 s\n",
            "Epoch :  1  Batch :  212  Loss :   0.298397037385137  Accuracy :  0.9068396226415094 Time  1.04 s\n",
            "Epoch :  1  Batch :  213  Loss :   0.29853700516754195  Accuracy :  0.9070422535211268 Time  1.04 s\n",
            "Epoch :  1  Batch :  214  Loss :   0.2977533617848966  Accuracy :  0.9070093457943925 Time  1.05 s\n",
            "Epoch :  1  Batch :  215  Loss :   0.2966445980810149  Accuracy :  0.9074418604651163 Time  1.03 s\n",
            "Epoch :  1  Batch :  216  Loss :   0.2953696335338194  Accuracy :  0.9078703703703703 Time  1.03 s\n",
            "Epoch :  1  Batch :  217  Loss :   0.2948164854988387  Accuracy :  0.9078341013824884 Time  1.03 s\n",
            "Epoch :  1  Batch :  218  Loss :   0.29496619312964173  Accuracy :  0.9077981651376147 Time  1.03 s\n",
            "Epoch :  1  Batch :  219  Loss :   0.2946359751550438  Accuracy :  0.9077625570776255 Time  1.03 s\n",
            "Epoch :  1  Batch :  220  Loss :   0.2948333024555309  Accuracy :  0.9072727272727272 Time  1.03 s\n",
            "Epoch :  1  Batch :  221  Loss :   0.2948611896080534  Accuracy :  0.9070135746606335 Time  1.03 s\n",
            "Epoch :  1  Batch :  222  Loss :   0.2939228336536535  Accuracy :  0.9072072072072072 Time  1.03 s\n",
            "Epoch :  1  Batch :  223  Loss :   0.29432637250309834  Accuracy :  0.9069506726457399 Time  1.05 s\n",
            "Epoch :  1  Batch :  224  Loss :   0.29330557570626425  Accuracy :  0.9071428571428571 Time  1.06 s\n",
            "Epoch :  1  Batch :  225  Loss :   0.2933674022803704  Accuracy :  0.9071111111111111 Time  1.04 s\n",
            "Epoch :  1  Batch :  226  Loss :   0.2934046235941021  Accuracy :  0.9070796460176991 Time  1.05 s\n",
            "Epoch :  1  Batch :  227  Loss :   0.29269951042854575  Accuracy :  0.9072687224669603 Time  1.04 s\n",
            "Epoch :  1  Batch :  228  Loss :   0.2922132762818875  Accuracy :  0.9074561403508772 Time  1.04 s\n",
            "Epoch :  1  Batch :  229  Loss :   0.2911816274901795  Accuracy :  0.9078602620087336 Time  1.04 s\n",
            "Epoch :  1  Batch :  230  Loss :   0.2901995512211452  Accuracy :  0.9082608695652173 Time  1.03 s\n",
            "Epoch :  1  Batch :  231  Loss :   0.2890446758889533  Accuracy :  0.9086580086580086 Time  1.03 s\n",
            "Epoch :  1  Batch :  232  Loss :   0.28879275506940383  Accuracy :  0.9086206896551724 Time  1.03 s\n",
            "Epoch :  1  Batch :  233  Loss :   0.28776110929353044  Accuracy :  0.9090128755364807 Time  1.03 s\n",
            "Epoch :  1  Batch :  234  Loss :   0.2870130132979307  Accuracy :  0.9091880341880342 Time  1.03 s\n",
            "Epoch :  1  Batch :  235  Loss :   0.28624478042759793  Accuracy :  0.9093617021276595 Time  1.05 s\n",
            "Epoch :  1  Batch :  236  Loss :   0.28559739114243093  Accuracy :  0.9095338983050848 Time  1.04 s\n",
            "Epoch :  1  Batch :  237  Loss :   0.2864445930480454  Accuracy :  0.9092827004219409 Time  1.19 s\n",
            "Epoch :  1  Batch :  238  Loss :   0.28628579073217736  Accuracy :  0.9090336134453781 Time  1.03 s\n",
            "Epoch :  1  Batch :  239  Loss :   0.2858604471740862  Accuracy :  0.909205020920502 Time  1.03 s\n",
            "Epoch :  1  Batch :  240  Loss :   0.2848327167642613  Accuracy :  0.9095833333333333 Time  1.04 s\n",
            "Epoch :  1  Batch :  241  Loss :   0.28493346221343113  Accuracy :  0.9095435684647303 Time  1.02 s\n",
            "Epoch :  1  Batch :  242  Loss :   0.28421288402366246  Accuracy :  0.9097107438016528 Time  1.03 s\n",
            "Epoch :  1  Batch :  243  Loss :   0.283650375504062  Accuracy :  0.9098765432098765 Time  1.03 s\n",
            "Epoch :  1  Batch :  244  Loss :   0.2827388213214571  Accuracy :  0.9102459016393443 Time  1.03 s\n",
            "Epoch :  1  Batch :  245  Loss :   0.28191507180430453  Accuracy :  0.9104081632653062 Time  1.03 s\n",
            "Epoch :  1  Batch :  246  Loss :   0.2810021648259182  Accuracy :  0.9107723577235772 Time  1.04 s\n",
            "Epoch :  1  Batch :  247  Loss :   0.28096057646549666  Accuracy :  0.9107287449392713 Time  1.04 s\n",
            "Epoch :  1  Batch :  248  Loss :   0.28013604738178755  Accuracy :  0.9110887096774194 Time  1.05 s\n",
            "Epoch :  1  Batch :  249  Loss :   0.27910345276615706  Accuracy :  0.9114457831325301 Time  1.03 s\n",
            "Epoch :  1  Batch :  250  Loss :   0.2785143314450979  Accuracy :  0.9116 Time  1.03 s\n",
            "Epoch :  1  Batch :  251  Loss :   0.2776605685007762  Accuracy :  0.9119521912350598 Time  1.03 s\n",
            "Epoch :  1  Batch :  252  Loss :   0.2780504070429338  Accuracy :  0.9117063492063492 Time  1.03 s\n",
            "Epoch :  1  Batch :  253  Loss :   0.27875338310721837  Accuracy :  0.9112648221343873 Time  1.03 s\n",
            "Epoch :  1  Batch :  254  Loss :   0.2779892779094732  Accuracy :  0.9116141732283465 Time  1.03 s\n",
            "Epoch :  1  Batch :  255  Loss :   0.2771537193918929  Accuracy :  0.9119607843137255 Time  1.03 s\n",
            "Epoch :  1  Batch :  256  Loss :   0.2763621446938487  Accuracy :  0.9123046875 Time  1.03 s\n",
            "Epoch :  1  Batch :  257  Loss :   0.27585731361220783  Accuracy :  0.9124513618677043 Time  1.04 s\n",
            "Epoch :  1  Batch :  258  Loss :   0.27525871753865894  Accuracy :  0.9125968992248062 Time  1.04 s\n",
            "Epoch :  1  Batch :  259  Loss :   0.2744800375494027  Accuracy :  0.9129343629343629 Time  1.05 s\n",
            "Epoch :  1  Batch :  260  Loss :   0.27398822142814216  Accuracy :  0.9130769230769231 Time  1.03 s\n",
            "Epoch :  1  Batch :  261  Loss :   0.2731576191254274  Accuracy :  0.9134099616858238 Time  1.03 s\n",
            "Epoch :  1  Batch :  262  Loss :   0.27226148865662003  Accuracy :  0.9137404580152672 Time  1.04 s\n",
            "Epoch :  1  Batch :  263  Loss :   0.27236088771840467  Accuracy :  0.9134980988593155 Time  1.03 s\n",
            "Epoch :  1  Batch :  264  Loss :   0.27163764539485175  Accuracy :  0.9138257575757576 Time  1.03 s\n",
            "Epoch :  1  Batch :  265  Loss :   0.2708318108517044  Accuracy :  0.9141509433962264 Time  1.03 s\n",
            "Epoch :  1  Batch :  266  Loss :   0.27001384257766087  Accuracy :  0.9144736842105263 Time  1.04 s\n",
            "Epoch :  1  Batch :  267  Loss :   0.2693686186569684  Accuracy :  0.9147940074906367 Time  1.05 s\n",
            "Epoch :  1  Batch :  268  Loss :   0.269041584429345  Accuracy :  0.9151119402985075 Time  1.05 s\n",
            "Epoch :  1  Batch :  269  Loss :   0.26891223032401396  Accuracy :  0.9148698884758364 Time  1.06 s\n",
            "Epoch :  1  Batch :  270  Loss :   0.26804928967246305  Accuracy :  0.9151851851851852 Time  1.05 s\n",
            "Epoch :  1  Batch :  271  Loss :   0.2673330801604419  Accuracy :  0.9153136531365313 Time  1.03 s\n",
            "Epoch :  1  Batch :  272  Loss :   0.2668995305293185  Accuracy :  0.9152573529411765 Time  1.03 s\n",
            "Epoch :  1  Batch :  273  Loss :   0.2661840605375531  Accuracy :  0.9153846153846154 Time  1.03 s\n",
            "Epoch :  1  Batch :  274  Loss :   0.2654359964721829  Accuracy :  0.9156934306569343 Time  1.03 s\n",
            "Epoch :  1  Batch :  275  Loss :   0.26477683080868286  Accuracy :  0.9158181818181819 Time  1.03 s\n",
            "Epoch :  1  Batch :  276  Loss :   0.2638764595410422  Accuracy :  0.9161231884057971 Time  1.03 s\n",
            "Epoch :  1  Batch :  277  Loss :   0.2633231235096493  Accuracy :  0.916245487364621 Time  1.03 s\n",
            "Epoch :  1  Batch :  278  Loss :   0.2625051073582588  Accuracy :  0.9165467625899281 Time  1.03 s\n",
            "Epoch :  1  Batch :  279  Loss :   0.26178107953440116  Accuracy :  0.9168458781362007 Time  1.04 s\n",
            "Epoch :  1  Batch :  280  Loss :   0.2610599634836295  Accuracy :  0.9171428571428571 Time  1.05 s\n",
            "Epoch :  1  Batch :  281  Loss :   0.2602728287162412  Accuracy :  0.9174377224199288 Time  1.05 s\n",
            "Epoch :  1  Batch :  282  Loss :   0.2595872587940477  Accuracy :  0.9175531914893617 Time  1.03 s\n",
            "Epoch :  1  Batch :  283  Loss :   0.25895228392901987  Accuracy :  0.9176678445229682 Time  1.04 s\n",
            "Epoch :  1  Batch :  284  Loss :   0.25833824188382903  Accuracy :  0.9177816901408451 Time  1.04 s\n",
            "Epoch :  1  Batch :  285  Loss :   0.2582832731764045  Accuracy :  0.9178947368421052 Time  1.04 s\n",
            "Epoch :  1  Batch :  286  Loss :   0.2581488502153254  Accuracy :  0.9178321678321678 Time  1.03 s\n",
            "Epoch :  1  Batch :  287  Loss :   0.25759365324592964  Accuracy :  0.9181184668989547 Time  1.03 s\n",
            "Epoch :  1  Batch :  288  Loss :   0.2567866852752761  Accuracy :  0.9184027777777778 Time  1.03 s\n",
            "Epoch :  1  Batch :  289  Loss :   0.2568360304582387  Accuracy :  0.9183391003460207 Time  1.03 s\n",
            "Epoch :  1  Batch :  290  Loss :   0.2559916817904289  Accuracy :  0.9186206896551724 Time  1.04 s\n",
            "Epoch :  1  Batch :  291  Loss :   0.25570001793366015  Accuracy :  0.9187285223367697 Time  1.05 s\n",
            "Epoch :  1  Batch :  292  Loss :   0.2553378567067677  Accuracy :  0.9188356164383562 Time  1.07 s\n",
            "Epoch :  1  Batch :  293  Loss :   0.2552204152391175  Accuracy :  0.9189419795221843 Time  1.03 s\n",
            "Epoch :  1  Batch :  294  Loss :   0.2546349165511324  Accuracy :  0.919047619047619 Time  1.03 s\n",
            "Epoch :  1  Batch :  295  Loss :   0.25404575090476517  Accuracy :  0.9193220338983051 Time  1.03 s\n",
            "Epoch :  1  Batch :  296  Loss :   0.2534012211002158  Accuracy :  0.9194256756756757 Time  1.03 s\n",
            "Epoch :  1  Batch :  297  Loss :   0.25334170229595016  Accuracy :  0.9195286195286195 Time  1.03 s\n",
            "Epoch :  1  Batch :  298  Loss :   0.2525969176778207  Accuracy :  0.9197986577181209 Time  1.04 s\n",
            "Epoch :  1  Batch :  299  Loss :   0.25184007824077753  Accuracy :  0.920066889632107 Time  1.04 s\n",
            "Epoch :  1  Batch :  300  Loss :   0.25125884726954  Accuracy :  0.9203333333333333 Time  1.04 s\n",
            "Epoch :  1  Batch :  301  Loss :   0.2506010961870468  Accuracy :  0.9205980066445183 Time  1.05 s\n",
            "Epoch :  1  Batch :  302  Loss :   0.2498032683629962  Accuracy :  0.9208609271523179 Time  1.05 s\n",
            "Epoch :  1  Batch :  303  Loss :   0.24950024525545808  Accuracy :  0.920957095709571 Time  1.05 s\n",
            "Epoch :  1  Batch :  304  Loss :   0.24883170231662102  Accuracy :  0.9212171052631579 Time  1.04 s\n",
            "Epoch :  1  Batch :  305  Loss :   0.24814722087906033  Accuracy :  0.9214754098360656 Time  1.03 s\n",
            "Epoch :  1  Batch :  306  Loss :   0.24762255369131667  Accuracy :  0.9215686274509803 Time  1.03 s\n",
            "Epoch :  1  Batch :  307  Loss :   0.247148427123307  Accuracy :  0.9216612377850163 Time  1.04 s\n",
            "Epoch :  1  Batch :  308  Loss :   0.24732585446667169  Accuracy :  0.9214285714285714 Time  1.05 s\n",
            "Epoch :  1  Batch :  309  Loss :   0.24664598857097833  Accuracy :  0.9216828478964402 Time  1.05 s\n",
            "Epoch :  1  Batch :  310  Loss :   0.24593251953802764  Accuracy :  0.9219354838709677 Time  1.03 s\n",
            "Epoch :  1  Batch :  311  Loss :   0.24535307341473853  Accuracy :  0.9221864951768489 Time  1.04 s\n",
            "Epoch :  1  Batch :  312  Loss :   0.24470951234420332  Accuracy :  0.9224358974358975 Time  1.04 s\n",
            "Epoch :  1  Batch :  313  Loss :   0.2440440245270253  Accuracy :  0.9226837060702875 Time  1.04 s\n",
            "Epoch :  1  Batch :  314  Loss :   0.24424751282663673  Accuracy :  0.9226114649681528 Time  1.05 s\n",
            "Epoch :  1  Batch :  315  Loss :   0.2438984926671736  Accuracy :  0.9226984126984127 Time  1.04 s\n",
            "Epoch :  1  Batch :  316  Loss :   0.24357311837257276  Accuracy :  0.9227848101265823 Time  1.03 s\n",
            "Epoch :  1  Batch :  317  Loss :   0.242915566616959  Accuracy :  0.9230283911671924 Time  1.03 s\n",
            "Epoch :  1  Batch :  318  Loss :   0.2425541404177839  Accuracy :  0.9231132075471699 Time  1.03 s\n",
            "Epoch :  1  Batch :  319  Loss :   0.241939325895756  Accuracy :  0.9233542319749216 Time  1.03 s\n",
            "Epoch :  1  Batch :  320  Loss :   0.24179018420982173  Accuracy :  0.92328125 Time  1.03 s\n",
            "Epoch :  1  Batch :  321  Loss :   0.24186156854335206  Accuracy :  0.9233644859813084 Time  1.03 s\n",
            "Epoch :  1  Batch :  322  Loss :   0.24138750487024555  Accuracy :  0.9234472049689441 Time  1.03 s\n",
            "Epoch :  1  Batch :  323  Loss :   0.24082108251981138  Accuracy :  0.9235294117647059 Time  1.05 s\n",
            "Epoch :  1  Batch :  324  Loss :   0.2408381132926378  Accuracy :  0.9236111111111112 Time  1.05 s\n",
            "Epoch :  1  Batch :  325  Loss :   0.2401419820263982  Accuracy :  0.9238461538461539 Time  1.06 s\n",
            "Epoch :  1  Batch :  326  Loss :   0.23973659762221336  Accuracy :  0.9239263803680982 Time  1.03 s\n",
            "Epoch :  1  Batch :  327  Loss :   0.23914212511641625  Accuracy :  0.924006116207951 Time  1.03 s\n",
            "Epoch :  1  Batch :  328  Loss :   0.23878013641607562  Accuracy :  0.9242378048780487 Time  1.03 s\n",
            "Epoch :  1  Batch :  329  Loss :   0.23824240975251768  Accuracy :  0.9243161094224924 Time  1.03 s\n",
            "Epoch :  1  Batch :  330  Loss :   0.2379337382728629  Accuracy :  0.9243939393939394 Time  1.03 s\n",
            "Epoch :  1  Batch :  331  Loss :   0.2374207270655252  Accuracy :  0.9246223564954683 Time  1.04 s\n",
            "Epoch :  1  Batch :  332  Loss :   0.23679726039261434  Accuracy :  0.9248493975903614 Time  1.04 s\n",
            "Epoch :  1  Batch :  333  Loss :   0.2361076845544147  Accuracy :  0.925075075075075 Time  1.03 s\n",
            "Epoch :  1  Batch :  334  Loss :   0.23543777626041257  Accuracy :  0.9252994011976048 Time  1.05 s\n",
            "Epoch :  1  Batch :  335  Loss :   0.2354423813104852  Accuracy :  0.9253731343283582 Time  1.05 s\n",
            "Epoch :  1  Batch :  336  Loss :   0.23494865813214952  Accuracy :  0.9255952380952381 Time  1.06 s\n",
            "Epoch :  1  Batch :  337  Loss :   0.2346412074014279  Accuracy :  0.9255192878338279 Time  1.04 s\n",
            "Epoch :  1  Batch :  338  Loss :   0.2340598701686769  Accuracy :  0.9257396449704142 Time  1.03 s\n",
            "Epoch :  1  Batch :  339  Loss :   0.2333870352105757  Accuracy :  0.9259587020648967 Time  1.03 s\n",
            "Epoch :  1  Batch :  340  Loss :   0.23280375397161526  Accuracy :  0.9261764705882353 Time  1.05 s\n",
            "Epoch :  1  Batch :  341  Loss :   0.23214892482062763  Accuracy :  0.9263929618768328 Time  1.03 s\n",
            "Epoch :  1  Batch :  342  Loss :   0.23258275188483865  Accuracy :  0.9264619883040935 Time  1.04 s\n",
            "Epoch :  1  Batch :  343  Loss :   0.23197762804437136  Accuracy :  0.9266763848396501 Time  1.04 s\n",
            "Epoch :  1  Batch :  344  Loss :   0.23152442187135822  Accuracy :  0.926889534883721 Time  1.04 s\n",
            "Epoch :  1  Batch :  345  Loss :   0.23113109205404053  Accuracy :  0.9269565217391305 Time  1.06 s\n",
            "Epoch :  1  Batch :  346  Loss :   0.2305008776383636  Accuracy :  0.9271676300578034 Time  1.05 s\n",
            "Epoch :  1  Batch :  347  Loss :   0.22985941398974713  Accuracy :  0.9273775216138328 Time  1.06 s\n",
            "Epoch :  1  Batch :  348  Loss :   0.22925997333569004  Accuracy :  0.9275862068965517 Time  1.04 s\n",
            "Epoch :  1  Batch :  349  Loss :   0.22903002462053623  Accuracy :  0.9275071633237822 Time  1.06 s\n",
            "Epoch :  1  Batch :  350  Loss :   0.2284278621976929  Accuracy :  0.9277142857142857 Time  1.05 s\n",
            "Epoch :  1  Batch :  351  Loss :   0.227991129123099  Accuracy :  0.9277777777777778 Time  1.04 s\n",
            "Epoch :  1  Batch :  352  Loss :   0.22772931315227074  Accuracy :  0.9276988636363637 Time  1.04 s\n",
            "Epoch :  1  Batch :  353  Loss :   0.22744681467974912  Accuracy :  0.9276203966005666 Time  1.03 s\n",
            "Epoch :  1  Batch :  354  Loss :   0.22685413214898967  Accuracy :  0.9278248587570621 Time  1.04 s\n",
            "Epoch :  1  Batch :  355  Loss :   0.22651152216999884  Accuracy :  0.927887323943662 Time  1.03 s\n",
            "Epoch :  1  Batch :  356  Loss :   0.22599454878913133  Accuracy :  0.9280898876404494 Time  1.05 s\n",
            "Epoch :  1  Batch :  357  Loss :   0.2254092370131228  Accuracy :  0.9282913165266107 Time  1.05 s\n",
            "Epoch :  1  Batch :  358  Loss :   0.22576185277085647  Accuracy :  0.9283519553072626 Time  1.04 s\n",
            "Epoch :  1  Batch :  359  Loss :   0.22520338970399917  Accuracy :  0.9285515320334262 Time  1.03 s\n",
            "Epoch :  1  Batch :  360  Loss :   0.2247511256719008  Accuracy :  0.92875 Time  1.04 s\n",
            "Epoch :  1  Batch :  361  Loss :   0.2242595564156069  Accuracy :  0.9289473684210526 Time  1.04 s\n",
            "Epoch :  1  Batch :  362  Loss :   0.2239175442611356  Accuracy :  0.9291436464088397 Time  1.03 s\n",
            "Epoch :  1  Batch :  363  Loss :   0.2240789014225205  Accuracy :  0.9292011019283747 Time  1.04 s\n",
            "Epoch :  1  Batch :  364  Loss :   0.22358129363107895  Accuracy :  0.9293956043956044 Time  1.04 s\n",
            "Epoch :  1  Batch :  365  Loss :   0.22319326471435288  Accuracy :  0.9294520547945205 Time  1.04 s\n",
            "Epoch :  1  Batch :  366  Loss :   0.22268238870549154  Accuracy :  0.9296448087431693 Time  1.04 s\n",
            "Epoch :  1  Batch :  367  Loss :   0.22213723108791605  Accuracy :  0.9298365122615804 Time  1.05 s\n",
            "Epoch :  1  Batch :  368  Loss :   0.22163256062650244  Accuracy :  0.9300271739130435 Time  1.05 s\n",
            "Epoch :  1  Batch :  369  Loss :   0.2211561349112046  Accuracy :  0.9302168021680217 Time  1.04 s\n",
            "Epoch :  1  Batch :  370  Loss :   0.2207466751664273  Accuracy :  0.9304054054054054 Time  1.04 s\n",
            "Epoch :  1  Batch :  371  Loss :   0.22039705102464982  Accuracy :  0.9304582210242588 Time  1.04 s\n",
            "Epoch :  1  Batch :  372  Loss :   0.22002464347839434  Accuracy :  0.9306451612903226 Time  1.04 s\n",
            "Epoch :  1  Batch :  373  Loss :   0.21977782232721832  Accuracy :  0.9306917394224311 Time  0.29 s\n",
            "Accuracy of     0 : 94 %\n",
            "Accuracy of     1 : 90 %\n",
            "Accuracy of     2 : 94 %\n",
            "[1 epoch] Accuracy of the network on the Training images: 93.069 %\n",
            "Epoch :  2  Batch :  1  Loss :   0.08206566423177719  Accuracy :  1.0 Time  1.05 s\n",
            "Epoch :  2  Batch :  2  Loss :   0.055345285683870316  Accuracy :  1.0 Time  1.03 s\n",
            "Epoch :  2  Batch :  3  Loss :   0.060245491564273834  Accuracy :  0.9833333333333333 Time  1.03 s\n",
            "Epoch :  2  Batch :  4  Loss :   0.06428289599716663  Accuracy :  0.975 Time  1.05 s\n",
            "Epoch :  2  Batch :  5  Loss :   0.060916867852210996  Accuracy :  0.98 Time  1.06 s\n",
            "Epoch :  2  Batch :  6  Loss :   0.062374696135520935  Accuracy :  0.9833333333333333 Time  1.05 s\n",
            "Epoch :  2  Batch :  7  Loss :   0.07388329931667872  Accuracy :  0.9714285714285714 Time  1.04 s\n",
            "Epoch :  2  Batch :  8  Loss :   0.06747620971873403  Accuracy :  0.975 Time  1.07 s\n",
            "Epoch :  2  Batch :  9  Loss :   0.06847800521386994  Accuracy :  0.9722222222222222 Time  1.06 s\n",
            "Epoch :  2  Batch :  10  Loss :   0.06339989304542541  Accuracy :  0.975 Time  1.04 s\n",
            "Epoch :  2  Batch :  11  Loss :   0.06710984490134499  Accuracy :  0.9727272727272728 Time  1.03 s\n",
            "Epoch :  2  Batch :  12  Loss :   0.06265905980641644  Accuracy :  0.975 Time  1.04 s\n",
            "Epoch :  2  Batch :  13  Loss :   0.05865286347957758  Accuracy :  0.9769230769230769 Time  1.04 s\n",
            "Epoch :  2  Batch :  14  Loss :   0.06991273324404444  Accuracy :  0.975 Time  1.03 s\n",
            "Epoch :  2  Batch :  15  Loss :   0.07495727290709814  Accuracy :  0.97 Time  1.05 s\n",
            "Epoch :  2  Batch :  16  Loss :   0.07345591997727752  Accuracy :  0.971875 Time  1.05 s\n",
            "Epoch :  2  Batch :  17  Loss :   0.07831184960463468  Accuracy :  0.9705882352941176 Time  1.06 s\n",
            "Epoch :  2  Batch :  18  Loss :   0.07481152657419443  Accuracy :  0.9722222222222222 Time  1.06 s\n",
            "Epoch :  2  Batch :  19  Loss :   0.07672299140770185  Accuracy :  0.9710526315789474 Time  1.05 s\n",
            "Epoch :  2  Batch :  20  Loss :   0.07326854197308422  Accuracy :  0.9725 Time  1.06 s\n",
            "Epoch :  2  Batch :  21  Loss :   0.07084306728627  Accuracy :  0.9738095238095238 Time  1.04 s\n",
            "Epoch :  2  Batch :  22  Loss :   0.07009886552325705  Accuracy :  0.975 Time  1.05 s\n",
            "Epoch :  2  Batch :  23  Loss :   0.07217230753082296  Accuracy :  0.9717391304347827 Time  1.04 s\n",
            "Epoch :  2  Batch :  24  Loss :   0.07556749391369522  Accuracy :  0.9708333333333333 Time  1.03 s\n",
            "Epoch :  2  Batch :  25  Loss :   0.07955345280468464  Accuracy :  0.97 Time  1.04 s\n",
            "Epoch :  2  Batch :  26  Loss :   0.07809764196952948  Accuracy :  0.9711538461538461 Time  1.06 s\n",
            "Epoch :  2  Batch :  27  Loss :   0.07906236299486072  Accuracy :  0.9703703703703703 Time  1.06 s\n",
            "Epoch :  2  Batch :  28  Loss :   0.0771540131286851  Accuracy :  0.9714285714285714 Time  1.05 s\n",
            "Epoch :  2  Batch :  29  Loss :   0.07488452912918453  Accuracy :  0.9724137931034482 Time  1.04 s\n",
            "Epoch :  2  Batch :  30  Loss :   0.07542023646334807  Accuracy :  0.9716666666666667 Time  1.04 s\n",
            "Epoch :  2  Batch :  31  Loss :   0.07468876615166664  Accuracy :  0.9725806451612903 Time  1.04 s\n",
            "Epoch :  2  Batch :  32  Loss :   0.07578292244579643  Accuracy :  0.971875 Time  1.04 s\n",
            "Epoch :  2  Batch :  33  Loss :   0.07363136576940164  Accuracy :  0.9727272727272728 Time  1.03 s\n",
            "Epoch :  2  Batch :  34  Loss :   0.07240535090129603  Accuracy :  0.9735294117647059 Time  1.04 s\n",
            "Epoch :  2  Batch :  35  Loss :   0.07130106912393655  Accuracy :  0.9742857142857143 Time  1.03 s\n",
            "Epoch :  2  Batch :  36  Loss :   0.0704068747581914  Accuracy :  0.975 Time  1.03 s\n",
            "Epoch :  2  Batch :  37  Loss :   0.0689003597063994  Accuracy :  0.9756756756756757 Time  1.05 s\n",
            "Epoch :  2  Batch :  38  Loss :   0.06942198117949853  Accuracy :  0.975 Time  1.05 s\n",
            "Epoch :  2  Batch :  39  Loss :   0.06899134467284267  Accuracy :  0.9756410256410256 Time  1.04 s\n",
            "Epoch :  2  Batch :  40  Loss :   0.06741131948074326  Accuracy :  0.97625 Time  1.04 s\n",
            "Epoch :  2  Batch :  41  Loss :   0.07419021785395538  Accuracy :  0.9719512195121951 Time  1.04 s\n",
            "Epoch :  2  Batch :  42  Loss :   0.07260472142314982  Accuracy :  0.9726190476190476 Time  1.04 s\n",
            "Epoch :  2  Batch :  43  Loss :   0.0726438214201047  Accuracy :  0.9720930232558139 Time  1.03 s\n",
            "Epoch :  2  Batch :  44  Loss :   0.07129894866904413  Accuracy :  0.9727272727272728 Time  1.03 s\n",
            "Epoch :  2  Batch :  45  Loss :   0.07174454158585933  Accuracy :  0.9722222222222222 Time  1.04 s\n",
            "Epoch :  2  Batch :  46  Loss :   0.07222519419156015  Accuracy :  0.9728260869565217 Time  1.03 s\n",
            "Epoch :  2  Batch :  47  Loss :   0.07079293358912493  Accuracy :  0.973404255319149 Time  1.04 s\n",
            "Epoch :  2  Batch :  48  Loss :   0.06946105789393187  Accuracy :  0.9739583333333334 Time  1.05 s\n",
            "Epoch :  2  Batch :  49  Loss :   0.06876745835250737  Accuracy :  0.9744897959183674 Time  1.06 s\n",
            "Epoch :  2  Batch :  50  Loss :   0.06772284861654043  Accuracy :  0.975 Time  1.05 s\n",
            "Epoch :  2  Batch :  51  Loss :   0.06696954563113988  Accuracy :  0.9754901960784313 Time  1.04 s\n",
            "Epoch :  2  Batch :  52  Loss :   0.06592490097794396  Accuracy :  0.9759615384615384 Time  1.03 s\n",
            "Epoch :  2  Batch :  53  Loss :   0.06478823464855833  Accuracy :  0.9764150943396226 Time  1.04 s\n",
            "Epoch :  2  Batch :  54  Loss :   0.0638819876368399  Accuracy :  0.9768518518518519 Time  1.04 s\n",
            "Epoch :  2  Batch :  55  Loss :   0.06407700167460875  Accuracy :  0.9763636363636363 Time  1.04 s\n",
            "Epoch :  2  Batch :  56  Loss :   0.07049262563564948  Accuracy :  0.9758928571428571 Time  1.03 s\n",
            "Epoch :  2  Batch :  57  Loss :   0.06966318337148741  Accuracy :  0.9763157894736842 Time  1.04 s\n",
            "Epoch :  2  Batch :  58  Loss :   0.06871725776200664  Accuracy :  0.9767241379310345 Time  1.04 s\n",
            "Epoch :  2  Batch :  59  Loss :   0.06785845592365426  Accuracy :  0.9771186440677966 Time  1.04 s\n",
            "Epoch :  2  Batch :  60  Loss :   0.07122621821860473  Accuracy :  0.9766666666666667 Time  1.06 s\n",
            "Epoch :  2  Batch :  61  Loss :   0.07038138373220554  Accuracy :  0.9770491803278688 Time  1.05 s\n",
            "Epoch :  2  Batch :  62  Loss :   0.06973223916945918  Accuracy :  0.9774193548387097 Time  1.07 s\n",
            "Epoch :  2  Batch :  63  Loss :   0.0689534458021323  Accuracy :  0.9777777777777777 Time  1.05 s\n",
            "Epoch :  2  Batch :  64  Loss :   0.06802703841822222  Accuracy :  0.978125 Time  1.05 s\n",
            "Epoch :  2  Batch :  65  Loss :   0.06861757137454473  Accuracy :  0.9776923076923076 Time  1.03 s\n",
            "Epoch :  2  Batch :  66  Loss :   0.06787903065031226  Accuracy :  0.978030303030303 Time  1.04 s\n",
            "Epoch :  2  Batch :  67  Loss :   0.06697643307079353  Accuracy :  0.9783582089552239 Time  1.03 s\n",
            "Epoch :  2  Batch :  68  Loss :   0.06653881859828663  Accuracy :  0.9786764705882353 Time  1.03 s\n",
            "Epoch :  2  Batch :  69  Loss :   0.06608249434013513  Accuracy :  0.9789855072463768 Time  1.03 s\n",
            "Epoch :  2  Batch :  70  Loss :   0.06555486138510917  Accuracy :  0.9792857142857143 Time  1.04 s\n",
            "Epoch :  2  Batch :  71  Loss :   0.06483222870156169  Accuracy :  0.9795774647887324 Time  1.05 s\n",
            "Epoch :  2  Batch :  72  Loss :   0.06535227866455291  Accuracy :  0.9791666666666666 Time  1.06 s\n",
            "Epoch :  2  Batch :  73  Loss :   0.06467537636141459  Accuracy :  0.9794520547945206 Time  1.05 s\n",
            "Epoch :  2  Batch :  74  Loss :   0.06409911547686804  Accuracy :  0.9797297297297297 Time  1.04 s\n",
            "Epoch :  2  Batch :  75  Loss :   0.06352025882030526  Accuracy :  0.98 Time  1.03 s\n",
            "Epoch :  2  Batch :  76  Loss :   0.06296890158524834  Accuracy :  0.9802631578947368 Time  1.03 s\n",
            "Epoch :  2  Batch :  77  Loss :   0.0622988997765079  Accuracy :  0.9805194805194806 Time  1.03 s\n",
            "Epoch :  2  Batch :  78  Loss :   0.06174947447382296  Accuracy :  0.9807692307692307 Time  1.04 s\n",
            "Epoch :  2  Batch :  79  Loss :   0.061302119530030064  Accuracy :  0.9810126582278481 Time  1.03 s\n",
            "Epoch :  2  Batch :  80  Loss :   0.06096486357855611  Accuracy :  0.98125 Time  1.03 s\n",
            "Epoch :  2  Batch :  81  Loss :   0.06035316361252357  Accuracy :  0.9814814814814815 Time  1.04 s\n",
            "Epoch :  2  Batch :  82  Loss :   0.05975616026510734  Accuracy :  0.9817073170731707 Time  1.06 s\n",
            "Epoch :  2  Batch :  83  Loss :   0.05917163770533649  Accuracy :  0.9819277108433735 Time  1.05 s\n",
            "Epoch :  2  Batch :  84  Loss :   0.058686632269416894  Accuracy :  0.9821428571428571 Time  1.05 s\n",
            "Epoch :  2  Batch :  85  Loss :   0.06090436135692631  Accuracy :  0.9811764705882353 Time  1.04 s\n",
            "Epoch :  2  Batch :  86  Loss :   0.060439825150032725  Accuracy :  0.9813953488372092 Time  1.04 s\n",
            "Epoch :  2  Batch :  87  Loss :   0.05993465747919747  Accuracy :  0.9816091954022989 Time  1.03 s\n",
            "Epoch :  2  Batch :  88  Loss :   0.05942482921951027  Accuracy :  0.9818181818181818 Time  1.03 s\n",
            "Epoch :  2  Batch :  89  Loss :   0.05880689868452341  Accuracy :  0.9820224719101124 Time  1.04 s\n",
            "Epoch :  2  Batch :  90  Loss :   0.05830386424333685  Accuracy :  0.9822222222222222 Time  1.03 s\n",
            "Epoch :  2  Batch :  91  Loss :   0.057910593886665265  Accuracy :  0.9824175824175824 Time  1.03 s\n",
            "Epoch :  2  Batch :  92  Loss :   0.05757159448694438  Accuracy :  0.9826086956521739 Time  1.04 s\n",
            "Epoch :  2  Batch :  93  Loss :   0.05746840966504908  Accuracy :  0.9827956989247312 Time  1.05 s\n",
            "Epoch :  2  Batch :  94  Loss :   0.056930528785240776  Accuracy :  0.9829787234042553 Time  1.05 s\n",
            "Epoch :  2  Batch :  95  Loss :   0.056509443127403136  Accuracy :  0.9831578947368421 Time  1.05 s\n",
            "Epoch :  2  Batch :  96  Loss :   0.056327933785117544  Accuracy :  0.9833333333333333 Time  1.04 s\n",
            "Epoch :  2  Batch :  97  Loss :   0.056402636125453355  Accuracy :  0.9829896907216494 Time  1.04 s\n",
            "Epoch :  2  Batch :  98  Loss :   0.055947453952489457  Accuracy :  0.9831632653061224 Time  1.03 s\n",
            "Epoch :  2  Batch :  99  Loss :   0.0555033887727092  Accuracy :  0.9833333333333333 Time  1.04 s\n",
            "Epoch :  2  Batch :  100  Loss :   0.055355487391352654  Accuracy :  0.9835 Time  1.05 s\n",
            "Epoch :  2  Batch :  101  Loss :   0.05542232564622813  Accuracy :  0.9831683168316832 Time  1.05 s\n",
            "Epoch :  2  Batch :  102  Loss :   0.05494683826177874  Accuracy :  0.9833333333333333 Time  1.05 s\n",
            "Epoch :  2  Batch :  103  Loss :   0.054714067038872  Accuracy :  0.983495145631068 Time  1.03 s\n",
            "Epoch :  2  Batch :  104  Loss :   0.05553816345323307  Accuracy :  0.9831730769230769 Time  1.04 s\n",
            "Epoch :  2  Batch :  105  Loss :   0.05510996333988649  Accuracy :  0.9833333333333333 Time  1.05 s\n",
            "Epoch :  2  Batch :  106  Loss :   0.05501282069709082  Accuracy :  0.9834905660377359 Time  1.05 s\n",
            "Epoch :  2  Batch :  107  Loss :   0.054697650428165066  Accuracy :  0.9836448598130841 Time  1.04 s\n",
            "Epoch :  2  Batch :  108  Loss :   0.05465529774988277  Accuracy :  0.9837962962962963 Time  1.03 s\n",
            "Epoch :  2  Batch :  109  Loss :   0.054245080401557025  Accuracy :  0.9839449541284404 Time  1.04 s\n",
            "Epoch :  2  Batch :  110  Loss :   0.054014401489191434  Accuracy :  0.9840909090909091 Time  1.04 s\n",
            "Epoch :  2  Batch :  111  Loss :   0.053652209703818905  Accuracy :  0.9842342342342343 Time  1.04 s\n",
            "Epoch :  2  Batch :  112  Loss :   0.0532263064856774  Accuracy :  0.984375 Time  1.03 s\n",
            "Epoch :  2  Batch :  113  Loss :   0.05290943168235564  Accuracy :  0.9845132743362832 Time  1.03 s\n",
            "Epoch :  2  Batch :  114  Loss :   0.05255320892881667  Accuracy :  0.9846491228070176 Time  1.04 s\n",
            "Epoch :  2  Batch :  115  Loss :   0.05261232790577671  Accuracy :  0.9847826086956522 Time  1.04 s\n",
            "Epoch :  2  Batch :  116  Loss :   0.05225263109655473  Accuracy :  0.9849137931034483 Time  1.06 s\n",
            "Epoch :  2  Batch :  117  Loss :   0.05352471893828394  Accuracy :  0.9846153846153847 Time  1.05 s\n",
            "Epoch :  2  Batch :  118  Loss :   0.053485637601717546  Accuracy :  0.9843220338983051 Time  1.04 s\n",
            "Epoch :  2  Batch :  119  Loss :   0.053131106426986326  Accuracy :  0.9844537815126051 Time  1.03 s\n",
            "Epoch :  2  Batch :  120  Loss :   0.052751041816857955  Accuracy :  0.9845833333333334 Time  1.03 s\n",
            "Epoch :  2  Batch :  121  Loss :   0.05247118049262723  Accuracy :  0.9847107438016529 Time  1.04 s\n",
            "Epoch :  2  Batch :  122  Loss :   0.05224516435877466  Accuracy :  0.9848360655737705 Time  1.04 s\n",
            "Epoch :  2  Batch :  123  Loss :   0.05186638765309642  Accuracy :  0.984959349593496 Time  1.04 s\n",
            "Epoch :  2  Batch :  124  Loss :   0.05175208077285318  Accuracy :  0.9850806451612903 Time  1.03 s\n",
            "Epoch :  2  Batch :  125  Loss :   0.05147506596893072  Accuracy :  0.9852 Time  1.04 s\n",
            "Epoch :  2  Batch :  126  Loss :   0.05112140030703611  Accuracy :  0.9853174603174604 Time  1.05 s\n",
            "Epoch :  2  Batch :  127  Loss :   0.05098982213255693  Accuracy :  0.9854330708661417 Time  1.05 s\n",
            "Epoch :  2  Batch :  128  Loss :   0.05167756275477586  Accuracy :  0.984765625 Time  1.05 s\n",
            "Epoch :  2  Batch :  129  Loss :   0.052556188870943335  Accuracy :  0.9844961240310077 Time  1.04 s\n",
            "Epoch :  2  Batch :  130  Loss :   0.05235251848084422  Accuracy :  0.9846153846153847 Time  1.05 s\n",
            "Epoch :  2  Batch :  131  Loss :   0.052015915562803966  Accuracy :  0.9847328244274809 Time  1.04 s\n",
            "Epoch :  2  Batch :  132  Loss :   0.05183671968706855  Accuracy :  0.9848484848484849 Time  1.04 s\n",
            "Epoch :  2  Batch :  133  Loss :   0.05147201215141082  Accuracy :  0.9849624060150376 Time  1.03 s\n",
            "Epoch :  2  Batch :  134  Loss :   0.05116856495203422  Accuracy :  0.9850746268656716 Time  1.04 s\n",
            "Epoch :  2  Batch :  135  Loss :   0.05095563807731701  Accuracy :  0.9851851851851852 Time  1.05 s\n",
            "Epoch :  2  Batch :  136  Loss :   0.051136884627767894  Accuracy :  0.9852941176470589 Time  1.04 s\n",
            "Epoch :  2  Batch :  137  Loss :   0.051797612422370236  Accuracy :  0.9846715328467154 Time  1.05 s\n",
            "Epoch :  2  Batch :  138  Loss :   0.05145847882596317  Accuracy :  0.9847826086956522 Time  1.05 s\n",
            "Epoch :  2  Batch :  139  Loss :   0.05168560017469815  Accuracy :  0.9845323741007195 Time  1.05 s\n",
            "Epoch :  2  Batch :  140  Loss :   0.051363197047196864  Accuracy :  0.9846428571428572 Time  1.04 s\n",
            "Epoch :  2  Batch :  141  Loss :   0.05110545101549133  Accuracy :  0.9847517730496453 Time  1.05 s\n",
            "Epoch :  2  Batch :  142  Loss :   0.050766525514633724  Accuracy :  0.9848591549295774 Time  1.04 s\n",
            "Epoch :  2  Batch :  143  Loss :   0.05064743161983006  Accuracy :  0.984965034965035 Time  1.04 s\n",
            "Epoch :  2  Batch :  144  Loss :   0.050994587894011706  Accuracy :  0.9847222222222223 Time  1.03 s\n",
            "Epoch :  2  Batch :  145  Loss :   0.05106144332937126  Accuracy :  0.9844827586206897 Time  1.03 s\n",
            "Epoch :  2  Batch :  146  Loss :   0.050820172266805005  Accuracy :  0.9845890410958904 Time  1.04 s\n",
            "Epoch :  2  Batch :  147  Loss :   0.05049876648723623  Accuracy :  0.9846938775510204 Time  1.04 s\n",
            "Epoch :  2  Batch :  148  Loss :   0.0510019259574521  Accuracy :  0.9844594594594595 Time  1.05 s\n",
            "Epoch :  2  Batch :  149  Loss :   0.05100675305232856  Accuracy :  0.9845637583892617 Time  1.06 s\n",
            "Epoch :  2  Batch :  150  Loss :   0.050766198217558366  Accuracy :  0.9846666666666667 Time  1.04 s\n",
            "Epoch :  2  Batch :  151  Loss :   0.05088747137793593  Accuracy :  0.9844370860927152 Time  1.03 s\n",
            "Epoch :  2  Batch :  152  Loss :   0.050734637211701884  Accuracy :  0.9845394736842106 Time  1.04 s\n",
            "Epoch :  2  Batch :  153  Loss :   0.05043856710579027  Accuracy :  0.984640522875817 Time  1.04 s\n",
            "Epoch :  2  Batch :  154  Loss :   0.05021494363174568  Accuracy :  0.9847402597402597 Time  1.04 s\n",
            "Epoch :  2  Batch :  155  Loss :   0.04994114067615761  Accuracy :  0.9848387096774194 Time  1.04 s\n",
            "Epoch :  2  Batch :  156  Loss :   0.04986014092812697  Accuracy :  0.9849358974358975 Time  1.03 s\n",
            "Epoch :  2  Batch :  157  Loss :   0.049773333272392487  Accuracy :  0.9850318471337579 Time  1.04 s\n",
            "Epoch :  2  Batch :  158  Loss :   0.049907911048695165  Accuracy :  0.9848101265822785 Time  1.03 s\n",
            "Epoch :  2  Batch :  159  Loss :   0.04993120552649803  Accuracy :  0.9845911949685534 Time  1.06 s\n",
            "Epoch :  2  Batch :  160  Loss :   0.04971457238862058  Accuracy :  0.9846875 Time  1.05 s\n",
            "Epoch :  2  Batch :  161  Loss :   0.04952448668820286  Accuracy :  0.9847826086956522 Time  1.04 s\n",
            "Epoch :  2  Batch :  162  Loss :   0.04938498146136372  Accuracy :  0.9848765432098765 Time  1.03 s\n",
            "Epoch :  2  Batch :  163  Loss :   0.04912054617717816  Accuracy :  0.9849693251533742 Time  1.04 s\n",
            "Epoch :  2  Batch :  164  Loss :   0.048953083118071734  Accuracy :  0.9850609756097561 Time  1.03 s\n",
            "Epoch :  2  Batch :  165  Loss :   0.04877639904082047  Accuracy :  0.9851515151515151 Time  1.04 s\n",
            "Epoch :  2  Batch :  166  Loss :   0.04862166753919593  Accuracy :  0.9852409638554217 Time  1.04 s\n",
            "Epoch :  2  Batch :  167  Loss :   0.05118902011016038  Accuracy :  0.9844311377245509 Time  1.03 s\n",
            "Epoch :  2  Batch :  168  Loss :   0.050940854504005983  Accuracy :  0.9845238095238096 Time  1.03 s\n",
            "Epoch :  2  Batch :  169  Loss :   0.05094472692105589  Accuracy :  0.9843195266272189 Time  1.04 s\n",
            "Epoch :  2  Batch :  170  Loss :   0.05079777181175921  Accuracy :  0.9844117647058823 Time  1.05 s\n",
            "Epoch :  2  Batch :  171  Loss :   0.050565436276830515  Accuracy :  0.9845029239766082 Time  1.06 s\n",
            "Epoch :  2  Batch :  172  Loss :   0.05036650902488767  Accuracy :  0.984593023255814 Time  1.04 s\n",
            "Epoch :  2  Batch :  173  Loss :   0.050198324424392315  Accuracy :  0.9846820809248555 Time  1.03 s\n",
            "Epoch :  2  Batch :  174  Loss :   0.04999098053400073  Accuracy :  0.9847701149425288 Time  1.03 s\n",
            "Epoch :  2  Batch :  175  Loss :   0.049862490659579636  Accuracy :  0.9848571428571429 Time  1.03 s\n",
            "Epoch :  2  Batch :  176  Loss :   0.049669606845286166  Accuracy :  0.9849431818181819 Time  1.04 s\n",
            "Epoch :  2  Batch :  177  Loss :   0.049420319498900724  Accuracy :  0.9850282485875707 Time  1.04 s\n",
            "Epoch :  2  Batch :  178  Loss :   0.050750791483684284  Accuracy :  0.9845505617977528 Time  1.04 s\n",
            "Epoch :  2  Batch :  179  Loss :   0.05076180379863766  Accuracy :  0.9843575418994414 Time  1.04 s\n",
            "Epoch :  2  Batch :  180  Loss :   0.05050734541146085  Accuracy :  0.9844444444444445 Time  1.03 s\n",
            "Epoch :  2  Batch :  181  Loss :   0.05107685588994861  Accuracy :  0.9842541436464088 Time  1.06 s\n",
            "Epoch :  2  Batch :  182  Loss :   0.05091167823539453  Accuracy :  0.9843406593406593 Time  1.07 s\n",
            "Epoch :  2  Batch :  183  Loss :   0.05072726380420961  Accuracy :  0.9844262295081967 Time  1.05 s\n",
            "Epoch :  2  Batch :  184  Loss :   0.05051448895550414  Accuracy :  0.9845108695652174 Time  1.07 s\n",
            "Epoch :  2  Batch :  185  Loss :   0.05053850566288708  Accuracy :  0.9845945945945946 Time  1.04 s\n",
            "Epoch :  2  Batch :  186  Loss :   0.05064384503945989  Accuracy :  0.9844086021505376 Time  1.04 s\n",
            "Epoch :  2  Batch :  187  Loss :   0.050404290826791986  Accuracy :  0.9844919786096257 Time  1.04 s\n",
            "Epoch :  2  Batch :  188  Loss :   0.050199924803467744  Accuracy :  0.9845744680851064 Time  1.04 s\n",
            "Epoch :  2  Batch :  189  Loss :   0.05003473780945771  Accuracy :  0.9846560846560847 Time  1.03 s\n",
            "Epoch :  2  Batch :  190  Loss :   0.04977595059286901  Accuracy :  0.9847368421052631 Time  1.04 s\n",
            "Epoch :  2  Batch :  191  Loss :   0.0504763819763671  Accuracy :  0.9842931937172775 Time  1.03 s\n",
            "Epoch :  2  Batch :  192  Loss :   0.0503251675224116  Accuracy :  0.984375 Time  1.04 s\n",
            "Epoch :  2  Batch :  193  Loss :   0.05024310676417183  Accuracy :  0.9844559585492227 Time  1.05 s\n",
            "Epoch :  2  Batch :  194  Loss :   0.05030413922678545  Accuracy :  0.9845360824742269 Time  1.05 s\n",
            "Epoch :  2  Batch :  195  Loss :   0.05006838554743295  Accuracy :  0.9846153846153847 Time  1.05 s\n",
            "Epoch :  2  Batch :  196  Loss :   0.05043657362753316  Accuracy :  0.9844387755102041 Time  1.04 s\n",
            "Epoch :  2  Batch :  197  Loss :   0.05022043198392003  Accuracy :  0.9845177664974619 Time  1.03 s\n",
            "Epoch :  2  Batch :  198  Loss :   0.05004498343432623  Accuracy :  0.9845959595959596 Time  1.03 s\n",
            "Epoch :  2  Batch :  199  Loss :   0.04985812864905158  Accuracy :  0.9846733668341708 Time  1.03 s\n",
            "Epoch :  2  Batch :  200  Loss :   0.049715514953131784  Accuracy :  0.98475 Time  1.04 s\n",
            "Epoch :  2  Batch :  201  Loss :   0.04949877963607566  Accuracy :  0.9848258706467662 Time  1.04 s\n",
            "Epoch :  2  Batch :  202  Loss :   0.04934651248034846  Accuracy :  0.9849009900990099 Time  1.03 s\n",
            "Epoch :  2  Batch :  203  Loss :   0.04942058307735772  Accuracy :  0.9847290640394089 Time  1.03 s\n",
            "Epoch :  2  Batch :  204  Loss :   0.049228813190483396  Accuracy :  0.9848039215686275 Time  1.05 s\n",
            "Epoch :  2  Batch :  205  Loss :   0.04902334115751905  Accuracy :  0.9848780487804878 Time  1.05 s\n",
            "Epoch :  2  Batch :  206  Loss :   0.04883950903674913  Accuracy :  0.9849514563106796 Time  1.04 s\n",
            "Epoch :  2  Batch :  207  Loss :   0.04862077422788735  Accuracy :  0.985024154589372 Time  1.04 s\n",
            "Epoch :  2  Batch :  208  Loss :   0.048683508945731986  Accuracy :  0.9848557692307692 Time  1.04 s\n",
            "Epoch :  2  Batch :  209  Loss :   0.04848345576698611  Accuracy :  0.9849282296650718 Time  1.03 s\n",
            "Epoch :  2  Batch :  210  Loss :   0.04829529159691273  Accuracy :  0.985 Time  1.03 s\n",
            "Epoch :  2  Batch :  211  Loss :   0.04810286309929803  Accuracy :  0.9850710900473933 Time  1.04 s\n",
            "Epoch :  2  Batch :  212  Loss :   0.04796380600793164  Accuracy :  0.9851415094339623 Time  1.03 s\n",
            "Epoch :  2  Batch :  213  Loss :   0.048178420084563606  Accuracy :  0.9849765258215962 Time  1.03 s\n",
            "Epoch :  2  Batch :  214  Loss :   0.048035820834578025  Accuracy :  0.9850467289719627 Time  1.05 s\n",
            "Epoch :  2  Batch :  215  Loss :   0.04783029573980372  Accuracy :  0.9851162790697674 Time  1.05 s\n",
            "Epoch :  2  Batch :  216  Loss :   0.047619025004678406  Accuracy :  0.9851851851851852 Time  1.06 s\n",
            "Epoch :  2  Batch :  217  Loss :   0.047608878091728736  Accuracy :  0.9852534562211982 Time  1.04 s\n",
            "Epoch :  2  Batch :  218  Loss :   0.04769048394385401  Accuracy :  0.9850917431192661 Time  1.03 s\n",
            "Epoch :  2  Batch :  219  Loss :   0.047539023922216234  Accuracy :  0.9851598173515982 Time  1.03 s\n",
            "Epoch :  2  Batch :  220  Loss :   0.04755642382925461  Accuracy :  0.985 Time  1.04 s\n",
            "Epoch :  2  Batch :  221  Loss :   0.047426523650760395  Accuracy :  0.9850678733031675 Time  1.04 s\n",
            "Epoch :  2  Batch :  222  Loss :   0.04723381110087356  Accuracy :  0.9851351351351352 Time  1.05 s\n",
            "Epoch :  2  Batch :  223  Loss :   0.04778136359684319  Accuracy :  0.9849775784753363 Time  1.05 s\n",
            "Epoch :  2  Batch :  224  Loss :   0.04801086023664019  Accuracy :  0.9848214285714286 Time  1.04 s\n",
            "Epoch :  2  Batch :  225  Loss :   0.04852863868025856  Accuracy :  0.9846666666666667 Time  1.05 s\n",
            "Epoch :  2  Batch :  226  Loss :   0.048454543509195036  Accuracy :  0.9847345132743363 Time  1.05 s\n",
            "Epoch :  2  Batch :  227  Loss :   0.04839019899078058  Accuracy :  0.9848017621145374 Time  1.04 s\n",
            "Epoch :  2  Batch :  228  Loss :   0.04840026202707617  Accuracy :  0.9848684210526316 Time  1.04 s\n",
            "Epoch :  2  Batch :  229  Loss :   0.048470079882058224  Accuracy :  0.9847161572052402 Time  1.04 s\n",
            "Epoch :  2  Batch :  230  Loss :   0.048288382000148136  Accuracy :  0.9847826086956522 Time  1.04 s\n",
            "Epoch :  2  Batch :  231  Loss :   0.04868525575626706  Accuracy :  0.9846320346320346 Time  1.04 s\n",
            "Epoch :  2  Batch :  232  Loss :   0.0485005940341768  Accuracy :  0.9846982758620689 Time  1.03 s\n",
            "Epoch :  2  Batch :  233  Loss :   0.048349055762866376  Accuracy :  0.9847639484978541 Time  1.04 s\n",
            "Epoch :  2  Batch :  234  Loss :   0.0483967059219264  Accuracy :  0.9846153846153847 Time  1.04 s\n",
            "Epoch :  2  Batch :  235  Loss :   0.04841953547067068  Accuracy :  0.9846808510638297 Time  1.05 s\n",
            "Epoch :  2  Batch :  236  Loss :   0.048236180019418914  Accuracy :  0.9847457627118644 Time  1.05 s\n",
            "Epoch :  2  Batch :  237  Loss :   0.048040264607348206  Accuracy :  0.9848101265822785 Time  1.04 s\n",
            "Epoch :  2  Batch :  238  Loss :   0.04826205987150648  Accuracy :  0.9846638655462185 Time  1.04 s\n",
            "Epoch :  2  Batch :  239  Loss :   0.048258805089283374  Accuracy :  0.9847280334728034 Time  1.04 s\n",
            "Epoch :  2  Batch :  240  Loss :   0.04811717854172457  Accuracy :  0.9847916666666666 Time  1.03 s\n",
            "Epoch :  2  Batch :  241  Loss :   0.047989303341784605  Accuracy :  0.9848547717842324 Time  1.04 s\n",
            "Epoch :  2  Batch :  242  Loss :   0.04782020653817372  Accuracy :  0.9849173553719008 Time  1.04 s\n",
            "Epoch :  2  Batch :  243  Loss :   0.047686523093876464  Accuracy :  0.9849794238683127 Time  1.04 s\n",
            "Epoch :  2  Batch :  244  Loss :   0.047620415365987566  Accuracy :  0.9850409836065573 Time  1.04 s\n",
            "Epoch :  2  Batch :  245  Loss :   0.04785362662918562  Accuracy :  0.9848979591836735 Time  1.05 s\n",
            "Epoch :  2  Batch :  246  Loss :   0.04772505691044063  Accuracy :  0.984959349593496 Time  1.05 s\n",
            "Epoch :  2  Batch :  247  Loss :   0.048095279195070686  Accuracy :  0.9846153846153847 Time  1.05 s\n",
            "Epoch :  2  Batch :  248  Loss :   0.04804986258574401  Accuracy :  0.9846774193548387 Time  1.05 s\n",
            "Epoch :  2  Batch :  249  Loss :   0.04792110496163218  Accuracy :  0.9847389558232932 Time  1.04 s\n",
            "Epoch :  2  Batch :  250  Loss :   0.04775685877446085  Accuracy :  0.9848 Time  1.04 s\n",
            "Epoch :  2  Batch :  251  Loss :   0.04807614046148956  Accuracy :  0.9846613545816733 Time  1.04 s\n",
            "Epoch :  2  Batch :  252  Loss :   0.04792672090162153  Accuracy :  0.9847222222222223 Time  1.04 s\n",
            "Epoch :  2  Batch :  253  Loss :   0.047768749039907285  Accuracy :  0.9847826086956522 Time  1.04 s\n",
            "Epoch :  2  Batch :  254  Loss :   0.047975873010871035  Accuracy :  0.9846456692913386 Time  1.03 s\n",
            "Epoch :  2  Batch :  255  Loss :   0.047811013924907525  Accuracy :  0.9847058823529412 Time  1.03 s\n",
            "Epoch :  2  Batch :  256  Loss :   0.04767850293228548  Accuracy :  0.984765625 Time  1.05 s\n",
            "Epoch :  2  Batch :  257  Loss :   0.04757382440315523  Accuracy :  0.9848249027237355 Time  1.05 s\n",
            "Epoch :  2  Batch :  258  Loss :   0.04849394007365746  Accuracy :  0.9844961240310077 Time  1.04 s\n",
            "Epoch :  2  Batch :  259  Loss :   0.04832883620487246  Accuracy :  0.9845559845559846 Time  1.03 s\n",
            "Epoch :  2  Batch :  260  Loss :   0.04837499634595588  Accuracy :  0.9846153846153847 Time  1.03 s\n",
            "Epoch :  2  Batch :  261  Loss :   0.048548225139471136  Accuracy :  0.9844827586206897 Time  1.04 s\n",
            "Epoch :  2  Batch :  262  Loss :   0.04838315489122516  Accuracy :  0.9845419847328244 Time  1.04 s\n",
            "Epoch :  2  Batch :  263  Loss :   0.04904808297296526  Accuracy :  0.9844106463878327 Time  1.05 s\n",
            "Epoch :  2  Batch :  264  Loss :   0.048920191841192937  Accuracy :  0.984469696969697 Time  1.05 s\n",
            "Epoch :  2  Batch :  265  Loss :   0.04894423340271526  Accuracy :  0.9843396226415094 Time  1.04 s\n",
            "Epoch :  2  Batch :  266  Loss :   0.048973174908380476  Accuracy :  0.9842105263157894 Time  1.05 s\n",
            "Epoch :  2  Batch :  267  Loss :   0.04884517955251931  Accuracy :  0.9842696629213483 Time  1.05 s\n",
            "Epoch :  2  Batch :  268  Loss :   0.048698193059170815  Accuracy :  0.9843283582089553 Time  1.04 s\n",
            "Epoch :  2  Batch :  269  Loss :   0.04899112842752006  Accuracy :  0.9842007434944238 Time  1.03 s\n",
            "Epoch :  2  Batch :  270  Loss :   0.04889641974586993  Accuracy :  0.9842592592592593 Time  1.03 s\n",
            "Epoch :  2  Batch :  271  Loss :   0.049115985349281195  Accuracy :  0.9841328413284133 Time  1.03 s\n",
            "Epoch :  2  Batch :  272  Loss :   0.049135293927119  Accuracy :  0.9840073529411765 Time  1.04 s\n",
            "Epoch :  2  Batch :  273  Loss :   0.0490028921833719  Accuracy :  0.984065934065934 Time  1.03 s\n",
            "Epoch :  2  Batch :  274  Loss :   0.0488512890972537  Accuracy :  0.9841240875912409 Time  1.04 s\n",
            "Epoch :  2  Batch :  275  Loss :   0.048868218522349544  Accuracy :  0.9841818181818182 Time  1.03 s\n",
            "Epoch :  2  Batch :  276  Loss :   0.04954287514809276  Accuracy :  0.9836956521739131 Time  1.05 s\n",
            "Epoch :  2  Batch :  277  Loss :   0.049438692505777364  Accuracy :  0.983754512635379 Time  1.05 s\n",
            "Epoch :  2  Batch :  278  Loss :   0.049447996834152304  Accuracy :  0.9838129496402878 Time  1.06 s\n",
            "Epoch :  2  Batch :  279  Loss :   0.0493077897278118  Accuracy :  0.9838709677419355 Time  1.04 s\n",
            "Epoch :  2  Batch :  280  Loss :   0.04921407343769845  Accuracy :  0.9839285714285714 Time  1.04 s\n",
            "Epoch :  2  Batch :  281  Loss :   0.04907726590336032  Accuracy :  0.9839857651245552 Time  1.04 s\n",
            "Epoch :  2  Batch :  282  Loss :   0.048987907513559976  Accuracy :  0.9840425531914894 Time  1.04 s\n",
            "Epoch :  2  Batch :  283  Loss :   0.04981054560867115  Accuracy :  0.9839222614840989 Time  1.04 s\n",
            "Epoch :  2  Batch :  284  Loss :   0.04964870389741124  Accuracy :  0.9839788732394367 Time  1.04 s\n",
            "Epoch :  2  Batch :  285  Loss :   0.04971372691195523  Accuracy :  0.983859649122807 Time  1.03 s\n",
            "Epoch :  2  Batch :  286  Loss :   0.049724413350654334  Accuracy :  0.9837412587412587 Time  1.03 s\n",
            "Epoch :  2  Batch :  287  Loss :   0.04969750842702565  Accuracy :  0.9837979094076655 Time  1.05 s\n",
            "Epoch :  2  Batch :  288  Loss :   0.04957072236478174  Accuracy :  0.9838541666666667 Time  1.05 s\n",
            "Epoch :  2  Batch :  289  Loss :   0.04987628981116579  Accuracy :  0.9835640138408305 Time  1.04 s\n",
            "Epoch :  2  Batch :  290  Loss :   0.049724824474482184  Accuracy :  0.9836206896551725 Time  1.04 s\n",
            "Epoch :  2  Batch :  291  Loss :   0.049815597126253996  Accuracy :  0.9835051546391752 Time  1.04 s\n",
            "Epoch :  2  Batch :  292  Loss :   0.04975764781766099  Accuracy :  0.9835616438356164 Time  1.03 s\n",
            "Epoch :  2  Batch :  293  Loss :   0.04972958330020512  Accuracy :  0.9836177474402731 Time  1.04 s\n",
            "Epoch :  2  Batch :  294  Loss :   0.04965057372128223  Accuracy :  0.9836734693877551 Time  1.04 s\n",
            "Epoch :  2  Batch :  295  Loss :   0.049821953410756285  Accuracy :  0.9835593220338983 Time  1.03 s\n",
            "Epoch :  2  Batch :  296  Loss :   0.049805999719349014  Accuracy :  0.9836148648648648 Time  1.04 s\n",
            "Epoch :  2  Batch :  297  Loss :   0.04974462296217931  Accuracy :  0.9836700336700337 Time  1.05 s\n",
            "Epoch :  2  Batch :  298  Loss :   0.049667665058271894  Accuracy :  0.9837248322147651 Time  1.05 s\n",
            "Epoch :  2  Batch :  299  Loss :   0.049538803817922354  Accuracy :  0.9837792642140468 Time  1.04 s\n",
            "Epoch :  2  Batch :  300  Loss :   0.04940107149227212  Accuracy :  0.9838333333333333 Time  1.03 s\n",
            "Epoch :  2  Batch :  301  Loss :   0.04925853599240366  Accuracy :  0.9838870431893688 Time  1.04 s\n",
            "Epoch :  2  Batch :  302  Loss :   0.04918397286913006  Accuracy :  0.9839403973509934 Time  1.04 s\n",
            "Epoch :  2  Batch :  303  Loss :   0.04918668748466636  Accuracy :  0.9838283828382838 Time  1.04 s\n",
            "Epoch :  2  Batch :  304  Loss :   0.04906373476076528  Accuracy :  0.9838815789473684 Time  1.05 s\n",
            "Epoch :  2  Batch :  305  Loss :   0.04922903734793673  Accuracy :  0.9837704918032787 Time  1.05 s\n",
            "Epoch :  2  Batch :  306  Loss :   0.049095128962672714  Accuracy :  0.9838235294117647 Time  1.03 s\n",
            "Epoch :  2  Batch :  307  Loss :   0.04895848992465713  Accuracy :  0.9838762214983713 Time  1.05 s\n",
            "Epoch :  2  Batch :  308  Loss :   0.048980252434765656  Accuracy :  0.9839285714285714 Time  1.05 s\n",
            "Epoch :  2  Batch :  309  Loss :   0.04911905944703032  Accuracy :  0.9838187702265372 Time  1.04 s\n",
            "Epoch :  2  Batch :  310  Loss :   0.0492669737432152  Accuracy :  0.9837096774193549 Time  1.03 s\n",
            "Epoch :  2  Batch :  311  Loss :   0.04989850159788391  Accuracy :  0.9836012861736334 Time  1.04 s\n",
            "Epoch :  2  Batch :  312  Loss :   0.050346338528936774  Accuracy :  0.9833333333333333 Time  1.03 s\n",
            "Epoch :  2  Batch :  313  Loss :   0.050353369742524794  Accuracy :  0.9833865814696485 Time  1.03 s\n",
            "Epoch :  2  Batch :  314  Loss :   0.0502491246977121  Accuracy :  0.9834394904458599 Time  1.03 s\n",
            "Epoch :  2  Batch :  315  Loss :   0.050112178822654105  Accuracy :  0.9834920634920635 Time  1.04 s\n",
            "Epoch :  2  Batch :  316  Loss :   0.051037208608917514  Accuracy :  0.9830696202531646 Time  1.04 s\n",
            "Epoch :  2  Batch :  317  Loss :   0.050983724811581504  Accuracy :  0.9831230283911672 Time  1.04 s\n",
            "Epoch :  2  Batch :  318  Loss :   0.05103950501923338  Accuracy :  0.9830188679245283 Time  1.05 s\n",
            "Epoch :  2  Batch :  319  Loss :   0.05096157869837921  Accuracy :  0.9830721003134796 Time  1.05 s\n",
            "Epoch :  2  Batch :  320  Loss :   0.05087526543211425  Accuracy :  0.983125 Time  1.03 s\n",
            "Epoch :  2  Batch :  321  Loss :   0.0507536841704397  Accuracy :  0.983177570093458 Time  1.04 s\n",
            "Epoch :  2  Batch :  322  Loss :   0.05066810131379582  Accuracy :  0.9832298136645963 Time  1.03 s\n",
            "Epoch :  2  Batch :  323  Loss :   0.050523882851454406  Accuracy :  0.98328173374613 Time  1.04 s\n",
            "Epoch :  2  Batch :  324  Loss :   0.05040557653338499  Accuracy :  0.9833333333333333 Time  1.04 s\n",
            "Epoch :  2  Batch :  325  Loss :   0.05027181955054402  Accuracy :  0.9833846153846154 Time  1.04 s\n",
            "Epoch :  2  Batch :  326  Loss :   0.05048186701802434  Accuracy :  0.9832822085889571 Time  1.03 s\n",
            "Epoch :  2  Batch :  327  Loss :   0.050338569450382974  Accuracy :  0.9833333333333333 Time  1.03 s\n",
            "Epoch :  2  Batch :  328  Loss :   0.050210206613239904  Accuracy :  0.9833841463414634 Time  1.04 s\n",
            "Epoch :  2  Batch :  329  Loss :   0.05007339917027072  Accuracy :  0.983434650455927 Time  1.05 s\n",
            "Epoch :  2  Batch :  330  Loss :   0.049996192193110335  Accuracy :  0.9834848484848485 Time  1.04 s\n",
            "Epoch :  2  Batch :  331  Loss :   0.05013969660317385  Accuracy :  0.9833836858006042 Time  1.03 s\n",
            "Epoch :  2  Batch :  332  Loss :   0.05016922561805246  Accuracy :  0.9832831325301205 Time  1.04 s\n",
            "Epoch :  2  Batch :  333  Loss :   0.050181765460294556  Accuracy :  0.9833333333333333 Time  1.03 s\n",
            "Epoch :  2  Batch :  334  Loss :   0.050077343865682536  Accuracy :  0.9833832335329341 Time  1.03 s\n",
            "Epoch :  2  Batch :  335  Loss :   0.05037083305946704  Accuracy :  0.9832835820895522 Time  1.04 s\n",
            "Epoch :  2  Batch :  336  Loss :   0.05032515909849843  Accuracy :  0.9833333333333333 Time  1.04 s\n",
            "Epoch :  2  Batch :  337  Loss :   0.05051038321798518  Accuracy :  0.9832344213649852 Time  1.04 s\n",
            "Epoch :  2  Batch :  338  Loss :   0.050478801377856077  Accuracy :  0.9832840236686391 Time  1.05 s\n",
            "Epoch :  2  Batch :  339  Loss :   0.05034837726871744  Accuracy :  0.9833333333333333 Time  1.05 s\n",
            "Epoch :  2  Batch :  340  Loss :   0.05033070751986302  Accuracy :  0.9832352941176471 Time  1.05 s\n",
            "Epoch :  2  Batch :  341  Loss :   0.050379536304448094  Accuracy :  0.9832844574780059 Time  1.04 s\n",
            "Epoch :  2  Batch :  342  Loss :   0.05038134299616237  Accuracy :  0.9833333333333333 Time  1.04 s\n",
            "Epoch :  2  Batch :  343  Loss :   0.05031178889622363  Accuracy :  0.9833819241982508 Time  1.04 s\n",
            "Epoch :  2  Batch :  344  Loss :   0.05031033385637065  Accuracy :  0.9832848837209303 Time  1.03 s\n",
            "Epoch :  2  Batch :  345  Loss :   0.050664243978056786  Accuracy :  0.9831884057971014 Time  1.06 s\n",
            "Epoch :  2  Batch :  346  Loss :   0.05052587497344165  Accuracy :  0.9832369942196532 Time  1.04 s\n",
            "Epoch :  2  Batch :  347  Loss :   0.050418257324148494  Accuracy :  0.98328530259366 Time  1.04 s\n",
            "Epoch :  2  Batch :  348  Loss :   0.05079722185833273  Accuracy :  0.9831896551724137 Time  1.04 s\n",
            "Epoch :  2  Batch :  349  Loss :   0.0508546206465039  Accuracy :  0.9830945558739255 Time  1.05 s\n",
            "Epoch :  2  Batch :  350  Loss :   0.050742712042161395  Accuracy :  0.9831428571428571 Time  1.05 s\n",
            "Epoch :  2  Batch :  351  Loss :   0.05062505717991594  Accuracy :  0.9831908831908832 Time  1.03 s\n",
            "Epoch :  2  Batch :  352  Loss :   0.05055453058924864  Accuracy :  0.9832386363636364 Time  1.04 s\n",
            "Epoch :  2  Batch :  353  Loss :   0.05042271478439315  Accuracy :  0.9832861189801699 Time  1.04 s\n",
            "Epoch :  2  Batch :  354  Loss :   0.05085076658860228  Accuracy :  0.9831920903954803 Time  1.04 s\n",
            "Epoch :  2  Batch :  355  Loss :   0.05077397009410279  Accuracy :  0.9832394366197184 Time  1.04 s\n",
            "Epoch :  2  Batch :  356  Loss :   0.05065069103932657  Accuracy :  0.9832865168539325 Time  1.03 s\n",
            "Epoch :  2  Batch :  357  Loss :   0.05061261162960103  Accuracy :  0.9833333333333333 Time  1.04 s\n",
            "Epoch :  2  Batch :  358  Loss :   0.050672134802047186  Accuracy :  0.9832402234636871 Time  1.04 s\n",
            "Epoch :  2  Batch :  359  Loss :   0.05098902358489324  Accuracy :  0.983008356545961 Time  1.05 s\n",
            "Epoch :  2  Batch :  360  Loss :   0.050875099203808026  Accuracy :  0.9830555555555556 Time  1.05 s\n",
            "Epoch :  2  Batch :  361  Loss :   0.051349731934852795  Accuracy :  0.9828254847645429 Time  1.04 s\n",
            "Epoch :  2  Batch :  362  Loss :   0.05174804659359651  Accuracy :  0.9824585635359117 Time  1.04 s\n",
            "Epoch :  2  Batch :  363  Loss :   0.051851664973838515  Accuracy :  0.9823691460055096 Time  1.04 s\n",
            "Epoch :  2  Batch :  364  Loss :   0.05206840181759057  Accuracy :  0.9822802197802197 Time  1.04 s\n",
            "Epoch :  2  Batch :  365  Loss :   0.05196052789815689  Accuracy :  0.9823287671232876 Time  1.04 s\n",
            "Epoch :  2  Batch :  366  Loss :   0.05183442536604087  Accuracy :  0.9823770491803279 Time  1.04 s\n",
            "Epoch :  2  Batch :  367  Loss :   0.05175399471312883  Accuracy :  0.982425068119891 Time  1.04 s\n",
            "Epoch :  2  Batch :  368  Loss :   0.05190776875267899  Accuracy :  0.9823369565217391 Time  1.04 s\n",
            "Epoch :  2  Batch :  369  Loss :   0.051778899074145936  Accuracy :  0.9823848238482384 Time  1.05 s\n",
            "Epoch :  2  Batch :  370  Loss :   0.05183156800984934  Accuracy :  0.9822972972972973 Time  1.05 s\n",
            "Epoch :  2  Batch :  371  Loss :   0.05181654837645209  Accuracy :  0.9823450134770889 Time  1.05 s\n",
            "Epoch :  2  Batch :  372  Loss :   0.05215633592207826  Accuracy :  0.9822580645161291 Time  1.04 s\n",
            "Epoch :  2  Batch :  373  Loss :   0.052737788482002376  Accuracy :  0.9821356615177972 Time  0.3 s\n",
            "Accuracy of     0 : 98 %\n",
            "Accuracy of     1 : 97 %\n",
            "Accuracy of     2 : 98 %\n",
            "[2 epoch] Accuracy of the network on the Training images: 98.214 %\n",
            "Epoch :  3  Batch :  1  Loss :   0.007657979615032673  Accuracy :  1.0 Time  1.04 s\n",
            "Epoch :  3  Batch :  2  Loss :   0.01846508914604783  Accuracy :  1.0 Time  1.04 s\n",
            "Epoch :  3  Batch :  3  Loss :   0.01322070020250976  Accuracy :  1.0 Time  1.04 s\n",
            "Epoch :  3  Batch :  4  Loss :   0.012161326420027763  Accuracy :  1.0 Time  1.04 s\n",
            "Epoch :  3  Batch :  5  Loss :   0.010654750047251582  Accuracy :  1.0 Time  1.04 s\n",
            "Epoch :  3  Batch :  6  Loss :   0.012386807201740643  Accuracy :  1.0 Time  1.04 s\n",
            "Epoch :  3  Batch :  7  Loss :   0.038747905321153145  Accuracy :  0.9928571428571429 Time  1.05 s\n",
            "Epoch :  3  Batch :  8  Loss :   0.036242936010239646  Accuracy :  0.99375 Time  1.12 s\n",
            "Epoch :  3  Batch :  9  Loss :   0.03401756284034087  Accuracy :  0.9944444444444445 Time  1.04 s\n",
            "Epoch :  3  Batch :  10  Loss :   0.03214670864399523  Accuracy :  0.995 Time  1.04 s\n",
            "Epoch :  3  Batch :  11  Loss :   0.030833188592540948  Accuracy :  0.9954545454545455 Time  1.03 s\n",
            "Epoch :  3  Batch :  12  Loss :   0.03281272868237769  Accuracy :  0.9958333333333333 Time  1.04 s\n",
            "Epoch :  3  Batch :  13  Loss :   0.03286178881087555  Accuracy :  0.9961538461538462 Time  1.05 s\n",
            "Epoch :  3  Batch :  14  Loss :   0.035352167390686064  Accuracy :  0.9964285714285714 Time  1.06 s\n",
            "Epoch :  3  Batch :  15  Loss :   0.03491635830141604  Accuracy :  0.9966666666666667 Time  1.04 s\n",
            "Epoch :  3  Batch :  16  Loss :   0.034909156485809945  Accuracy :  0.996875 Time  1.03 s\n",
            "Epoch :  3  Batch :  17  Loss :   0.03416256090242635  Accuracy :  0.9970588235294118 Time  1.05 s\n",
            "Epoch :  3  Batch :  18  Loss :   0.033987228331776954  Accuracy :  0.9972222222222222 Time  1.05 s\n",
            "Epoch :  3  Batch :  19  Loss :   0.04037794714646512  Accuracy :  0.9894736842105263 Time  1.04 s\n",
            "Epoch :  3  Batch :  20  Loss :   0.039578615583013746  Accuracy :  0.99 Time  1.03 s\n",
            "Epoch :  3  Batch :  21  Loss :   0.040880559888180526  Accuracy :  0.9880952380952381 Time  1.04 s\n",
            "Epoch :  3  Batch :  22  Loss :   0.03920396759217097  Accuracy :  0.9886363636363636 Time  1.04 s\n",
            "Epoch :  3  Batch :  23  Loss :   0.03781352320726475  Accuracy :  0.9891304347826086 Time  1.05 s\n",
            "Epoch :  3  Batch :  24  Loss :   0.03702246109605767  Accuracy :  0.9895833333333334 Time  1.04 s\n",
            "Epoch :  3  Batch :  25  Loss :   0.03600909418426454  Accuracy :  0.99 Time  1.04 s\n",
            "Epoch :  3  Batch :  26  Loss :   0.034893812907214924  Accuracy :  0.9903846153846154 Time  1.04 s\n",
            "Epoch :  3  Batch :  27  Loss :   0.04113499420970954  Accuracy :  0.9851851851851852 Time  1.05 s\n",
            "Epoch :  3  Batch :  28  Loss :   0.04334052346946139  Accuracy :  0.9839285714285714 Time  1.06 s\n",
            "Epoch :  3  Batch :  29  Loss :   0.04341289697311305  Accuracy :  0.9844827586206897 Time  1.06 s\n",
            "Epoch :  3  Batch :  30  Loss :   0.042561995494179425  Accuracy :  0.985 Time  1.04 s\n",
            "Epoch :  3  Batch :  31  Loss :   0.04156791786062381  Accuracy :  0.9854838709677419 Time  1.04 s\n",
            "Epoch :  3  Batch :  32  Loss :   0.041627058359154034  Accuracy :  0.9859375 Time  1.03 s\n",
            "Epoch :  3  Batch :  33  Loss :   0.0407041347176401  Accuracy :  0.9863636363636363 Time  1.04 s\n",
            "Epoch :  3  Batch :  34  Loss :   0.03961842583136305  Accuracy :  0.986764705882353 Time  1.04 s\n",
            "Epoch :  3  Batch :  35  Loss :   0.03872722032746034  Accuracy :  0.9871428571428571 Time  1.03 s\n",
            "Epoch :  3  Batch :  36  Loss :   0.03827158203219167  Accuracy :  0.9875 Time  1.03 s\n",
            "Epoch :  3  Batch :  37  Loss :   0.03750200667166831  Accuracy :  0.9878378378378379 Time  1.04 s\n",
            "Epoch :  3  Batch :  38  Loss :   0.03840421235164333  Accuracy :  0.9868421052631579 Time  1.05 s\n",
            "Epoch :  3  Batch :  39  Loss :   0.03755910229534866  Accuracy :  0.9871794871794872 Time  1.05 s\n",
            "Epoch :  3  Batch :  40  Loss :   0.03668758751009591  Accuracy :  0.9875 Time  1.04 s\n",
            "Epoch :  3  Batch :  41  Loss :   0.036246044998534205  Accuracy :  0.9878048780487805 Time  1.04 s\n",
            "Epoch :  3  Batch :  42  Loss :   0.03649863390628958  Accuracy :  0.986904761904762 Time  1.03 s\n",
            "Epoch :  3  Batch :  43  Loss :   0.03630432567212644  Accuracy :  0.9872093023255814 Time  1.04 s\n",
            "Epoch :  3  Batch :  44  Loss :   0.035593645747708666  Accuracy :  0.9875 Time  1.03 s\n",
            "Epoch :  3  Batch :  45  Loss :   0.03504401972620851  Accuracy :  0.9877777777777778 Time  1.04 s\n",
            "Epoch :  3  Batch :  46  Loss :   0.034753246976912996  Accuracy :  0.9880434782608696 Time  1.04 s\n",
            "Epoch :  3  Batch :  47  Loss :   0.034237575395270545  Accuracy :  0.9882978723404255 Time  1.04 s\n",
            "Epoch :  3  Batch :  48  Loss :   0.03364865262119565  Accuracy :  0.9885416666666667 Time  1.05 s\n",
            "Epoch :  3  Batch :  49  Loss :   0.033506405078901014  Accuracy :  0.9887755102040816 Time  1.05 s\n",
            "Epoch :  3  Batch :  50  Loss :   0.03305941655766219  Accuracy :  0.989 Time  1.04 s\n",
            "Epoch :  3  Batch :  51  Loss :   0.033229819622219485  Accuracy :  0.9892156862745098 Time  1.03 s\n",
            "Epoch :  3  Batch :  52  Loss :   0.03271474829391362  Accuracy :  0.989423076923077 Time  1.04 s\n",
            "Epoch :  3  Batch :  53  Loss :   0.03217516796891841  Accuracy :  0.9896226415094339 Time  1.04 s\n",
            "Epoch :  3  Batch :  54  Loss :   0.031684506818203735  Accuracy :  0.9898148148148148 Time  1.05 s\n",
            "Epoch :  3  Batch :  55  Loss :   0.031406735523011195  Accuracy :  0.99 Time  1.04 s\n",
            "Epoch :  3  Batch :  56  Loss :   0.030873768108514405  Accuracy :  0.9901785714285715 Time  1.04 s\n",
            "Epoch :  3  Batch :  57  Loss :   0.0303526445590123  Accuracy :  0.9903508771929824 Time  1.04 s\n",
            "Epoch :  3  Batch :  58  Loss :   0.030813958112487633  Accuracy :  0.9896551724137931 Time  1.06 s\n",
            "Epoch :  3  Batch :  59  Loss :   0.03033462784971284  Accuracy :  0.9898305084745763 Time  1.05 s\n",
            "Epoch :  3  Batch :  60  Loss :   0.03055409117951058  Accuracy :  0.99 Time  1.06 s\n",
            "Epoch :  3  Batch :  61  Loss :   0.030926639849671207  Accuracy :  0.989344262295082 Time  1.04 s\n",
            "Epoch :  3  Batch :  62  Loss :   0.030509740371452345  Accuracy :  0.989516129032258 Time  1.04 s\n",
            "Epoch :  3  Batch :  63  Loss :   0.03019346839504405  Accuracy :  0.9896825396825397 Time  1.04 s\n",
            "Epoch :  3  Batch :  64  Loss :   0.029996611427122843  Accuracy :  0.98984375 Time  1.04 s\n",
            "Epoch :  3  Batch :  65  Loss :   0.029677471104794396  Accuracy :  0.99 Time  1.03 s\n",
            "Epoch :  3  Batch :  66  Loss :   0.029482889569463266  Accuracy :  0.9901515151515151 Time  1.03 s\n",
            "Epoch :  3  Batch :  67  Loss :   0.030312699378718302  Accuracy :  0.9895522388059701 Time  1.04 s\n",
            "Epoch :  3  Batch :  68  Loss :   0.029966878781766248  Accuracy :  0.9897058823529412 Time  1.03 s\n",
            "Epoch :  3  Batch :  69  Loss :   0.0297032618790568  Accuracy :  0.9898550724637681 Time  1.05 s\n",
            "Epoch :  3  Batch :  70  Loss :   0.02931942676825981  Accuracy :  0.99 Time  1.05 s\n",
            "Epoch :  3  Batch :  71  Loss :   0.029058708394484097  Accuracy :  0.9901408450704225 Time  1.04 s\n",
            "Epoch :  3  Batch :  72  Loss :   0.028698277832720324  Accuracy :  0.9902777777777778 Time  1.04 s\n",
            "Epoch :  3  Batch :  73  Loss :   0.02847548248086839  Accuracy :  0.9904109589041096 Time  1.03 s\n",
            "Epoch :  3  Batch :  74  Loss :   0.028260027742755878  Accuracy :  0.9905405405405405 Time  1.03 s\n",
            "Epoch :  3  Batch :  75  Loss :   0.028280238464164238  Accuracy :  0.9906666666666667 Time  1.03 s\n",
            "Epoch :  3  Batch :  76  Loss :   0.027964820170860837  Accuracy :  0.9907894736842106 Time  1.04 s\n",
            "Epoch :  3  Batch :  77  Loss :   0.0276615184765043  Accuracy :  0.990909090909091 Time  1.04 s\n",
            "Epoch :  3  Batch :  78  Loss :   0.027493890403256487  Accuracy :  0.9910256410256411 Time  1.03 s\n",
            "Epoch :  3  Batch :  79  Loss :   0.027207371624056956  Accuracy :  0.9911392405063291 Time  1.05 s\n",
            "Epoch :  3  Batch :  80  Loss :   0.027629122485814152  Accuracy :  0.990625 Time  1.05 s\n",
            "Epoch :  3  Batch :  81  Loss :   0.02738435854876621  Accuracy :  0.9907407407407407 Time  1.05 s\n",
            "Epoch :  3  Batch :  82  Loss :   0.02711915091196893  Accuracy :  0.9908536585365854 Time  1.03 s\n",
            "Epoch :  3  Batch :  83  Loss :   0.02692507168541786  Accuracy :  0.9909638554216867 Time  1.03 s\n",
            "Epoch :  3  Batch :  84  Loss :   0.026654723248655154  Accuracy :  0.9910714285714286 Time  1.03 s\n",
            "Epoch :  3  Batch :  85  Loss :   0.026384736333206735  Accuracy :  0.9911764705882353 Time  1.04 s\n",
            "Epoch :  3  Batch :  86  Loss :   0.02619761339968157  Accuracy :  0.9912790697674418 Time  1.04 s\n",
            "Epoch :  3  Batch :  87  Loss :   0.025977670476001143  Accuracy :  0.9913793103448276 Time  1.03 s\n",
            "Epoch :  3  Batch :  88  Loss :   0.025882370318868198  Accuracy :  0.9914772727272727 Time  1.03 s\n",
            "Epoch :  3  Batch :  89  Loss :   0.02564779700308494  Accuracy :  0.9915730337078652 Time  1.04 s\n",
            "Epoch :  3  Batch :  90  Loss :   0.02561353484246259  Accuracy :  0.9916666666666667 Time  1.05 s\n",
            "Epoch :  3  Batch :  91  Loss :   0.025367227898511504  Accuracy :  0.9917582417582418 Time  1.05 s\n",
            "Epoch :  3  Batch :  92  Loss :   0.02568961053696947  Accuracy :  0.991304347826087 Time  1.04 s\n",
            "Epoch :  3  Batch :  93  Loss :   0.02543165999519769  Accuracy :  0.9913978494623656 Time  1.05 s\n",
            "Epoch :  3  Batch :  94  Loss :   0.025230775172376332  Accuracy :  0.9914893617021276 Time  1.05 s\n",
            "Epoch :  3  Batch :  95  Loss :   0.02514309730307248  Accuracy :  0.991578947368421 Time  1.04 s\n",
            "Epoch :  3  Batch :  96  Loss :   0.025235413070428574  Accuracy :  0.9916666666666667 Time  1.03 s\n",
            "Epoch :  3  Batch :  97  Loss :   0.02503627761550363  Accuracy :  0.9917525773195877 Time  1.03 s\n",
            "Epoch :  3  Batch :  98  Loss :   0.024795541735793635  Accuracy :  0.9918367346938776 Time  1.03 s\n",
            "Epoch :  3  Batch :  99  Loss :   0.024716145054418406  Accuracy :  0.9919191919191919 Time  1.04 s\n",
            "Epoch :  3  Batch :  100  Loss :   0.024598870916524903  Accuracy :  0.992 Time  1.05 s\n",
            "Epoch :  3  Batch :  101  Loss :   0.024468523511285017  Accuracy :  0.9920792079207921 Time  1.04 s\n",
            "Epoch :  3  Batch :  102  Loss :   0.02432703052980679  Accuracy :  0.9921568627450981 Time  1.04 s\n",
            "Epoch :  3  Batch :  103  Loss :   0.024137297311788698  Accuracy :  0.9922330097087378 Time  1.04 s\n",
            "Epoch :  3  Batch :  104  Loss :   0.023954770658747293  Accuracy :  0.9923076923076923 Time  1.04 s\n",
            "Epoch :  3  Batch :  105  Loss :   0.02373502409373898  Accuracy :  0.9923809523809524 Time  1.04 s\n",
            "Epoch :  3  Batch :  106  Loss :   0.02362513954790731  Accuracy :  0.9924528301886792 Time  1.03 s\n",
            "Epoch :  3  Batch :  107  Loss :   0.02364473498892039  Accuracy :  0.9925233644859813 Time  1.03 s\n",
            "Epoch :  3  Batch :  108  Loss :   0.023436336138897954  Accuracy :  0.9925925925925926 Time  1.04 s\n",
            "Epoch :  3  Batch :  109  Loss :   0.02325585979323219  Accuracy :  0.9926605504587156 Time  1.04 s\n",
            "Epoch :  3  Batch :  110  Loss :   0.023102682101836598  Accuracy :  0.9927272727272727 Time  1.05 s\n",
            "Epoch :  3  Batch :  111  Loss :   0.023663450822208984  Accuracy :  0.9923423423423423 Time  1.05 s\n",
            "Epoch :  3  Batch :  112  Loss :   0.023571346280472687  Accuracy :  0.9924107142857143 Time  1.06 s\n",
            "Epoch :  3  Batch :  113  Loss :   0.02338068208150335  Accuracy :  0.9924778761061946 Time  1.03 s\n",
            "Epoch :  3  Batch :  114  Loss :   0.023227434363338705  Accuracy :  0.9925438596491228 Time  1.03 s\n",
            "Epoch :  3  Batch :  115  Loss :   0.02316624993843067  Accuracy :  0.9926086956521739 Time  1.04 s\n",
            "Epoch :  3  Batch :  116  Loss :   0.022984646299878005  Accuracy :  0.9926724137931034 Time  1.04 s\n",
            "Epoch :  3  Batch :  117  Loss :   0.022876617282780252  Accuracy :  0.9927350427350428 Time  1.04 s\n",
            "Epoch :  3  Batch :  118  Loss :   0.023329626625774712  Accuracy :  0.9923728813559322 Time  1.04 s\n",
            "Epoch :  3  Batch :  119  Loss :   0.023291435702156055  Accuracy :  0.992436974789916 Time  1.04 s\n",
            "Epoch :  3  Batch :  120  Loss :   0.023150011931041565  Accuracy :  0.9925 Time  1.04 s\n",
            "Epoch :  3  Batch :  121  Loss :   0.023630515698243457  Accuracy :  0.9921487603305785 Time  1.05 s\n",
            "Epoch :  3  Batch :  122  Loss :   0.023469143271346988  Accuracy :  0.9922131147540983 Time  1.05 s\n",
            "Epoch :  3  Batch :  123  Loss :   0.023328030564277093  Accuracy :  0.9922764227642277 Time  1.04 s\n",
            "Epoch :  3  Batch :  124  Loss :   0.023345532413053836  Accuracy :  0.9923387096774193 Time  1.03 s\n",
            "Epoch :  3  Batch :  125  Loss :   0.023182665291242303  Accuracy :  0.9924 Time  1.04 s\n",
            "Epoch :  3  Batch :  126  Loss :   0.0230165342051935  Accuracy :  0.9924603174603175 Time  1.04 s\n",
            "Epoch :  3  Batch :  127  Loss :   0.022916404140827164  Accuracy :  0.99251968503937 Time  1.04 s\n",
            "Epoch :  3  Batch :  128  Loss :   0.02281421647694515  Accuracy :  0.992578125 Time  1.04 s\n",
            "Epoch :  3  Batch :  129  Loss :   0.02268955971623316  Accuracy :  0.9926356589147287 Time  1.03 s\n",
            "Epoch :  3  Batch :  130  Loss :   0.022538898764357256  Accuracy :  0.9926923076923077 Time  1.03 s\n",
            "Epoch :  3  Batch :  131  Loss :   0.022396169799266254  Accuracy :  0.9927480916030534 Time  1.04 s\n",
            "Epoch :  3  Batch :  132  Loss :   0.02224904635769428  Accuracy :  0.9928030303030303 Time  1.05 s\n",
            "Epoch :  3  Batch :  133  Loss :   0.022137473310217877  Accuracy :  0.9928571428571429 Time  1.07 s\n",
            "Epoch :  3  Batch :  134  Loss :   0.021983590121241983  Accuracy :  0.9929104477611941 Time  1.05 s\n",
            "Epoch :  3  Batch :  135  Loss :   0.021954190322301455  Accuracy :  0.9929629629629629 Time  1.04 s\n",
            "Epoch :  3  Batch :  136  Loss :   0.021800485587685697  Accuracy :  0.993014705882353 Time  1.04 s\n",
            "Epoch :  3  Batch :  137  Loss :   0.021759263719907915  Accuracy :  0.993065693430657 Time  1.03 s\n",
            "Epoch :  3  Batch :  138  Loss :   0.02169223423065294  Accuracy :  0.9931159420289855 Time  1.03 s\n",
            "Epoch :  3  Batch :  139  Loss :   0.021767650004777817  Accuracy :  0.9931654676258993 Time  1.03 s\n",
            "Epoch :  3  Batch :  140  Loss :   0.02166825971050587  Accuracy :  0.9932142857142857 Time  1.04 s\n",
            "Epoch :  3  Batch :  141  Loss :   0.02156894875720064  Accuracy :  0.9932624113475177 Time  1.04 s\n",
            "Epoch :  3  Batch :  142  Loss :   0.02149291759976645  Accuracy :  0.9933098591549295 Time  1.05 s\n",
            "Epoch :  3  Batch :  143  Loss :   0.0214700838461375  Accuracy :  0.9933566433566433 Time  1.06 s\n",
            "Epoch :  3  Batch :  144  Loss :   0.021349003008961316  Accuracy :  0.9934027777777777 Time  1.04 s\n",
            "Epoch :  3  Batch :  145  Loss :   0.02124857005326013  Accuracy :  0.993448275862069 Time  1.04 s\n",
            "Epoch :  3  Batch :  146  Loss :   0.021136515714030406  Accuracy :  0.9934931506849315 Time  1.04 s\n",
            "Epoch :  3  Batch :  147  Loss :   0.021035965764103142  Accuracy :  0.9935374149659864 Time  1.03 s\n",
            "Epoch :  3  Batch :  148  Loss :   0.021103998549389526  Accuracy :  0.9935810810810811 Time  1.04 s\n",
            "Epoch :  3  Batch :  149  Loss :   0.02104439578040959  Accuracy :  0.9936241610738255 Time  1.03 s\n",
            "Epoch :  3  Batch :  150  Loss :   0.020913511803373693  Accuracy :  0.9936666666666667 Time  1.04 s\n",
            "Epoch :  3  Batch :  151  Loss :   0.020792144767027225  Accuracy :  0.9937086092715232 Time  1.03 s\n",
            "Epoch :  3  Batch :  152  Loss :   0.020688921234594954  Accuracy :  0.99375 Time  1.04 s\n",
            "Epoch :  3  Batch :  153  Loss :   0.020603525382314438  Accuracy :  0.9937908496732026 Time  1.05 s\n",
            "Epoch :  3  Batch :  154  Loss :   0.021969313258547094  Accuracy :  0.9931818181818182 Time  1.04 s\n",
            "Epoch :  3  Batch :  155  Loss :   0.022897125441100327  Accuracy :  0.9929032258064516 Time  1.03 s\n",
            "Epoch :  3  Batch :  156  Loss :   0.022798813846654806  Accuracy :  0.992948717948718 Time  1.03 s\n",
            "Epoch :  3  Batch :  157  Loss :   0.0233643556245051  Accuracy :  0.9926751592356687 Time  1.04 s\n",
            "Epoch :  3  Batch :  158  Loss :   0.023226816119490592  Accuracy :  0.9927215189873417 Time  1.04 s\n",
            "Epoch :  3  Batch :  159  Loss :   0.023114738684973487  Accuracy :  0.9927672955974842 Time  1.04 s\n",
            "Epoch :  3  Batch :  160  Loss :   0.023789859461976447  Accuracy :  0.9925 Time  1.04 s\n",
            "Epoch :  3  Batch :  161  Loss :   0.02367630086460307  Accuracy :  0.9925465838509316 Time  1.03 s\n",
            "Epoch :  3  Batch :  162  Loss :   0.023543067478408095  Accuracy :  0.9925925925925926 Time  1.05 s\n",
            "Epoch :  3  Batch :  163  Loss :   0.02343583624721419  Accuracy :  0.992638036809816 Time  1.05 s\n",
            "Epoch :  3  Batch :  164  Loss :   0.023315513681864547  Accuracy :  0.9926829268292683 Time  1.05 s\n",
            "Epoch :  3  Batch :  165  Loss :   0.023261984516019848  Accuracy :  0.9927272727272727 Time  1.03 s\n",
            "Epoch :  3  Batch :  166  Loss :   0.023202212049810957  Accuracy :  0.9927710843373494 Time  1.04 s\n",
            "Epoch :  3  Batch :  167  Loss :   0.023127136517087456  Accuracy :  0.9928143712574851 Time  1.04 s\n",
            "Epoch :  3  Batch :  168  Loss :   0.023077273890348374  Accuracy :  0.9928571428571429 Time  1.04 s\n",
            "Epoch :  3  Batch :  169  Loss :   0.022979439417390737  Accuracy :  0.9928994082840237 Time  1.03 s\n",
            "Epoch :  3  Batch :  170  Loss :   0.022864608520724097  Accuracy :  0.9929411764705882 Time  1.04 s\n",
            "Epoch :  3  Batch :  171  Loss :   0.022778994920500145  Accuracy :  0.9929824561403509 Time  1.03 s\n",
            "Epoch :  3  Batch :  172  Loss :   0.022985903610513263  Accuracy :  0.9927325581395349 Time  1.04 s\n",
            "Epoch :  3  Batch :  173  Loss :   0.02286296693818116  Accuracy :  0.9927745664739884 Time  1.05 s\n",
            "Epoch :  3  Batch :  174  Loss :   0.022767513392268325  Accuracy :  0.992816091954023 Time  1.05 s\n",
            "Epoch :  3  Batch :  175  Loss :   0.022684775751882366  Accuracy :  0.9928571428571429 Time  1.05 s\n",
            "Epoch :  3  Batch :  176  Loss :   0.023205764328436504  Accuracy :  0.9926136363636363 Time  1.06 s\n",
            "Epoch :  3  Batch :  177  Loss :   0.023214850775992214  Accuracy :  0.9926553672316384 Time  1.04 s\n",
            "Epoch :  3  Batch :  178  Loss :   0.023157853953634504  Accuracy :  0.9926966292134831 Time  1.03 s\n",
            "Epoch :  3  Batch :  179  Loss :   0.023073743619076784  Accuracy :  0.9927374301675977 Time  1.04 s\n",
            "Epoch :  3  Batch :  180  Loss :   0.023713898520347557  Accuracy :  0.9925 Time  1.03 s\n",
            "Epoch :  3  Batch :  181  Loss :   0.02359305253864693  Accuracy :  0.9925414364640884 Time  1.03 s\n",
            "Epoch :  3  Batch :  182  Loss :   0.023503681149712383  Accuracy :  0.9925824175824176 Time  1.04 s\n",
            "Epoch :  3  Batch :  183  Loss :   0.023475803034074726  Accuracy :  0.9926229508196721 Time  1.04 s\n",
            "Epoch :  3  Batch :  184  Loss :   0.024208535284623908  Accuracy :  0.9923913043478261 Time  1.03 s\n",
            "Epoch :  3  Batch :  185  Loss :   0.024180985449788136  Accuracy :  0.9924324324324324 Time  1.05 s\n",
            "Epoch :  3  Batch :  186  Loss :   0.02407733488562567  Accuracy :  0.9924731182795699 Time  1.05 s\n",
            "Epoch :  3  Batch :  187  Loss :   0.024007214844615304  Accuracy :  0.9925133689839573 Time  1.03 s\n",
            "Epoch :  3  Batch :  188  Loss :   0.024032373698378736  Accuracy :  0.9925531914893617 Time  1.04 s\n",
            "Epoch :  3  Batch :  189  Loss :   0.023912748723492895  Accuracy :  0.9925925925925926 Time  1.04 s\n",
            "Epoch :  3  Batch :  190  Loss :   0.023796982027737324  Accuracy :  0.9926315789473684 Time  1.03 s\n",
            "Epoch :  3  Batch :  191  Loss :   0.023693541773102435  Accuracy :  0.9926701570680628 Time  1.04 s\n",
            "Epoch :  3  Batch :  192  Loss :   0.02363395274854459  Accuracy :  0.9927083333333333 Time  1.04 s\n",
            "Epoch :  3  Batch :  193  Loss :   0.023541515120039717  Accuracy :  0.9927461139896373 Time  1.04 s\n",
            "Epoch :  3  Batch :  194  Loss :   0.023440707752183463  Accuracy :  0.9927835051546392 Time  1.04 s\n",
            "Epoch :  3  Batch :  195  Loss :   0.02336988387366709  Accuracy :  0.9928205128205129 Time  1.05 s\n",
            "Epoch :  3  Batch :  196  Loss :   0.02326018350883102  Accuracy :  0.9928571428571429 Time  1.05 s\n",
            "Epoch :  3  Batch :  197  Loss :   0.023173417354730635  Accuracy :  0.9928934010152284 Time  1.05 s\n",
            "Epoch :  3  Batch :  198  Loss :   0.023076621853191443  Accuracy :  0.9929292929292929 Time  1.03 s\n",
            "Epoch :  3  Batch :  199  Loss :   0.023024973936903118  Accuracy :  0.992964824120603 Time  1.04 s\n",
            "Epoch :  3  Batch :  200  Loss :   0.02307946721557528  Accuracy :  0.993 Time  1.03 s\n",
            "Epoch :  3  Batch :  201  Loss :   0.023436047048748132  Accuracy :  0.9927860696517413 Time  1.04 s\n",
            "Epoch :  3  Batch :  202  Loss :   0.023323996024238555  Accuracy :  0.9928217821782178 Time  1.04 s\n",
            "Epoch :  3  Batch :  203  Loss :   0.023626621256885232  Accuracy :  0.9926108374384236 Time  1.04 s\n",
            "Epoch :  3  Batch :  204  Loss :   0.023520272489358653  Accuracy :  0.9926470588235294 Time  1.03 s\n",
            "Epoch :  3  Batch :  205  Loss :   0.023508134765391486  Accuracy :  0.9926829268292683 Time  1.03 s\n",
            "Epoch :  3  Batch :  206  Loss :   0.02347790211997474  Accuracy :  0.9927184466019418 Time  1.05 s\n",
            "Epoch :  3  Batch :  207  Loss :   0.023508904672200806  Accuracy :  0.9927536231884058 Time  1.04 s\n",
            "Epoch :  3  Batch :  208  Loss :   0.02340916727497153  Accuracy :  0.9927884615384616 Time  1.04 s\n",
            "Epoch :  3  Batch :  209  Loss :   0.023485545912851093  Accuracy :  0.992822966507177 Time  1.03 s\n",
            "Epoch :  3  Batch :  210  Loss :   0.02346904153347991  Accuracy :  0.9928571428571429 Time  1.04 s\n",
            "Epoch :  3  Batch :  211  Loss :   0.023536167153316193  Accuracy :  0.9928909952606635 Time  1.03 s\n",
            "Epoch :  3  Batch :  212  Loss :   0.024175948829649296  Accuracy :  0.992688679245283 Time  1.04 s\n",
            "Epoch :  3  Batch :  213  Loss :   0.02407680657537033  Accuracy :  0.9927230046948357 Time  1.05 s\n",
            "Epoch :  3  Batch :  214  Loss :   0.02410122819373245  Accuracy :  0.9927570093457944 Time  1.05 s\n",
            "Epoch :  3  Batch :  215  Loss :   0.024099920605049403  Accuracy :  0.9927906976744186 Time  1.04 s\n",
            "Epoch :  3  Batch :  216  Loss :   0.02407043675743302  Accuracy :  0.992824074074074 Time  1.05 s\n",
            "Epoch :  3  Batch :  217  Loss :   0.0239909229352684  Accuracy :  0.9928571428571429 Time  1.05 s\n",
            "Epoch :  3  Batch :  218  Loss :   0.02393839852361077  Accuracy :  0.9928899082568807 Time  1.04 s\n",
            "Epoch :  3  Batch :  219  Loss :   0.023846364728404745  Accuracy :  0.9929223744292237 Time  1.03 s\n",
            "Epoch :  3  Batch :  220  Loss :   0.02377413658118299  Accuracy :  0.9929545454545454 Time  1.04 s\n",
            "Epoch :  3  Batch :  221  Loss :   0.023681447514105267  Accuracy :  0.9929864253393665 Time  1.04 s\n",
            "Epoch :  3  Batch :  222  Loss :   0.02364930744347926  Accuracy :  0.993018018018018 Time  1.04 s\n",
            "Epoch :  3  Batch :  223  Loss :   0.023609316044887987  Accuracy :  0.9930493273542601 Time  1.03 s\n",
            "Epoch :  3  Batch :  224  Loss :   0.023563312609309963  Accuracy :  0.9930803571428571 Time  1.04 s\n",
            "Epoch :  3  Batch :  225  Loss :   0.02346946086268872  Accuracy :  0.9931111111111111 Time  1.04 s\n",
            "Epoch :  3  Batch :  226  Loss :   0.02345473476658798  Accuracy :  0.993141592920354 Time  1.05 s\n",
            "Epoch :  3  Batch :  227  Loss :   0.02336747525208568  Accuracy :  0.9931718061674009 Time  1.05 s\n",
            "Epoch :  3  Batch :  228  Loss :   0.02327185015810915  Accuracy :  0.9932017543859649 Time  1.06 s\n",
            "Epoch :  3  Batch :  229  Loss :   0.023215310492524347  Accuracy :  0.993231441048035 Time  1.03 s\n",
            "Epoch :  3  Batch :  230  Loss :   0.02314095888590521  Accuracy :  0.9932608695652174 Time  1.03 s\n",
            "Epoch :  3  Batch :  231  Loss :   0.023060903774606654  Accuracy :  0.9932900432900433 Time  1.04 s\n",
            "Epoch :  3  Batch :  232  Loss :   0.023044824157640788  Accuracy :  0.9933189655172414 Time  1.03 s\n",
            "Epoch :  3  Batch :  233  Loss :   0.023024533046889138  Accuracy :  0.9933476394849785 Time  1.03 s\n",
            "Epoch :  3  Batch :  234  Loss :   0.022948355862719573  Accuracy :  0.9933760683760684 Time  1.03 s\n",
            "Epoch :  3  Batch :  235  Loss :   0.0235303291406958  Accuracy :  0.9929787234042553 Time  1.04 s\n",
            "Epoch :  3  Batch :  236  Loss :   0.023458787929700783  Accuracy :  0.9930084745762712 Time  1.03 s\n",
            "Epoch :  3  Batch :  237  Loss :   0.023369532519605656  Accuracy :  0.9930379746835443 Time  1.05 s\n",
            "Epoch :  3  Batch :  238  Loss :   0.023288530662475826  Accuracy :  0.9930672268907563 Time  1.05 s\n",
            "Epoch :  3  Batch :  239  Loss :   0.023220900926450617  Accuracy :  0.9930962343096235 Time  1.04 s\n",
            "Epoch :  3  Batch :  240  Loss :   0.02313882147621674  Accuracy :  0.993125 Time  1.03 s\n",
            "Epoch :  3  Batch :  241  Loss :   0.023119732577168223  Accuracy :  0.9931535269709544 Time  1.04 s\n",
            "Epoch :  3  Batch :  242  Loss :   0.023135426048235583  Accuracy :  0.9931818181818182 Time  1.03 s\n",
            "Epoch :  3  Batch :  243  Loss :   0.02328143129508498  Accuracy :  0.9930041152263375 Time  1.04 s\n",
            "Epoch :  3  Batch :  244  Loss :   0.023229183379148484  Accuracy :  0.9930327868852459 Time  1.04 s\n",
            "Epoch :  3  Batch :  245  Loss :   0.02420930840569187  Accuracy :  0.9928571428571429 Time  1.04 s\n",
            "Epoch :  3  Batch :  246  Loss :   0.025181696206952136  Accuracy :  0.9926829268292683 Time  1.04 s\n",
            "Epoch :  3  Batch :  247  Loss :   0.02529661450346532  Accuracy :  0.9927125506072875 Time  1.05 s\n",
            "Epoch :  3  Batch :  248  Loss :   0.025198680691368457  Accuracy :  0.992741935483871 Time  1.05 s\n",
            "Epoch :  3  Batch :  249  Loss :   0.025311480471714734  Accuracy :  0.992570281124498 Time  1.04 s\n",
            "Epoch :  3  Batch :  250  Loss :   0.025230943308211864  Accuracy :  0.9926 Time  1.03 s\n",
            "Epoch :  3  Batch :  251  Loss :   0.0251718407943919  Accuracy :  0.9926294820717132 Time  1.03 s\n",
            "Epoch :  3  Batch :  252  Loss :   0.02515117395465957  Accuracy :  0.9926587301587302 Time  1.05 s\n",
            "Epoch :  3  Batch :  253  Loss :   0.025062515703121957  Accuracy :  0.9926877470355732 Time  1.05 s\n",
            "Epoch :  3  Batch :  254  Loss :   0.025357376216676115  Accuracy :  0.99251968503937 Time  1.06 s\n",
            "Epoch :  3  Batch :  255  Loss :   0.025273625706961633  Accuracy :  0.9925490196078431 Time  1.04 s\n",
            "Epoch :  3  Batch :  256  Loss :   0.026115499037587142  Accuracy :  0.9919921875 Time  1.04 s\n",
            "Epoch :  3  Batch :  257  Loss :   0.02603452197268808  Accuracy :  0.992023346303502 Time  1.05 s\n",
            "Epoch :  3  Batch :  258  Loss :   0.026039571303679326  Accuracy :  0.9920542635658914 Time  1.06 s\n",
            "Epoch :  3  Batch :  259  Loss :   0.026133887567755167  Accuracy :  0.9918918918918919 Time  1.05 s\n",
            "Epoch :  3  Batch :  260  Loss :   0.026054954895069107  Accuracy :  0.9919230769230769 Time  1.04 s\n",
            "Epoch :  3  Batch :  261  Loss :   0.026004291301007985  Accuracy :  0.9919540229885058 Time  1.04 s\n",
            "Epoch :  3  Batch :  262  Loss :   0.026013539664141605  Accuracy :  0.9919847328244275 Time  1.04 s\n",
            "Epoch :  3  Batch :  263  Loss :   0.02598270198185096  Accuracy :  0.9920152091254753 Time  1.04 s\n",
            "Epoch :  3  Batch :  264  Loss :   0.02619176981071095  Accuracy :  0.9918560606060606 Time  1.03 s\n",
            "Epoch :  3  Batch :  265  Loss :   0.026102215532248594  Accuracy :  0.9918867924528302 Time  1.04 s\n",
            "Epoch :  3  Batch :  266  Loss :   0.026012379334735356  Accuracy :  0.9919172932330828 Time  1.03 s\n",
            "Epoch :  3  Batch :  267  Loss :   0.02603584202355269  Accuracy :  0.9919475655430712 Time  1.03 s\n",
            "Epoch :  3  Batch :  268  Loss :   0.026032031133228828  Accuracy :  0.9919776119402985 Time  1.05 s\n",
            "Epoch :  3  Batch :  269  Loss :   0.026491162718574907  Accuracy :  0.9918215613382899 Time  1.05 s\n",
            "Epoch :  3  Batch :  270  Loss :   0.027126148669049145  Accuracy :  0.9916666666666667 Time  1.04 s\n",
            "Epoch :  3  Batch :  271  Loss :   0.02704278202693071  Accuracy :  0.9916974169741697 Time  1.03 s\n",
            "Epoch :  3  Batch :  272  Loss :   0.026978710060254398  Accuracy :  0.9917279411764706 Time  1.03 s\n",
            "Epoch :  3  Batch :  273  Loss :   0.02693913370411802  Accuracy :  0.9917582417582418 Time  1.03 s\n",
            "Epoch :  3  Batch :  274  Loss :   0.027258990492236658  Accuracy :  0.9914233576642336 Time  1.04 s\n",
            "Epoch :  3  Batch :  275  Loss :   0.02726960424333811  Accuracy :  0.9914545454545455 Time  1.03 s\n",
            "Epoch :  3  Batch :  276  Loss :   0.027356277877950797  Accuracy :  0.9914855072463769 Time  1.03 s\n",
            "Epoch :  3  Batch :  277  Loss :   0.02727675025556438  Accuracy :  0.9915162454873646 Time  1.04 s\n",
            "Epoch :  3  Batch :  278  Loss :   0.02718163068006787  Accuracy :  0.991546762589928 Time  1.05 s\n",
            "Epoch :  3  Batch :  279  Loss :   0.027238958392344  Accuracy :  0.9915770609318997 Time  1.05 s\n",
            "Epoch :  3  Batch :  280  Loss :   0.027184293848819964  Accuracy :  0.9916071428571429 Time  1.03 s\n",
            "Epoch :  3  Batch :  281  Loss :   0.027104454897832975  Accuracy :  0.9916370106761566 Time  1.04 s\n",
            "Epoch :  3  Batch :  282  Loss :   0.027379891413044356  Accuracy :  0.9914893617021276 Time  1.04 s\n",
            "Epoch :  3  Batch :  283  Loss :   0.02729836411427792  Accuracy :  0.9915194346289753 Time  1.04 s\n",
            "Epoch :  3  Batch :  284  Loss :   0.027579816370426915  Accuracy :  0.9913732394366197 Time  1.03 s\n",
            "Epoch :  3  Batch :  285  Loss :   0.027492171765117205  Accuracy :  0.9914035087719298 Time  1.04 s\n",
            "Epoch :  3  Batch :  286  Loss :   0.02740719326966364  Accuracy :  0.9914335664335664 Time  1.03 s\n",
            "Epoch :  3  Batch :  287  Loss :   0.027548045815392122  Accuracy :  0.9912891986062717 Time  1.04 s\n",
            "Epoch :  3  Batch :  288  Loss :   0.027483448398925248  Accuracy :  0.9913194444444444 Time  1.04 s\n",
            "Epoch :  3  Batch :  289  Loss :   0.02741495790229917  Accuracy :  0.9913494809688581 Time  1.05 s\n",
            "Epoch :  3  Batch :  290  Loss :   0.027564714228983263  Accuracy :  0.9912068965517241 Time  1.05 s\n",
            "Epoch :  3  Batch :  291  Loss :   0.027633844586561315  Accuracy :  0.9912371134020619 Time  1.03 s\n",
            "Epoch :  3  Batch :  292  Loss :   0.027586317203152758  Accuracy :  0.9912671232876712 Time  1.05 s\n",
            "Epoch :  3  Batch :  293  Loss :   0.02750410178001595  Accuracy :  0.991296928327645 Time  1.04 s\n",
            "Epoch :  3  Batch :  294  Loss :   0.02817700263789893  Accuracy :  0.9909863945578231 Time  1.04 s\n",
            "Epoch :  3  Batch :  295  Loss :   0.028088536914398547  Accuracy :  0.9910169491525423 Time  1.03 s\n",
            "Epoch :  3  Batch :  296  Loss :   0.028000743637873  Accuracy :  0.9910472972972973 Time  1.04 s\n",
            "Epoch :  3  Batch :  297  Loss :   0.02794188617549128  Accuracy :  0.9910774410774411 Time  1.03 s\n",
            "Epoch :  3  Batch :  298  Loss :   0.02968219737971558  Accuracy :  0.9907718120805369 Time  1.04 s\n",
            "Epoch :  3  Batch :  299  Loss :   0.0296797164710765  Accuracy :  0.9908026755852842 Time  1.05 s\n",
            "Epoch :  3  Batch :  300  Loss :   0.02961822812426059  Accuracy :  0.9908333333333333 Time  1.05 s\n",
            "Epoch :  3  Batch :  301  Loss :   0.029530607769381798  Accuracy :  0.9908637873754153 Time  1.04 s\n",
            "Epoch :  3  Batch :  302  Loss :   0.029445008721490952  Accuracy :  0.9908940397350994 Time  1.04 s\n",
            "Epoch :  3  Batch :  303  Loss :   0.02957132861472316  Accuracy :  0.9907590759075907 Time  1.04 s\n",
            "Epoch :  3  Batch :  304  Loss :   0.029816836113911307  Accuracy :  0.9907894736842106 Time  1.03 s\n",
            "Epoch :  3  Batch :  305  Loss :   0.030636900756317267  Accuracy :  0.9904918032786886 Time  1.04 s\n",
            "Epoch :  3  Batch :  306  Loss :   0.03061229342520937  Accuracy :  0.9905228758169935 Time  1.04 s\n",
            "Epoch :  3  Batch :  307  Loss :   0.0308056503960162  Accuracy :  0.9903908794788273 Time  1.03 s\n",
            "Epoch :  3  Batch :  308  Loss :   0.0307381461182074  Accuracy :  0.9904220779220779 Time  1.03 s\n",
            "Epoch :  3  Batch :  309  Loss :   0.03074201731848407  Accuracy :  0.9904530744336569 Time  1.05 s\n",
            "Epoch :  3  Batch :  310  Loss :   0.030816094049875956  Accuracy :  0.9904838709677419 Time  1.05 s\n",
            "Epoch :  3  Batch :  311  Loss :   0.030738321817038325  Accuracy :  0.9905144694533762 Time  1.05 s\n",
            "Epoch :  3  Batch :  312  Loss :   0.030682613149110693  Accuracy :  0.9905448717948718 Time  1.03 s\n",
            "Epoch :  3  Batch :  313  Loss :   0.030732509101177165  Accuracy :  0.9905750798722045 Time  1.04 s\n",
            "Epoch :  3  Batch :  314  Loss :   0.03083711514485982  Accuracy :  0.9904458598726115 Time  1.04 s\n",
            "Epoch :  3  Batch :  315  Loss :   0.030862773607285426  Accuracy :  0.9904761904761905 Time  1.03 s\n",
            "Epoch :  3  Batch :  316  Loss :   0.030824762841066215  Accuracy :  0.990506329113924 Time  1.04 s\n",
            "Epoch :  3  Batch :  317  Loss :   0.031012622564436123  Accuracy :  0.990378548895899 Time  1.04 s\n",
            "Epoch :  3  Batch :  318  Loss :   0.030983034628055368  Accuracy :  0.9904088050314466 Time  1.05 s\n",
            "Epoch :  3  Batch :  319  Loss :   0.03114428547656946  Accuracy :  0.990282131661442 Time  1.04 s\n",
            "Epoch :  3  Batch :  320  Loss :   0.03106151045340084  Accuracy :  0.9903125 Time  1.05 s\n",
            "Epoch :  3  Batch :  321  Loss :   0.03098913529039886  Accuracy :  0.9903426791277259 Time  1.06 s\n",
            "Epoch :  3  Batch :  322  Loss :   0.03141980422411247  Accuracy :  0.9902173913043478 Time  1.04 s\n",
            "Epoch :  3  Batch :  323  Loss :   0.03140836272762811  Accuracy :  0.9902476780185758 Time  1.04 s\n",
            "Epoch :  3  Batch :  324  Loss :   0.03169841053992665  Accuracy :  0.9901234567901235 Time  1.03 s\n",
            "Epoch :  3  Batch :  325  Loss :   0.031624415978037106  Accuracy :  0.9901538461538462 Time  1.04 s\n",
            "Epoch :  3  Batch :  326  Loss :   0.03172922568903533  Accuracy :  0.9901840490797545 Time  1.04 s\n",
            "Epoch :  3  Batch :  327  Loss :   0.03165835395312244  Accuracy :  0.9902140672782874 Time  1.04 s\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "\n",
        "for epoch in range(epochs):  \n",
        "    running_loss = 0.0\n",
        "    correct=0\n",
        "    total=0\n",
        "    class_correct = list(0. for gvar in classes)\n",
        "    class_total = list(0. for gvar in classes)\n",
        "    for i, data in enumerate(train_loader, 0):\n",
        "        inputs, labels = data\n",
        "        t0 = time()\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        labels = eye[labels]\n",
        "        optimizer.zero_grad()\n",
        "        #torch.cuda.empty_cache()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, torch.max(labels, 1)[1])\n",
        "        predicted = torch.argmax(outputs, 1)\n",
        "        labels = torch.argmax(labels, 1)\n",
        "        c = (predicted == labels.data).squeeze()\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "        accuracy = float(correct) / float(total)\n",
        "        \n",
        "        history_accuracy.append(accuracy)\n",
        "        history_loss.append(loss)\n",
        "        \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        for j in range(labels.size(0)):\n",
        "            label = labels[j]\n",
        "            class_correct[label] += c[j].item()\n",
        "            class_total[label] += 1\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        \n",
        "        print( \"Epoch : \",epoch+1,\" Batch : \", i+1,\" Loss :  \",running_loss/(i+1),\" Accuracy : \",accuracy,\"Time \",round(time()-t0, 2),\"s\" )\n",
        "    for k in range(len(classes)):\n",
        "        if(class_total[k]!=0):\n",
        "            print('Accuracy of %5s : %2d %%' % (classes[k], 100 * class_correct[k] / class_total[k]))\n",
        "        \n",
        "    print('[%d epoch] Accuracy of the network on the Training images: %.3f %%' % (epoch+1, 100 * correct / total))\n",
        "    \n",
        "    file=f\"/content/drive/MyDrive/Capstone Data (Shared)/Capstone Data/TrainedModelCheckpoints/EN4-Augment-epoch {epoch+1} model.pth\"\n",
        "    torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss\n",
        "            }, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zHz8umjDcyR"
      },
      "source": [
        "## Visualisation of accuracy and loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWre-m2htCtX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cksuKNXXuCvL"
      },
      "outputs": [],
      "source": [
        "hist_loss = []\n",
        "for i in history_loss:\n",
        "  j=i.cpu().detach().numpy()\n",
        "  hist_loss.append(j)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ftBUd45uqZ1"
      },
      "outputs": [],
      "source": [
        "hist_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "id": "nXQBAdWDvAi9",
        "outputId": "1e6a6e94-b678-4841-dd53-50dcd20db867"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f291ac04670>]"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x576 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.style.use(\"ggplot\")\n",
        "plt.figure(figsize=(16,8))\n",
        "plt.plot(history_accuracy)\n",
        "plt.plot(hist_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOavE2vT71TM"
      },
      "outputs": [],
      "source": [
        "# plt.savefig(\"LossAndAccuracy\",dpi=2048, format = png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f7LzOiLDndQ"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VC6c552AtA5x",
        "outputId": "7939ad2b-27bb-42b2-df42-10d3986adf42"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EfficientNet(\n",
              "  (_conv_stem): Conv2dStaticSamePadding(\n",
              "    3, 48, kernel_size=(3, 3), stride=(2, 2), bias=False\n",
              "    (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "  )\n",
              "  (_bn0): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_blocks): ModuleList(\n",
              "    (0): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (1): MBConvBlock(\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (2): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
              "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (3): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (4): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (5): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (6): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (7): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (8): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (9): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (10): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
              "        (static_padding): ZeroPad2d((0, 1, 0, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (11): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (12): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (13): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (14): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (15): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (16): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (17): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (18): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (19): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (20): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (21): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (22): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 2, 1, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (23): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (24): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (25): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (26): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (27): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (28): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (29): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((2, 2, 2, 2))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (30): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "    (31): MBConvBlock(\n",
              "      (_expand_conv): Conv2dStaticSamePadding(\n",
              "        448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_depthwise_conv): Conv2dStaticSamePadding(\n",
              "        2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
              "        (static_padding): ZeroPad2d((1, 1, 1, 1))\n",
              "      )\n",
              "      (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_se_reduce): Conv2dStaticSamePadding(\n",
              "        2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_se_expand): Conv2dStaticSamePadding(\n",
              "        112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_project_conv): Conv2dStaticSamePadding(\n",
              "        2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "        (static_padding): Identity()\n",
              "      )\n",
              "      (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "      (_swish): MemoryEfficientSwish()\n",
              "    )\n",
              "  )\n",
              "  (_conv_head): Conv2dStaticSamePadding(\n",
              "    448, 1792, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
              "    (static_padding): Identity()\n",
              "  )\n",
              "  (_bn1): BatchNorm2d(1792, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
              "  (_avg_pooling): AdaptiveAvgPool2d(output_size=1)\n",
              "  (_dropout): Dropout(p=0.4, inplace=False)\n",
              "  (_fc): Linear(in_features=1792, out_features=3, bias=True)\n",
              "  (_swish): MemoryEfficientSwish()\n",
              ")"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZTSacoKvVW_",
        "outputId": "8be7c260-8de1-4c28-ce09-13feaa9300b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 99.282453 %\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "predictions=[]\n",
        "actuals=[]\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "        outputs = model(images)\n",
        "        predicted = torch.argmax(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        pred_arr = predicted.cpu().detach().numpy()\n",
        "        actual_arr = labels.cpu().detach().numpy()\n",
        "        predictions.append(pred_arr)\n",
        "        actuals.append(actual_arr)\n",
        "\n",
        "print('Accuracy of the network on the test images: %f %%'% (100 * correct / total))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b2tfQ7ssygo"
      },
      "outputs": [],
      "source": [
        "pred=np.concatenate(predictions)\n",
        "act=np.concatenate(actuals)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azXaaWOBsyeA"
      },
      "outputs": [],
      "source": [
        "pred_arr = predicted.cpu().detach().numpy()\n",
        "actual_arr = labels.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "5iE5Mxy7sybc",
        "outputId": "a57ffb9b-1534-49cd-9c46-2e08d880306b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2be1c70d-c494-4a83-b5a7-f52f1601137a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Actual</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Predicted</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>702</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>576</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2be1c70d-c494-4a83-b5a7-f52f1601137a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2be1c70d-c494-4a83-b5a7-f52f1601137a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2be1c70d-c494-4a83-b5a7-f52f1601137a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "Actual       0    1    2\n",
              "Predicted               \n",
              "0          702    2    0\n",
              "1            0  576    3\n",
              "2            1    5  244"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.crosstab(pred,act,rownames=['Predicted'], colnames=['Actual'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTMP4GsPsyY1",
        "outputId": "11dbf1bc-f32f-4884-d8d0-e1ba6392610a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Covid', 'Normal', 'Pneumonia']"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datavar.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-mOtYeBsyWN",
        "outputId": "6b4a4935-27a0-4056-ec2b-7b3e425980b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Covid': 0, 'Normal': 1, 'Pneumonia': 2}"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datavar.class_to_idx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPFgAo8y0hEq"
      },
      "source": [
        "## Load pretrained model into file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThCIRBFsz6Tq"
      },
      "outputs": [],
      "source": [
        "file = '/content/EN4-epoch 10 model.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bsj7noozJqN"
      },
      "outputs": [],
      "source": [
        "checkpoint = torch.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JsxuBs8BsyTL",
        "outputId": "c83aa75d-9a03-49e8-ab2d-c921bf96fb15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded pretrained weights for efficientnet-b4\n"
          ]
        }
      ],
      "source": [
        "model2 = en4.from_pretrained('efficientnet-b4', num_classes=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1UI27CssyQm"
      },
      "outputs": [],
      "source": [
        "optimizer2 = optim.AdamW(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TdiPRQIhsyOF"
      },
      "outputs": [],
      "source": [
        "model2.load_state_dict(checkpoint['model_state_dict'])\n",
        "optimizer2.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "epoch = checkpoint[\"epoch\"]\n",
        "loss = checkpoint['loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1fF-yax4y5b"
      },
      "outputs": [],
      "source": [
        "file_save = '/content/drive/MyDrive/Import to Colab/Models/E4-10epoch-batch16.pth'\n",
        "# '/content/drive/MyDrive/Capstone Data (Shared)/Capstone Data/TrainedModelCheckpoints/E4-10epoch-batch16.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8GAVfAKf4uXn"
      },
      "outputs": [],
      "source": [
        "torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss\n",
        "            }, file_save)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2zMs9Y9syLp",
        "outputId": "3583c9f0-cf2d-4090-e24f-1fd3e0d811f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the test images: 99.282453 %\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model on test data\n",
        "\n",
        "correct2 = 0\n",
        "total2 = 0\n",
        "predictions2=[]\n",
        "actuals2=[]\n",
        "with torch.no_grad():\n",
        "    for data in test_loader:\n",
        "        images, labels = data\n",
        "        images,labels = images.to(device),labels.to(device)\n",
        "        outputs = model(images)\n",
        "        predicted = torch.argmax(outputs.data, 1)\n",
        "        total2 += labels.size(0)\n",
        "        correct2 += (predicted == labels).sum().item()\n",
        "        pred_arr2 = predicted.cpu().detach().numpy()\n",
        "        actual_arr2 = labels.cpu().detach().numpy()\n",
        "        predictions2.append(pred_arr2)\n",
        "        actuals2.append(actual_arr2)\n",
        "\n",
        "print('Accuracy of the network on the test images: %f %%'% (100 * correct2 / total2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3-Z9tnmsyJL"
      },
      "outputs": [],
      "source": [
        "pred2=np.concatenate(predictions2)\n",
        "act2=np.concatenate(actuals2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aFOcjrA5syGc"
      },
      "outputs": [],
      "source": [
        "pred_arr2 = predicted.cpu().detach().numpy()\n",
        "actual_arr2 = labels.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "QNiTtJlWzdfz",
        "outputId": "34b4dfc5-1e09-4e32-91c9-8ef80c89ce3b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cb05f0ee-e5fd-48fb-87b0-29da891b2b64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Actual</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Predicted</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>702</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>576</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cb05f0ee-e5fd-48fb-87b0-29da891b2b64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cb05f0ee-e5fd-48fb-87b0-29da891b2b64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cb05f0ee-e5fd-48fb-87b0-29da891b2b64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "Actual       0    1    2\n",
              "Predicted               \n",
              "0          702    2    0\n",
              "1            0  576    3\n",
              "2            1    5  244"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.crosstab(pred2,act2,rownames=['Predicted'], colnames=['Actual'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "0lU6tdZ-NZob",
        "k4rTr6szCy9s",
        "QRnQitcODO5B",
        "4zHz8umjDcyR",
        "9f7LzOiLDndQ",
        "sPFgAo8y0hEq"
      ],
      "provenance": [],
      "authorship_tag": "ABX9TyNVcV7eb1KJ+M+2YdWFn7bA",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}